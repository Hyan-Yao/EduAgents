{
    "student_profile": {
        "student_background": "Total students: 20-40. Student level: Primarily graduate students. International/domestic ratio: ~20% international, ~80% domestic. Academic background: Mostly Computer Science and related fields such as Operations Research, Electrical Engineering, Mechanical Engineering, and Transportation Research.",
        "aggregate_academic_performance": "Overall academic strength: Generally strong. Graduate-level readiness: High, given prerequisites in calculus and probability. Experience variability: Varies in familiarity with reinforcement learning, optimization, and dynamic programming.",
        "anticipated_learner_needs_and_barriers": "Programming confidence: Most are comfortable with Python and basic numerical computing. Concept gaps: Some unfamiliarity with advanced reinforcement learning concepts (e.g., approximate dynamic programming, multi-agent RL). Tool gaps: Limited experience with simulation tools, optimization solvers, and neural networks in RL settings. Language needs: Some students may benefit from clarified mathematical derivations and algorithmic explanations. Math background: Minor gaps in optimization, and calculus."
    },
    "instructor_preferences": {
        "instructor_emphasis_intent": "Teaching focus: Emphasizes reinforcement learning algorithms, dynamic programming, and applications to control, robotics, and AI systems. Content style preference: Strong theoretical focus, supplemented by demonstrations on applications, video lectures, and research readings. Instructional intent: Encourages independent research and deep conceptual understanding through directed readings and projects.",
        "instructor_style_preferences": "Language background: Fluent English speakers with strong academic communication. Tone: Graduate-level formal with technical rigor. Script style: Concept-driven, mathematically rigorous, with research-focused discussions. Slide visuals: Uses detailed slides, video lectures, animations, and technical derivations.",
        "instructor_focus_for_assessment": "Assessment type: Strong emphasis on research projects. Task format: Includes homeworks and a research paper or term project. Real-world application: Explored through projects on robotics, AI software, and multi-agent systems. Final exam: None; evaluation based on homeworks and research project."
    },
    "course_structure": {
        "course_learning_outcomes": "Students will be able to: Understand reinforcement learning and approximate dynamic programming algorithms. Analyze value and policy approximation methods. Apply RL methods in control, optimization, and engineering applications. Conduct independent research in reinforcement learning and effectively communicate findings.",
        "total_number_of_weeks": "Total number of weeks: 15",
        "weekly_schedule_outline": "Weeks 1–4: Overview of Reinforcement Learning and Dynamic Programming. Weeks 5–12: In-depth exploration of selected RL topics such as applications to multi-agent problems, Wordle puzzle, and computer chess. Week 13-15: Student research projects and presentations."
    },
    "assessment_design": {
        "assessment_format_preferences": "Assessment type preference: Homeworks and a major research project or a review paper. Milestone structure: Project includes proposal, progress updates, and final paper. Final project expectation: A term paper with new research on a specialized RL topic. Question type preference: Theoretical analysis, algorithmic derivations, and computational studies in homework. Application emphasis: Reinforcement learning applications in robotics, engineering, and computer science domains.",
        "assessment_delivery_constraints": "Final exam policy: No final exam; assessment via homeworks and research paper. Assessment pacing: Early homeworks followed by intensive project focus in latter half of semester. LMS compatibility: All submissions via ASU’s Canvas LMS. Submission format: PDF documents for homeworks and project report."
    },
    "teaching_constraints": {
        "platform_policy_constraints": "LMS platform: Canvas (ASU standard). Submission formats: PDF submissions. Policy compliance: Must comply with ASU accessibility, academic integrity, and copyright policies.",
        "ta_support_availability": "TA count: 1. TA responsibilities: Delivering of some lectures, assist with grading, and provide feedback on research papers. TA technical role: Support for mathematical modeling, optimization, and reinforcement learning tools. TA availability: Email-based support.",
        "instructional_delivery_context": "Session duration: 2.5 hours. Delivery format: In-person lectures, supported by video lectures and external readings. Use of classroom tools: Mathematical modeling tools, simulation frameworks, and reinforcement learning libraries. Instructional pacing: Intensive, research-oriented with deep dives into selected topics.",
        "max_slide_count": "50"
    },
    "institutional_requirements": {
        "program_learning_outcomes": "Reinforces student competencies in reinforcement learning, approximate dynamic programming, optimization, and research skills in AI.",
        "academic_policies_and_institutional_standards": "Academic integrity: Must follow ASU’s Academic Integrity Policy. Accessibility: Complies with ASU disability accommodation policy. Copyright: Unauthorized sharing or recording of course content is prohibited. Canvas requirement: All instructional materials and submissions are managed through Canvas.",
        "department_syllabus_requirements": "Clearly stated course learning outcomes. Grading policy breakdown. Participation and assessment components. Weekly schedule outline. Required university policies (academic integrity, Title IX, accessibility, etc.)."
    },
    "prior_feedback": {
        "historical_course_evaluation_results": "Overall course rating: Generally positive; students appreciate the real-world orientation and relevance of the material. Preferred assessment structure: Students express strong support for project-based learning and dislike high-stakes final exams. Clarity concerns: Occasional feedback indicates that lecture pacing can feel fast in early weeks for students unfamiliar with certain tools."
    }
}