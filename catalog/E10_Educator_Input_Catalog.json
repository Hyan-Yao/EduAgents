{
    "student_profile": {
        "student_background": "Total students: 20-40. Student level: Primarily graduate students. International/domestic ratio: ~60% international, ~40% domestic. Academic background: Mostly Computer Science and related fields such as Operations Research and Electrical Engineering.",
        "aggregate_academic_performance": "Overall academic strength: Generally strong. Graduate-level readiness: High, given prerequisites in calculus and probability. Experience variability: Varies in familiarity with reinforcement learning, optimization, and dynamic programming.",
        "anticipated_learner_needs_and_barriers": "Programming confidence: Most are comfortable with Python and basic numerical computing. Concept gaps: Some unfamiliarity with advanced reinforcement learning concepts (e.g., approximate dynamic programming, multi-agent RL). Tool gaps: Limited experience with simulation tools, optimization solvers, and neural networks in RL settings. Language needs: Some students may benefit from clarified mathematical derivations and algorithmic explanations. Math background: Minor gaps in optimization, calculus, and stochastic processes."
    },
    "instructor_preferences": {
        "instructor_emphasis_intent": "Teaching focus: Emphasizes reinforcement learning algorithms, dynamic programming, and applications to control, robotics, and AI systems. Content style preference: Strong theoretical focus, supplemented by video lectures and research readings. Instructional intent: Encourages independent research and deep conceptual understanding through directed readings and projects.",
        "instructor_style_preferences": "Language background: Native English speaker with strong academic communication. Tone: Graduate-level formal with technical rigor. Script style: Concept-driven, mathematically rigorous, with research-focused discussions. Slide visuals: Uses detailed slides, video lectures, and technical derivations.",
        "instructor_focus_for_assessment": "Assessment type: Strong emphasis on research projects and theoretical analysis. Task format: Includes homeworks and a research paper or term project. Real-world application: Explored through projects on robotics, healthcare, and multi-agent systems. Final exam: None; evaluation based on homeworks and research project."
    },
    "course_structure": {
        "course_learning_outcomes": "Students will be able to: Understand reinforcement learning and approximate dynamic programming algorithms. Analyze value and policy approximation methods. Apply RL methods in control, optimization, and engineering applications. Conduct independent research in reinforcement learning and effectively communicate findings.",
        "total_number_of_weeks": "Total number of weeks: 15",
        "weekly_schedule_outline": "Weeks 1–4: Overview of Reinforcement Learning and Dynamic Programming. Weeks 5–14: In-depth exploration of selected RL topics such as multi-agent methods, model predictive control, and neural networks. Week 15: Student Research Presentations."
    },
    "assessment_design": {
        "assessment_format_preferences": "Assessment type preference: Homeworks and a major research paper or term project. Milestone structure: Project includes proposal, progress updates, and final paper. Final project expectation: A substantial research paper on a specialized RL topic. Question type preference: Theoretical analysis and algorithmic derivations in homework. Application emphasis: Reinforcement learning applications in control and optimization domains.",
        "assessment_delivery_constraints": "Final exam policy: No final exam; assessment via homeworks and research paper. Assessment pacing: Early homeworks followed by intensive project focus in latter half of semester. LMS compatibility: All submissions via Duke University’s LMS. Submission format: PDF documents for homeworks and project report."
    },
    "teaching_constraints": {
        "platform_policy_constraints": "LMS platform: Sakai. Submission formats: PDF submissions. Policy compliance: Must comply with Duke University’s academic integrity and accessibility policies.",
        "ta_support_availability": "TA count: 1. TA responsibilities: Assist with grading and provide feedback on research papers. TA technical role: Support for mathematical modeling, optimization, and reinforcement learning tools. TA availability: Regular office hours and email-based support.",
        "instructional_delivery_context": "Session duration: 2.5 hours. Delivery format: In-person lectures, supported by video lectures and external readings. Use of classroom tools: Mathematical modeling tools, simulation frameworks, and reinforcement learning libraries. Instructional pacing: Intensive, research-oriented with deep dives into selected topics.",
        "max_slide_count": "70"
    },
    "institutional_requirements": {
        "program_learning_outcomes": "Reinforces student competencies in reinforcement learning, approximate dynamic programming, optimization, and research skills in AI.",
        "academic_policies_and_institutional_standards": "Academic integrity: Must follow Duke University’s Academic Integrity Policy. Accessibility: Complies with Duke University’s disability accommodation policy. Copyright: Unauthorized sharing or recording of course content is prohibited. Sakai requirement: All instructional materials and submissions are managed through the university’s LMS.",
        "department_syllabus_requirements": "Clearly stated course learning outcomes. Grading policy breakdown. Participation and assessment components. Weekly schedule outline. Required university policies (academic integrity, Title IX, accessibility, etc.)."
    },
    "prior_feedback": {
        "historical_course_evaluation_results": "Overall course rating: Generally positive; students appreciate the real-world orientation and relevance of the material. Preferred assessment structure: Students express strong support for project-based learning and dislike high-stakes final exams. Clarity concerns: Occasional feedback indicates that lecture pacing can feel fast in early weeks for students unfamiliar with certain tools."
    }
}