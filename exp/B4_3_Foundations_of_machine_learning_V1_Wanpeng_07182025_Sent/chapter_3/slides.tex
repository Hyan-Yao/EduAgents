\documentclass[aspectratio=169]{beamer}

% Theme and Color Setup
\usetheme{Madrid}
\usecolortheme{whale}
\useinnertheme{rectangles}
\useoutertheme{miniframes}

% Additional Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}
\usepackage{hyperref}

% Custom Colors
\definecolor{myblue}{RGB}{31, 73, 125}
\definecolor{mygray}{RGB}{100, 100, 100}
\definecolor{mygreen}{RGB}{0, 128, 0}
\definecolor{myorange}{RGB}{230, 126, 34}
\definecolor{mycodebackground}{RGB}{245, 245, 245}

% Set Theme Colors
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=white, bg=myblue}
\setbeamercolor{title}{fg=myblue}
\setbeamercolor{section in toc}{fg=myblue}
\setbeamercolor{item projected}{fg=white, bg=myblue}
\setbeamercolor{block title}{bg=myblue!20, fg=myblue}
\setbeamercolor{block body}{bg=myblue!10}
\setbeamercolor{alerted text}{fg=myorange}

% Set Fonts
\setbeamerfont{title}{size=\Large, series=\bfseries}
\setbeamerfont{frametitle}{size=\large, series=\bfseries}
\setbeamerfont{caption}{size=\small}
\setbeamerfont{footnote}{size=\tiny}

% Custom Commands
\newcommand{\hilight}[1]{\colorbox{myorange!30}{#1}}
\newcommand{\concept}[1]{\textcolor{myblue}{\textbf{#1}}}

% Footer and Navigation Setup
\setbeamertemplate{footline}{
  \leavevmode%
  \hbox{%
    \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
      \usebeamerfont{author in head/foot}\insertshortauthor
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.5\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
      \usebeamerfont{title in head/foot}\insertshorttitle
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.2\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}%
      \usebeamerfont{date in head/foot}
      \insertframenumber{} / \inserttotalframenumber
    \end{beamercolorbox}}%
  \vskip0pt%
}

% Turn off navigation symbols
\setbeamertemplate{navigation symbols}{}

% Title Page Information
\title[Supervised Learning - Regression]{Chapter 3: Supervised Learning - Regression}
\author[J. Smith]{John Smith, Ph.D.}
\institute[University Name]{
  Department of Computer Science\\
  University Name\\
  \vspace{0.3cm}
  Email: email@university.edu\\
  Website: www.university.edu
}
\date{\today}

% Document Start
\begin{document}

\frame{\titlepage}

\begin{frame}[fragile]
    \frametitle{Introduction to Chapter 3: Supervised Learning - Regression}
    \begin{block}{Overview of Supervised Learning}
        \begin{itemize}
            \item Supervised Learning is a type of machine learning where an algorithm is trained on a labeled dataset.
            \item The algorithm maps input features (independent variables) to known outputs (dependent variable).
            \item The goal is to make predictions based on new, unseen data after training.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{What is Regression?}
    \begin{block}{Definition}
        Regression is a statistical method used in supervised learning to predict a continuous outcome:
        \begin{itemize}
            \item Unlike classification, which predicts discrete labels.
            \item Examples include estimating house prices, predicting temperatures, or forecasting sales.
        \end{itemize}
    \end{block}
    
    \begin{block}{Key Concepts in Regression}
        \begin{itemize}
            \item \textbf{Dependent Variable (Target)}: Outcome variable to predict (e.g., house prices).
            \item \textbf{Independent Variables (Features)}: Factors used for prediction (e.g., size, number of bedrooms).
            \item \textbf{Regression Line}: Best-fitting line that represents the relationship between variables.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Common Types of Regression}
    \begin{itemize}
        \item \textbf{Linear Regression}:
        \begin{equation}
            y = mx + b
        \end{equation}
        \item \textbf{Multiple Linear Regression}:
        \begin{equation}
            y = b_0 + b_1x_1 + b_2x_2 + \ldots + b_nx_n
        \end{equation}
        \item \textbf{Polynomial Regression}:
        \begin{equation}
            y = b_0 + b_1x + b_2x^2 + \ldots + b_nx^n
        \end{equation}
    \end{itemize}
    
    \begin{block}{Importance of Regression Analysis}
        \begin{itemize}
            \item Understand relationships between variables.
            \item Valuable insights for forecasting and decision-making.
        \end{itemize}
    \end{block}

    \begin{block}{Next Steps}
        \begin{itemize}
            \item In the upcoming slide, we will delve deeper into regression techniques and their evaluation.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Overview of Key Concepts in Supervised Learning - Regression}
    \begin{block}{What is Supervised Learning?}
        \begin{itemize}
            \item \textbf{Definition}: A type of machine learning where the model is trained on labeled data (input-output pairs).
            \item \textbf{Objective}: To learn a mapping from inputs (features) to outputs (labels) based on training examples.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts in Regression}
    \begin{block}{What is Regression?}
        \begin{itemize}
            \item \textbf{Definition}: A statistical method modeling the relationship between a dependent variable and independent variables.
            \item \textbf{Goal}: Predict continuous outcomes (e.g., predicting house prices based on size and location).
        \end{itemize}
    \end{block}
    \begin{block}{Dependent and Independent Variables}
        \begin{itemize}
            \item \textbf{Dependent Variable}: The value we aim to predict (e.g., house price).
            \item \textbf{Independent Variables}: Features used for prediction (e.g., square footage, number of bedrooms).
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Regression and Metrics}
    \begin{block}{Types of Regression}
        \begin{itemize}
            \item \textbf{Linear Regression}: Uses a straight line (y = mx + b).
            \item \textbf{Polynomial Regression}: Fits a polynomial equation.
            \item \textbf{Logistic Regression}: For binary classification, represented with an S-shaped curve.
        \end{itemize}
    \end{block}
    \begin{block}{Loss Function}
        \textbf{Mean Squared Error (MSE)}:
        \begin{equation}
        MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
        \end{equation}
        where \(y_i\) is the true value and \(\hat{y}_i\) is the predicted value.
    \end{block}
    \begin{block}{Evaluation Metrics}
        \begin{itemize}
            \item \textbf{R-squared}: Measures how well the independent variables explain the variability of the dependent variable.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Example: Simple Linear Regression}
    \begin{block}{Scenario}
        Predicting the price of a house based on its square footage.
    \end{block}
    \begin{block}{Dataset}
        \begin{itemize}
            \item Square Footage: [1500, 2000, 2500, 3000]
            \item Prices: [$300,000, $400,000, $500,000, $600,000]
        \end{itemize}
    \end{block}
    \begin{block}{Model Representation}
        \begin{equation}
        \text{Price} = m \cdot \text{Square Footage} + b
        \end{equation}
    \end{block}
    \begin{block}{Interpretation}
        \begin{itemize}
            \item The slope \(m\) indicates the price increase per additional square foot.
            \item The intercept \(b\) represents the base price of the house when square footage is zero.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Important Considerations in Regression}
    \begin{block}{Overfitting vs. Underfitting}
        \begin{itemize}
            \item \textbf{Overfitting}: Model fits the training data too well; poor performance on unseen data.
            \item \textbf{Underfitting}: Model too simple to capture the underlying trend.
        \end{itemize}
    \end{block}
    \begin{block}{Key Points to Remember}
        \begin{itemize}
            \item Supervised Learning is essential for training accurate predictive models.
            \item Regression is a critical technique for predicting continuous outcomes.
            \item Understanding types of regression and applications is crucial for effective data modeling.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion - Summary of Supervised Learning}
    \begin{block}{Key Concepts Recap}
        \begin{itemize}
            \item \textbf{Supervised Learning}: A type of machine learning that uses labeled data to learn mappings from inputs to outputs.
            \item \textbf{Regression}: A method for predicting continuous numerical outputs, modeling relationships between variables.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion - Types of Regression}
    \begin{block}{Major Types of Regression}
        \begin{enumerate}
            \item \textbf{Linear Regression}: Fits a straight line to data. 
                \begin{equation}
                    y = mx + b
                \end{equation}
                \textit{Example}: Predicting house prices based on square footage.
            \item \textbf{Polynomial Regression}: Fits a polynomial curve to data.
                \textit{Example}: Modeling plant growth over time may require a curve.
            \item \textbf{Ridge and Lasso Regression}: Add penalty terms to linear regression to prevent overfitting.
                \begin{equation}
                    \text{Ridge:} \quad ||y - X\beta||^2 + \alpha||\beta||^2
                \end{equation}
                \textit{Example}: Useful for high-dimensional datasets.
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion - Evaluation Metrics and Next Steps}
    \begin{block}{Evaluation Metrics}
        \begin{itemize}
            \item \textbf{Mean Absolute Error (MAE)}: Average of absolute errors.
            \item \textbf{Mean Squared Error (MSE)}: Average of squared errors; emphasizes larger errors.
            \item \textbf{R² Score}: Proportion of variance explained by the model (0 to 1).
        \end{itemize}
    \end{block}
    \begin{block}{Next Steps}
        \begin{itemize}
            \item \textbf{Practice}: Implement regression models using online datasets.
            \item \textbf{Explore}: Advanced topics like ensemble methods and neural networks.
            \item \textbf{Reflect}: Consider ethical implications of predictive modeling.
        \end{itemize}
    \end{block}
\end{frame}


\end{document}