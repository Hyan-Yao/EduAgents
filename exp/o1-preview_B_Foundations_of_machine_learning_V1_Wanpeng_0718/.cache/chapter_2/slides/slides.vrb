\frametitle{Key Concepts - Training & Evaluation}
    \begin{itemize}
        \item \textbf{Training Data vs. Test Data:}
        \begin{itemize}
            \item \textbf{Training Data:} The dataset used to train the model.
            \item \textbf{Test Data:} Separate data used to evaluate the model's performance after training.
        \end{itemize}

        \item \textbf{Model Evaluation Metrics:}
        \begin{itemize}
            \item \textbf{Accuracy:} The proportion of correct predictions made by the model.
            \item \textbf{Precision:} The ratio of true positive predictions to the sum of true positives and false positives.
            \item \textbf{Recall:} The ratio of true positive predictions to the sum of true positives and false negatives.
            \item \textbf{F1 Score:} The harmonic mean of precision and recall, useful when dealing with imbalanced datasets.
        \end{itemize}

        \item \textbf{Overfitting \& Underfitting:}
        \begin{itemize}
            \item \textbf{Overfitting:} The model learns the training data too well, leading to poor generalization.
            \item \textbf{Underfitting:} The model is too simple and fails to capture the underlying trend.
        \end{itemize}
        \item \textbf{Key Point:} Balancing the complexity of the model is crucial to ensure it generalizes well.
    \end{itemize}
