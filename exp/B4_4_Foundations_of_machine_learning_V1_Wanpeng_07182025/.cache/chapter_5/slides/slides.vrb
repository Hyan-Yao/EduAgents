\frametitle{Comparison of Clustering Methods - Criteria Table}

    \begin{table}
        \centering
        \begin{tabular}{|l|l|l|}
            \hline
            \textbf{Criteria} & \textbf{K-means Clustering} & \textbf{Hierarchical Clustering} \\
            \hline
            \textbf{Definition} & Partitions the dataset into K distinct clusters by minimizing variance. & Builds a tree (dendrogram) of clusters either by agglomerative or divisive methods. \\
            \hline
            \textbf{Advantages} &
            \begin{itemize}
                \item Fast and efficient for large datasets (O(n*k) complexity)
                \item Easy to implement and understand
                \item Works well with spherical clusters
            \end{itemize} &
            \begin{itemize}
                \item Provides a visual representation of data through a dendrogram.
                \item Does not require the number of clusters to be specified in advance.
                \item Can capture complex relationships between clusters.
            \end{itemize} \\
            \hline
            \textbf{Disadvantages} &
            \begin{itemize}
                \item Requires predefining the number of clusters (K)
                \item Sensitive to initial centroid placement and outliers
                \item Assumes clusters are convex and isotropic (spherical)
            \end{itemize} &
            \begin{itemize}
                \item Computationally expensive for large datasets (O(n^3) complexity).
                \item The choice of linkage method can affect results (e.g., single, complete).
                \item May lead to overfitting with small datasets due to various configurations.
            \end{itemize} \\
            \hline
        \end{tabular}
    \end{table}
