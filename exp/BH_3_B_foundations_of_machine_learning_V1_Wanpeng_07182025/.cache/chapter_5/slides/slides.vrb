\frametitle{Decision Trees}
    \begin{itemize}
        \item \textbf{Definition}: A decision tree is a flowchart-like structure where:
        \begin{itemize}
            \item Each internal node represents a decision based on an attribute,
            \item Each branch represents the outcome of that decision,
            \item Each leaf node represents a class label or predicted value.
        \end{itemize}

        \item \textbf{Process}: The tree is constructed by splitting the data into subsets based on feature values, using criteria like Gini impurity or entropy.

        \item \textbf{Example}: Decision tree for a weather dataset:
        \begin{itemize}
            \item \textbf{Node 1}: Is it raining?
            \begin{itemize}
                \item Yes: \textbf{Node 2}
                \begin{itemize}
                    \item \textbf{Node 2}: Is it windy?
                    \begin{itemize}
                        \item Yes: Play indoors
                        \item No: Play outside
                    \end{itemize}
                \end{itemize}
                \item No: Play outside
            \end{itemize}
        \end{itemize}
    \end{itemize}
