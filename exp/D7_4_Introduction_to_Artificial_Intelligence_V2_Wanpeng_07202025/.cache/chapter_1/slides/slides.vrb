\frametitle{Decision Making and Planning - Markov Decision Processes}
    \begin{block}{Markov Decision Processes (MDPs)}
        MDPs provide a mathematical framework for modeling decision-making in environments where outcomes are partly random and partly under the control of a decision-maker.
    \end{block}

    \begin{itemize}
        \item \textbf{States (S)}: All possible situations in which an agent can find itself.
        \item \textbf{Actions (A)}: Choices available to the agent in each state.
        \item \textbf{Transition Function (T)}:
            \begin{equation}
                T(s, a, s') = P(s' \mid s, a)
            \end{equation}
        \item \textbf{Rewards (R)}: Immediate return after transitioning from one state to another via an action.
        \item \textbf{Policy (Ï€)}: A strategy that defines the action to take in each state, which can be deterministic or stochastic.
    \end{itemize}
