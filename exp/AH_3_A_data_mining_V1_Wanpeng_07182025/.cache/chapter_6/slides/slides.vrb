\frametitle{Bagging Technique in Random Forests - Decision Trees & Voting Mechanism}
    \begin{itemize}
        \item For each bootstrapped dataset, train a distinct decision tree.
        \item Each tree may differ due to unique training data.
    \end{itemize}

    \begin{block}{Majority Voting Mechanism}
        \begin{itemize}
            \item Predictions aggregated from all trees.
            \item Classification:
            \begin{itemize}
                \item Final prediction is determined by majority vote.
                \item Example:
                \begin{itemize}
                    \item Tree 1: Class A, Tree 2: Class B, Tree 3: Class B,
                    \item Final prediction: Class B (2 vs 1).
                \end{itemize}
            \end{itemize}
            \item Regression:
            \begin{itemize}
                \item Predictions averaged for final value.
            \end{itemize}
        \end{itemize}

        \begin{equation}
        Y = \text{arg max}_{y} \bigg( \sum_{i=1}^{m} \mathbb{I}(h_i(X) = y) \bigg)
        \end{equation}
    \end{block}
