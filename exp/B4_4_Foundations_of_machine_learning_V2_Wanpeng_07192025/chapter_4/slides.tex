\documentclass[aspectratio=169]{beamer}

% Theme and Color Setup
\usetheme{Madrid}
\usecolortheme{whale}
\useinnertheme{rectangles}
\useoutertheme{miniframes}

% Additional Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}
\usepackage{hyperref}

% Custom Colors
\definecolor{myblue}{RGB}{31, 73, 125}
\definecolor{mygray}{RGB}{100, 100, 100}
\definecolor{mygreen}{RGB}{0, 128, 0}
\definecolor{myorange}{RGB}{230, 126, 34}
\definecolor{mycodebackground}{RGB}{245, 245, 245}

% Set Theme Colors
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=white, bg=myblue}
\setbeamercolor{title}{fg=myblue}
\setbeamercolor{section in toc}{fg=myblue}
\setbeamercolor{item projected}{fg=white, bg=myblue}
\setbeamercolor{block title}{bg=myblue!20, fg=myblue}
\setbeamercolor{block body}{bg=myblue!10}
\setbeamercolor{alerted text}{fg=myorange}

% Set Fonts
\setbeamerfont{title}{size=\Large, series=\bfseries}
\setbeamerfont{frametitle}{size=\large, series=\bfseries}
\setbeamerfont{caption}{size=\small}
\setbeamerfont{footnote}{size=\tiny}

% Custom Commands
\newcommand{\hilight}[1]{\colorbox{myorange!30}{#1}}
\newcommand{\concept}[1]{\textcolor{myblue}{\textbf{#1}}}
\newcommand{\separator}{\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}}

% Title Page Information
\title[Supervised Learning: Linear Regression]{Chapter 4: Supervised Learning: Linear Regression}
\author[Your Name]{Your Name}
\date{\today}

% Document Start
\begin{document}

\frame{\titlepage}

\begin{frame}[fragile]
    \frametitle{Introduction to Supervised Learning and Linear Regression}
    \begin{block}{What is Supervised Learning?}
        Supervised learning is a type of machine learning where the model is trained on labeled data. Each example in the training dataset includes both input features and the correct output.
    \end{block}
    \begin{itemize}
        \item \textbf{Labeled Data:} The training data consists of input-output pairs.
        \item \textbf{Model Training:} The model learns from the data during the training phase and evaluates performance using metrics on testing data.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{What is Linear Regression?}
    \begin{block}{Overview}
        Linear regression is one of the simplest and most widely used statistical techniques for predicting a continuous target variable based on one or more predictor variables. The model assumes a linear relationship between the inputs and the output.
    \end{block}
    \begin{itemize}
        \item \textbf{Dependent Variable (Y):} The outcome to predict (e.g., house price).
        \item \textbf{Independent Variable (X):} The feature(s) used for predictions (e.g., square footage).
    \end{itemize}
    \begin{equation}
        Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_n X_n + \epsilon
    \end{equation}
    Where:
    \begin{itemize}
        \item \( \beta_0 \): Intercept
        \item \( \beta_1, \beta_2, ..., \beta_n \): Coefficients of the independent variables
        \item \( \epsilon \): Error term
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Example of Linear Regression}
    \begin{block}{Model Example}
        Imagine we want to predict a student's exam score based on the number of hours studied. The linear regression model might look like this:
    \end{block}
    \begin{equation}
        \text{Score} = 50 + 10 \times \text{Hours Studied}
    \end{equation}
    In this model:
    \begin{itemize}
        \item The intercept is 50 (the score predicted when no hours are studied).
        \item The coefficient 10 indicates that for each additional hour studied, the score increases by 10 points.
    \end{itemize}
    \begin{block}{Key Points to Emphasize}
        \begin{enumerate}
            \item \textbf{Goal:} To estimate the parameters (\( \beta \) values) that minimize the difference between predicted values and actual values.
            \item \textbf{Assumptions:} Linear relationship, Independence of errors, Homoscedasticity, Normality of error terms.
            \item \textbf{Applications:} Predictive modeling in economics, health care, marketing, etc.
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Overview of Key Concepts in Linear Regression}
    \begin{block}{What is Linear Regression?}
        Linear regression is a supervised learning algorithm used for predicting a continuous target variable based on one or more predictor variables. It models the relationship between the dependent variable and independent variable(s) by fitting a linear equation to the observed data.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts of Linear Regression - Part 1}
    \begin{enumerate}
        \item \textbf{Dependent and Independent Variables:}
            \begin{itemize}
                \item \textbf{Dependent Variable (Y):} The outcome we intend to predict. Example: Price of a house.
                \item \textbf{Independent Variable (X):} The variable(s) used for prediction. Example: Size of the house in square feet.
            \end{itemize}

        \item \textbf{The Linear Equation:}
            \begin{equation}
            Y = b_0 + b_1X + \epsilon
            \end{equation}
            where:
            \begin{itemize}
                \item \(Y\) = Dependent variable
                \item \(b_0\) = Y-intercept
                \item \(b_1\) = Slope of the line
                \item \(\epsilon\) = Error term
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts of Linear Regression - Part 2}
    \begin{enumerate}
        \setcounter{enumi}{2}
        \item \textbf{Assumptions of Linear Regression:}
            \begin{itemize}
                \item Linearity: The relationship between predictors and the target variable is linear.
                \item Independence: Observations are independent of each other.
                \item Homoscedasticity: Constant variance of error terms.
                \item Normality: Residuals should be normally distributed.
            \end{itemize}

        \item \textbf{Fitting a Model:}
            \begin{itemize}
                \item The objective is to find the best-fitting line through the data points, minimizing the sum of squared differences (Least Squares Method).
            \end{itemize}

        \item \textbf{Evaluating Model Performance:}
            \begin{itemize}
                \item \textbf{R-Squared (\(R^2\)):} Measures the variance explained by the independent variables (range: 0 to 1).
                \item \textbf{Mean Squared Error (MSE):} Average of the squares of the errors.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Example in Linear Regression}
    \begin{block}{Example:}
        Consider a dataset of house prices and their sizes. A simple linear regression analysis might show that for each additional square foot, the price of the house increases by \$50 (this is the slope \(b_1\) of the regression line). 

        For instance, if a house is 1,200 square feet, the predicted price (\(Y\)) can be calculated as follows (assuming \(b_0 = 30,000\)):
        \begin{equation}
        Y = 30,000 + (50 \times 1200) = 30,000 + 60,000 = 90,000
        \end{equation}
        This means that a 1,200 square foot house is predicted to cost \$90,000.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Key Points}
    \begin{itemize}
        \item Linear regression is foundational for understanding relationships between variables.
        \item Proper evaluation and understanding of assumptions are critical for effective modeling.
        \item Visualizing results can enhance interpretation and model acceptance.
    \end{itemize}
    \begin{block}{Summary}
        This overview provides the foundational knowledge needed as we dive deeper into linear regression techniques and applications.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion - Summary}
    \begin{block}{Summary and Conclusion}
        In this chapter, we explored the fundamentals of \textbf{Linear Regression}, a vital supervised learning technique used for predicting numerical outcomes based on input features.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion - Key Concepts Recap}
    \begin{itemize}
        \item \textbf{Definition}: Models the relationship between a dependent variable and independent variables using a linear equation.
        \item \textbf{Equation}:
        \begin{equation}
        y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n + \epsilon
        \end{equation}
        \item \textbf{Assumptions}:
        \begin{itemize}
            \item Linearity
            \item Independence
            \item Homoscedasticity
            \item Normally distributed errors
        \end{itemize}
        \item \textbf{Evaluation Metrics}:
        \begin{itemize}
            \item Mean Absolute Error (MAE)
            \item Mean Squared Error (MSE)
            \item R-squared (\(R^2\))
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion - Example and Key Takeaways}
    \begin{block}{Example}
        For predicting a house's price based on size:
        \begin{equation}
        \text{Price} = 50000 + 150 \times \text{Size}
        \end{equation}
        This indicates that for each additional square foot, the price increases by $150.
    \end{block}

    \begin{block}{Key Takeaways}
        \begin{itemize}
            \item \textbf{Linear Regression} is essential for making predictions based on linear relationships.
            \item Understanding assumptions and evaluation is crucial.
            \item Sets the foundation for advanced supervised learning techniques.
        \end{itemize}
        Reflect on its applications across various domains for impactful decisions.
    \end{block}
\end{frame}


\end{document}