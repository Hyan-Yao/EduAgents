\frametitle{Best Practices for Hyperparameter Tuning}
    \begin{enumerate}
        \item \textbf{Grid Search}
        \begin{itemize}
            \item \textbf{Definition:} Systematically working through multiple combinations of hyperparameter values.
            \item \textbf{Example:} Tuning the `max_depth` and `min_samples_split` of a decision tree.
            \begin{lstlisting}[language=Python]
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier

param_grid = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}
grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
            \end{lstlisting}
        \end{itemize}

        \item \textbf{Random Search}
        \begin{itemize}
            \item \textbf{Definition:} Samples a few randomly chosen hyperparameter combinations instead of checking all values.
            \begin{lstlisting}[language=Python]
from sklearn.model_selection import RandomizedSearchCV

param_dist = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'n_estimators': [50, 100, 200]
}
random_search = RandomizedSearchCV(DecisionTreeClassifier(), param_dist, n_iter=10, cv=5)
random_search.fit(X_train, y_train)
best_params = random_search.best_params_
            \end{lstlisting}
        \end{itemize}
    \end{enumerate}
