\documentclass[aspectratio=169]{beamer}

% Theme and Color Setup
\usetheme{Madrid}
\usecolortheme{whale}
\useinnertheme{rectangles}
\useoutertheme{miniframes}

% Additional Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}
\usepackage{hyperref}

% Custom Colors
\definecolor{myblue}{RGB}{31, 73, 125}
\definecolor{mygray}{RGB}{100, 100, 100}
\definecolor{mygreen}{RGB}{0, 128, 0}
\definecolor{myorange}{RGB}{230, 126, 34}
\definecolor{mycodebackground}{RGB}{245, 245, 245}

% Set Theme Colors
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=white, bg=myblue}
\setbeamercolor{title}{fg=myblue}
\setbeamercolor{section in toc}{fg=myblue}
\setbeamercolor{item projected}{fg=white, bg=myblue}
\setbeamercolor{block title}{bg=myblue!20, fg=myblue}
\setbeamercolor{block body}{bg=myblue!10}
\setbeamercolor{alerted text}{fg=myorange}

% Set Fonts
\setbeamerfont{title}{size=\Large, series=\bfseries}
\setbeamerfont{frametitle}{size=\large, series=\bfseries}
\setbeamerfont{caption}{size=\small}
\setbeamerfont{footnote}{size=\tiny}

% Document Start
\begin{document}

\frame{\titlepage}

\begin{frame}[fragile]
    \frametitle{Introduction to Function Approximation}
    \begin{itemize}
        \item Overview of function approximation in reinforcement learning.
        \item Importance for generalization in complex environments.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{What is Function Approximation?}
    \begin{itemize}
        \item Function approximation creates a function closely matching a target function based on data points or experiences.
        \item In reinforcement learning, it helps agents generalize learning from known to unknown states, enhancing capabilities in complex environments.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance in Reinforcement Learning}
    \begin{enumerate}
        \item \textbf{State Space Complexity:} Environments may have vast or continuous state spaces; direct mappings are often impractical.
        \item \textbf{Generalization:} Estimates value of unvisited states based on similar visited states, improving decision-making.
        \item \textbf{Reducing Overfitting:} Function approximators like neural networks allow for generalization, improving performance on unseen data.
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Types of Function Approximators}
    \begin{itemize}
        \item \textbf{Linear Function Approximators:} 
        \begin{itemize}
            \item Simple models representing linear relationships.
            \item Example: \( V(s) = w_0 + w_1 \times s_1 + w_2 \times s_2 \).
        \end{itemize}
        \item \textbf{Non-Linear Function Approximators:} 
        \begin{itemize}
            \item More complex models like neural networks.
            \item Can represent non-linear relationships but require more data for training.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Q-Learning with Function Approximation}
    \begin{itemize}
        \item Instead of storing Q-values in a Q-table, use a neural network to approximate Q-values.
        \item This enables efficient learning from similar states.
    \end{itemize}
    \begin{block}{Example of a Simple Q-Network Structure}
        \begin{lstlisting}[language=Python]
import torch
import torch.nn as nn

class QNetwork(nn.Module):
    def __init__(self, input_size, output_size):
        super(QNetwork, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.fc2 = nn.Linear(64, output_size)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        return self.fc2(x)
        \end{lstlisting}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points to Emphasize}
    \begin{itemize}
        \item Function approximation is essential for learning in large or continuous state spaces.
        \item Enhances generalization from past experiences, aiding in predictions in unfamiliar situations.
        \item The choice of function approximator (linear vs. non-linear) is crucial as complexity increases.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion}
    \begin{itemize}
        \item Function approximation is fundamental in reinforcement learning.
        \item Enables smarter agents capable of navigating complex tasks by generalizing learning across states.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{Understanding Generalization - Part 1}
    \frametitle{What is Generalization in Machine Learning?}
    \begin{itemize}
        \item \textbf{Definition}: Generalization refers to the ability of a machine learning model to perform well on unseen data, beyond the specific examples it was trained on. It is the key measure of a model's effectiveness in real-world applications.
        \item \textbf{Purpose}: In reinforcement learning (RL), generalization enables agents to make decisions in environments that differ from those encountered during training, boosting their adaptability and performance across various tasks.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{Understanding Generalization - Part 2}
    \frametitle{How Generalization Applies to Reinforcement Learning}
    \begin{enumerate}
        \item \textbf{Goal of Reinforcement Learning}: The primary aim is to learn an optimal policy—the strategy used by an agent to determine its actions based on the current state to maximize cumulative rewards.
        \item \textbf{Challenge of Generalization}: As environments can have vast state and action spaces, training an agent through every possible scenario is impractical. Without effective generalization, the agent might perform well in training scenarios but fail in novel situations.
            \begin{block}{Example}
                A robot trained to navigate through one specific room may struggle to adapt to variations in layout or object placements unless it generalizes the learned navigation strategy.
            \end{block}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]{Understanding Generalization - Part 3}
    \frametitle{Key Points and Examples}
    \begin{itemize}
        \item \textbf{Bias-Variance Tradeoff}:
            \begin{itemize}
                \item \textbf{Bias}: Errors due to overly simplistic models that don’t capture the underlying patterns (underfitting).
                \item \textbf{Variance}: Errors due to overly complex models that fit noise in the training dataset (overfitting).
            \end{itemize}
        \item \textbf{Function Approximation}: Techniques like linear regression, neural networks, or decision trees help encapsulate relationships in data for efficient generalization, especially in high-dimensional and continuous state spaces.
    \end{itemize}
    
    \begin{block}{Examples of Generalization in RL}
        \begin{itemize}
            \item \textbf{Q-Learning with Function Approximation}: 
                \begin{equation}
                    Q(s, a) \approx w^T \phi(s, a)
                \end{equation}
                Where \(w\) are the weights learned during training, and \(\phi(s, a)\) symbolizes the feature representation of state-action pairs.
            \item \textbf{Policy Gradient Methods}: Employ stochastic policies that can generalize well across similar states through sampling.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Need for Function Approximation - Understanding Function Approximation in RL}
    \begin{block}{Definition}
        Function approximation is the process of estimating complex functions using simpler, manageable representations. In reinforcement learning, this is essential for mapping states and actions to values or policies, especially in environments with vast or continuous state spaces.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Need for Function Approximation - Why is Function Approximation Crucial?}
    \begin{enumerate}
        \item \textbf{High-Dimensional Spaces:}
        \begin{itemize}
            \item Real-world environments often have high-dimensional state spaces (e.g., images, sensor data).
            \item Exact methods (like tabular representation) become infeasible due to memory and computational constraints.
            \item Example: A self-driving car processes data from hundreds of sensors; approximating the value function is essential for real-time decisions.
        \end{itemize}
        
        \item \textbf{Generalization:}
        \begin{itemize}
            \item Function approximators enable models to generalize learned experiences to unseen states.
            \item This is critical for effective decision-making as agents encounter new situations not part of their training data.
            \item Example: If trained on driving in sunny weather, the car should still navigate effectively in rain by generalizing learned patterns.
        \end{itemize}
        
        \item \textbf{Sample Efficiency:}
        \begin{itemize}
            \item Using function approximation improves sample efficiency by reducing the need for exhaustive exploration.
            \item It allows the agent to leverage past experiences to make predictions about new states.
            \item Example: In games like chess or Go, approximating the value function helps an agent to predict outcomes with fewer board states explored.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Need for Function Approximation - Key Points and Illustrative Example}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item \textbf{Direct Mapping Limitation:} In high-dimensional spaces, representing every state-action pair explicitly is impractical.
            \item \textbf{Flexibility:} Function approximators (neural networks, linear functions) provide the flexibility to capture complex relationships.
            \item \textbf{Performance Improvement:} Effective function approximation can significantly enhance an RL agent's performance and decision-making capabilities.
        \end{itemize}
    \end{block}
    
    \begin{block}{Illustrative Example: Q-Learning with Function Approximation}
        \begin{itemize}
            \item Traditional Q-Learning stores Q-values for each state-action pair in a table; impractical for complex tasks.
            \item \textbf{Function Approximation:} replaces the Q-table with a function \( Q(s, a; \theta) \) parameterized by weights \( \theta \).
            \item The agent updates weights based on observed rewards:
            \begin{equation}
                \theta = \theta + \alpha \left( r + \gamma \max_{a'} Q(s', a'; \theta) - Q(s, a; \theta) \right) \nabla_{\theta} Q(s, a; \theta)
            \end{equation}
            Here, \( \alpha \) is the learning rate, \( \gamma \) is the discount factor, \( r \) is the reward, and \( s' \) is the next state.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Linear Function Approximation - Introduction}
    \begin{block}{Overview}
        Linear Function Approximation is a powerful technique used in various fields such as machine learning, statistics, and reinforcement learning (RL).
    \end{block}
    \begin{itemize}
        \item Generalizes learning in high-dimensional spaces
        \item Approximates complex functions using linear combinations of features
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Linear Function Approximation - Key Concepts}
    \begin{enumerate}
        \item \textbf{Function Approximation}:
        \begin{itemize}
            \item Estimate a function based on observed data points
            \item Simplify relationships using linear functions
        \end{itemize}
        
        \item \textbf{Linear Models}:
        \begin{equation}
        y = \mathbf{w}^T \mathbf{x} + b
        \end{equation}
        where:
        \begin{itemize}
            \item \( \mathbf{w} \) is the weight vector
            \item \( \mathbf{x} \) is the feature vector
            \item \( b \) is the bias term
        \end{itemize}
        
        \item \textbf{Feature Representation}:
        \begin{itemize}
            \item Choice of features significantly impacts performance
            \item Features may include raw or transformed data
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Linear Function Approximation - Applications}
    \begin{enumerate}
        \item \textbf{Reinforcement Learning (RL)}:
        \begin{itemize}
            \item Utilizes linear function approximation for value function estimation
            \begin{equation}
            V(s) = \theta_0 + \theta_1 \cdot f_1(s) + \theta_2 \cdot f_2(s)
            \end{equation}
        \end{itemize}
        
        \item \textbf{Predictive Modeling}:
        \begin{itemize}
            \item Used in regression tasks to predict outcomes based on input variables
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Conclusion}
    \begin{itemize}
        \item \textbf{Simplicity and Interpretability}:
            \begin{itemize}
                \item Easy to understand compared to complex models
            \end{itemize}
        \item \textbf{Scalability}:
            \begin{itemize}
                \item Efficient in handling high-dimensional data
            \end{itemize}
        \item \textbf{Limitations}:
            \begin{itemize}
                \item May not capture complex relationships adequately
                \item Non-linear relationships require more sophisticated techniques
            \end{itemize}
    \end{itemize}
    \begin{block}{Conclusion}
        Linear function approximation is a foundational tool in machine learning, enabling efficient modeling across various problems.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Mathematics of Linear Approximation}
    % Slide Overview
    Linear approximation involves modeling complex relationships through simpler linear functions, essential in machine learning and statistics. 
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Linear Approximation}
    \begin{block}{Definition}
        Linear approximation simplifies complex relationships into linear representations for easier computation and interpretation.
    \end{block}
    
    \begin{itemize}
        \item Key concept in machine learning and statistics.
        \item Facilitates analysis of data.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts of Linear Approximation}
    \begin{enumerate}
        \item \textbf{Linear Function Definition}:
        \begin{equation}
            y = mx + b
        \end{equation}
        \item \textbf{Multiple Features}:
        \begin{equation}
            y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n
        \end{equation}
        \item \textbf{Feature Representation}:
        \begin{itemize}
            \item Feature Scaling
            \item Polynomial Features
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Example: Predicting House Prices}
    \begin{block}{Model Example}
        Consider predicting house prices based on size and age:
        \begin{equation}
            \text{Price} = \beta_0 + \beta_1 (\text{Size}) + \beta_2 (\text{Age})
        \end{equation}
    \end{block}
    \begin{itemize}
        \item Larger houses may increase price (\(\beta_1 > 0\)).
        \item Older houses might decrease value (\(\beta_2 < 0\)).
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Limitations}
    \begin{itemize}
        \item \textbf{Simplicity}:
        \begin{itemize}
            \item Easy interpretation of relationships.
        \end{itemize}
        \item \textbf{Computational Efficiency}:
        \begin{itemize}
            \item Less intensive than non-linear models.
        \end{itemize}
        \item \textbf{Limitations}:
        \begin{itemize}
            \item Linear assumption may lead to underfitting in real-world datasets.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Formulae}
    \begin{block}{Cost Function - Mean Squared Error}
        \begin{equation}
            MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
        \end{equation}
        where:
        \begin{itemize}
            \item \(y_i\) = actual output
            \item \(\hat{y}_i\) = predicted output
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion}
    \begin{itemize}
        \item Mastering the mathematics of linear approximation is crucial for machine learning tasks.
        \item These principles lay the groundwork for exploring complex non-linear approximations.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Non-linear Function Approximation}
  \begin{block}{Overview}
    Non-linear function approximation is essential for modeling complex relationships in data that cannot be captured by linear methods. This slide explores key non-linear approximation techniques, highlighting the role of neural networks and additional approaches.
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Understanding Non-linearity}
  \begin{itemize}
    \item \textbf{Definition}: Non-linear functions do not have a constant rate of change; their output does not scale linearly with input changes.
    \item \textbf{Importance}: Many real-world phenomena (e.g., weather, financial markets, biological systems) exhibit non-linear behavior.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Common Non-linear Approximation Methods}
  \begin{enumerate}
    \item \textbf{Neural Networks}:
      \begin{itemize}
        \item A powerful approach using layers of interconnected "neurons."
        \item \textbf{Architecture}: Input, hidden, and output layers with non-linear activation functions (e.g., ReLU, sigmoid).
        \item \textbf{Example}: Predicting house prices using features like size, location, and number of rooms. 
      \end{itemize}

    \item \textbf{Polynomial Regression}:
      \begin{itemize}
        \item Extends linear regression by adding polynomial terms.
        \item \textbf{Formula}: 
        \[
        y = a_0 + a_1x + a_2x^2 + ... + a_nx^n
        \]
        \item \textbf{Example}: Fitting a curve to weather temperature data over time.
      \end{itemize}

    \item \textbf{Support Vector Machines (SVM)}:
      \begin{itemize}
        \item Non-linear classification using the kernel trick.
        \item \textbf{Example}: Classifying images where linear boundaries are insufficient.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Activation Functions in Neural Networks}
  \begin{itemize}
    \item \textbf{Role}: Introduce non-linearity to the model, allowing learning of complex patterns.
    \item \textbf{Common Functions}:
      \begin{itemize}
        \item \textbf{ReLU}: \( f(x) = \max(0, x) \)
        \item \textbf{Sigmoid}: \( f(x) = \frac{1}{1 + e^{-x}} \)
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Performance and Generalization}
  \begin{itemize}
    \item Non-linear models capture dependencies in complex datasets but risk:
    \begin{itemize}
      \item \textbf{Overfitting}: Requires careful management of model complexity.
      \item Use techniques like cross-validation to ensure good generalization.
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Conclusion}
  Non-linear function approximation expands the capabilities of predictive modeling and is instrumental in applications from finance to healthcare. Understanding these methods lays the groundwork for exploring advanced topics, such as deep learning.
\end{frame}

\begin{frame}[fragile]
  \frametitle{Code Snippet Example}
  \begin{lstlisting}[language=Python]
from keras.models import Sequential
from keras.layers import Dense

# Create a simple feedforward neural network
model = Sequential()
model.add(Dense(10, input_dim=5, activation='relu'))  # Hidden Layer
model.add(Dense(1, activation='sigmoid'))              # Output Layer

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
  \end{lstlisting}
  \begin{block}{Note}
    In this code, we create a neural network with a single hidden layer that uses the ReLU activation function, often effective for non-linear approximation tasks.
  \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Deep Learning and Function Approximation - Overview}
    \begin{block}{What is Function Approximation?}
        Function approximation is a mathematical strategy used to model complex functions based on discrete data points. In Reinforcement Learning (RL), it allows agents to estimate value functions or policies when the state space is too large to manage directly.
    \end{block}
    
    \begin{block}{The Role of Deep Learning}
        Deep learning revolutionizes function approximation by:
        \begin{itemize}
            \item \textbf{Handling Non-Linearity:} Deep neural networks can model highly non-linear relationships between inputs and outputs.
            \item \textbf{Learning Hierarchical Features:} Networks learn to represent data across multiple levels of abstraction by stacking layers.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Deep Learning Advantages in Function Approximation}
    \begin{enumerate}
        \item \textbf{Scalability:} Models can scale effectively with vast amounts of data, learning complex patterns without manual feature engineering.
        \item \textbf{Flexibility:} Deep learning approximates any continuous function, supported by the universal approximation theorem.
        \item \textbf{Generalization:} Techniques like dropout and regularization enable models to generalize well to unseen data, crucial in RL.
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Practical Example: Deep Q-Networks (DQN)}
    \begin{block}{DQN Overview}
        DQN combines Q-learning with deep learning:
        \begin{itemize}
            \item \textbf{Q-Learning Recap:} A value-based method where an agent learns the value of actions in states to maximize cumulative rewards.
            \item \textbf{Neural Network Implementation:} A neural network predicts Q-values, allowing tackling environments with large or continuous state spaces.
        \end{itemize}
    \end{block}
    
    \begin{equation}
        Q(s, a; \theta)
    \end{equation}
    where \( \theta \) are the parameters (weights) of the neural network.

    \begin{block}{Visualization of Deep Learning Architecture}
        - Input layer: Represents the state \( s \).
        - Hidden layers: Learn features and relationships.
        - Output layer: Provides Q-values for each possible action.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item Deep learning enhances RL agents' ability to navigate complex environments by efficiently approximating functions.
            \item Neurons and layers of the network capture intricate patterns and relationships.
            \item DQNs highlight practical applications of deep learning function approximation in actionable RL scenarios.
        \end{itemize}
    \end{block}
    
    Deep learning transforms function approximation in reinforcement learning, enabling the development of more robust, scalable, and generalizable models for advanced AI solutions.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Function Approximation Techniques}
    \begin{block}{Introduction}
        Function approximation is essential in reinforcement learning (RL) when dealing with large or continuous state spaces. These techniques enable agents to generalize from limited experiences to broader situations, improving learning efficiency.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Comparison of Function Approximation Techniques - Part 1}
    \begin{enumerate}
        \item \textbf{Value Function Approximation}
        \begin{itemize}
            \item \textbf{Description}: Estimates the value of states or state-action pairs.
            \item \textbf{Examples}:
            \begin{itemize}
                \item \textit{Linear Function Approximation}:
                \begin{equation}
                    V(s) = w_1 f_1(s) + w_2 f_2(s) + \ldots + w_n f_n(s)
                \end{equation}
                \begin{itemize}
                    \item \textbf{Pros}: Simple and interpretable; quick to compute.
                    \item \textbf{Cons}: Limited expressiveness, may underfit complex environments.
                \end{itemize}
                
                \item \textit{Non-Linear Function Approximation} (e.g., Neural Networks):
                \begin{itemize}
                    \item \textbf{Pros}: Highly flexible; can model complex value functions.
                    \item \textbf{Cons}: Requires more computational resources; risk of overfitting.
                \end{itemize}
            \end{itemize}
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Comparison of Function Approximation Techniques - Part 2}
    \begin{enumerate}
        \setcounter{enumi}{1}
        \item \textbf{Policy Approximation}
        \begin{itemize}
            \item \textbf{Description}: Directly approximates the policy that maps states to actions.
            \item \textbf{Examples}:
            \begin{itemize}
                \item \textit{Deterministic Policies}: \( \pi(s) = w^T \phi(s) \)
                \item \textit{Stochastic Policies}: Models probability distributions over actions.
            \end{itemize}
            \item \textbf{Pros}: More stable and responsive outcomes.
            \item \textbf{Cons}: Challenging to optimize due to non-convexity.
        \end{itemize}
        \item \textbf{Model-Based Approaches}
        \begin{itemize}
            \item \textbf{Description}: Constructs a model of the environment dynamics.
            \item \textbf{Pros}: More sample efficient; can leverage planning.
            \item \textbf{Cons}: Model inaccuracies can lead to poor performance.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Bias-Variance Tradeoff}
    \begin{block}{Understanding the Bias-Variance Tradeoff}
        The Bias-Variance Tradeoff is a fundamental concept in statistical learning, illustrating the balance between two sources of error that affect model performance, particularly in function approximation and generalization.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts}
    \begin{enumerate}
        \item \textbf{Bias}
        \begin{itemize}
            \item \textbf{Definition}: Error introduced by approximating a complex real-world problem with a simplified model.
            \item \textbf{Characteristics}: High bias can lead to underfitting.
            \item \textbf{Example}: A linear model fitting a complex, nonlinear dataset leads to significant deviation from the actual trend.
        \end{itemize}

        \item \textbf{Variance}
        \begin{itemize}
            \item \textbf{Definition}: The model's sensitivity to fluctuations in the training dataset.
            \item \textbf{Characteristics}: High variance can lead to overfitting.
            \item \textbf{Example}: A complex model fitting training data extremely well but failing to generalize to new data.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{The Tradeoff and Key Points}
    \begin{block}{The Tradeoff}
        As model complexity increases:
        \begin{itemize}
            \item Bias decreases.
            \item Variance increases.
        \end{itemize}
        The goal is to find a balance where both bias and variance are minimized.
    \end{block}

    \begin{itemize}
        \item \textbf{Underfitting vs Overfitting}: Achieve optimal generalization.
        \item \textbf{Model Selection}: Use the tradeoff for selecting the appropriate model based on data complexity.
        \item \textbf{Regularization Techniques}: Methods like Lasso, Ridge regression, and dropout help manage overfitting.
    \end{itemize}

    \begin{block}{Practical Application}
        Monitor bias and variance in function approximation for reinforcement learning, using techniques such as cross-validation.
    \end{block}

    \begin{block}{Conclusion}
        Mastering the bias-variance tradeoff is crucial for effective function approximation.
    \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Key Algorithms Utilizing Function Approximation}
  \begin{block}{Overview}
    Function approximation is crucial in reinforcement learning (RL), allowing agents to generalize across states and actions in complex environments.
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Function Approximation in Reinforcement Learning}
  \begin{itemize}
    \item Function approximation estimates value functions or policies using parametric models (e.g., neural networks).
    \item Essential in environments with large or continuous state spaces where maintaining a lookup table is impractical.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Notable Algorithms in Function Approximation}
  \begin{enumerate}
    \item \textbf{Deep Q-Networks (DQN)}
      \begin{itemize}
        \item Combines Q-learning with deep learning.
        \item Uses a neural network to approximate the action-value function \( Q(s, a; \theta) \).
        \item Key Features:
          \begin{itemize}
            \item Experience Replay
            \item Target Network
          \end{itemize}
        \item Q-learning update rule:
        \begin{equation}
          Q(s_t, a_t) \leftarrow Q(s_t, a_t) + \alpha \left[ r_t + \gamma \max_{a'}Q(s_{t+1}, a'; \theta^-) - Q(s_t, a_t) \right]
        \end{equation}
      \end{itemize}

    \item \textbf{Policy Gradient Methods}
      \begin{itemize}
        \item Directly parameterize the policy \( \pi(a|s; \theta) \).
        \item Example: REINFORCE algorithm uses Monte Carlo methods for gradients.
      \end{itemize}
    
    \item \textbf{Actor-Critic Methods}
      \begin{itemize}
        \item Combines policy-based and value-based methods with distinct approximators.
        \item Example: A3C (Asynchronous Actor-Critic) explores concurrently.
      \end{itemize}

    \item \textbf{TRPO and PPO}
      \begin{itemize}
        \item Advanced techniques for reliable policy updates.
        \item Use surrogate objectives to maintain updates within a “trust region”.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Key Points and Conclusion}
  \begin{block}{Key Points}
    \begin{itemize}
      \item Function approximation enables learning in vast environments.
      \item Enhances learning efficiency but poses challenges like generalization errors.
      \item Algorithms like DQN have shown superior performance in complex tasks (e.g., Atari games).
    \end{itemize}
  \end{block}
  
  \begin{block}{Conclusion}
    Understanding these algorithms is crucial for effectively applying function approximation in reinforcement learning. This helps create scalable solutions across diverse applications from robotics to gaming.
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Evaluation of Function Approximation Methods}
  \begin{block}{Introduction}
    Function approximation is crucial in reinforcement learning (RL) to generalize from limited experiences. Evaluating these methods ensures effective model performance during training and real-world deployment.
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Criteria for Evaluation}
  \begin{enumerate}
    \item \textbf{Accuracy}
      \begin{itemize}
        \item Measures closeness of approximated function to true function.
        \item Metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE).
        \item Example:
        \begin{equation}
          \text{MSE} = \frac{1}{n} \sum_{i=1}^n (f(x_i) - \hat{f}(x_i))^2
        \end{equation}
      \end{itemize}
      
    \item \textbf{Generalization}
      \begin{itemize}
        \item Model's ability to perform well on unseen data.
        \item Assessed using cross-validation techniques.
      \end{itemize}

    \item \textbf{Computational Efficiency}
      \begin{itemize}
        \item Refers to runtime and resource consumption.
        \item Consider training time, memory usage, and inference speed.
      \end{itemize}

    \item \textbf{Robustness}
      \begin{itemize}
        \item Stability of performance under varying conditions.
        \item Techniques: Stress testing with noise in input data.
      \end{itemize}

    \item \textbf{Model Complexity}
      \begin{itemize}
        \item Evaluates complexity in terms of parameters and structure.
        \item Trade-offs: More complex models may lead to overfitting.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Methods for Evaluation}
  \begin{itemize}
    \item \textbf{Cross-Validation}
      \begin{itemize}
        \item Dataset split into training and validation sets multiple times.
        \item Example: \textit{k-fold} cross-validation, using one subset for validation each time.
      \end{itemize}
    
    \item \textbf{Learning Curves}
      \begin{itemize}
        \item Graphs of training and validation error versus the number of training examples.
        \item Visual tool to assess overfitting or underfitting.
      \end{itemize}
      
    \item \textbf{Performance Metrics}
      \begin{itemize}
        \item Additional metrics include R-squared, precision, recall, and F1-score for classification tasks.
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Key Points and Conclusion}
  \begin{block}{Key Points}
    \begin{itemize}
      \item Effectiveness of function approximation is assessed using a combination of the outlined criteria.
      \item Balance between model complexity and generalization to avoid overfitting and underfitting.
      \item Multiple evaluation techniques offer a clearer picture of model performance and robustness.
    \end{itemize}
  \end{block}
  
  \begin{block}{Conclusion}
    Evaluating function approximation methods is vital for robust, efficient, and accurate RL systems. Applying the outlined criteria ensures models perform well in both controlled and real-world environments.
  \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Practical Applications}
    \begin{block}{Understanding Function Approximation}
        Function approximation is a vital concept in machine learning, where we model complex relationships using simpler functions. 
        These approximations can be categorized into two main types:
        \begin{itemize}
            \item \textbf{Linear Approximations}
            \item \textbf{Non-Linear Approximations}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Linear Approximations}
    \begin{block}{Definition}
        Linear models assume a straight-line relationship between input variables and outputs. They are particularly useful when the relationship is roughly linear.
    \end{block}
    
    \begin{block}{Example Case Study: Housing Price Prediction}
        \begin{itemize}
            \item In real estate, the price of a house can often be estimated using linear regression, considering inputs like size, number of bedrooms, and location.
            \item \textbf{Model}:
            \begin{equation}
                Price = w_1 \cdot Size + w_2 \cdot Bedrooms + b
            \end{equation}
            \item Here, $w_1$ and $w_2$ are weights learned during training, and $b$ is the bias term.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Non-Linear Approximations}
    \begin{block}{Definition}
        Non-linear models allow for more complex relationships, utilizing techniques such as polynomial regression, neural networks, or decision trees.
    \end{block}
    
    \begin{block}{Example Case Study: Image Recognition}
        \begin{itemize}
            \item Distinguishing between objects in images usually requires non-linear models. 
            \item Deep learning, which employs neural networks, excels at pattern recognition crucial for identifying features like faces or animals.
            \item \textbf{Activation Function Example:} 
            \begin{equation}
                f(x) = \frac{1}{1 + e^{-x}} \quad \text{(Sigmoid Function)}
            \end{equation}
        \end{itemize}
    \end{block}
    
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item \textbf{Flexibility:} Non-linear models can fit more complex data but require more data and computation.
            \item \textbf{Usage of Linear Models:} Ideal for interpretability in limited data scenarios.
            \item \textbf{Trade-offs:} Choosing between model types involves considering accuracy, interpretability, and computational efficiency.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Challenges and Limitations - Introduction}
  \begin{block}{Overview}
    Function approximation is essential in reinforcement learning (RL), allowing agents to generalize from observed to unobserved states. However, several challenges and limitations must be addressed to effectively apply these techniques.
  \end{block}

  \begin{itemize}
    \item Importance of function approximation in RL
    \item Necessity of understanding challenges for successful application
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Challenges and Limitations - Key Challenges}
  
  \begin{enumerate}
    \item \textbf{Overfitting}
      \begin{itemize}
        \item Definition: Capturing noise instead of patterns.
        \item Example: Poor generalization due to training on narrow states.
        \item Mitigation: Cross-validation, regularization, simpler models.
      \end{itemize}
    
    \item \textbf{Approximation Bias}
      \begin{itemize}
        \item Definition: Chosen function not representing true value.
        \item Example: Linear models oversimplifying complex dynamics.
        \item Mitigation: Careful selection of model complexity.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Challenges and Limitations - Further Challenges}

  \begin{enumerate}
    \setcounter{enumi}{2}
    \item \textbf{Sample Inefficiency}
      \begin{itemize}
        \item Definition: Need for extensive samples for effective learning.
        \item Example: Delayed feedback in sparse reward environments.
        \item Mitigation: Utilizing experience replay.
      \end{itemize}

    \item \textbf{Function Instability}
      \begin{itemize}
        \item Definition: Unstable dynamics with non-linear models.
        \item Example: Training oscillations from large updates.
        \item Mitigation: Target networks, gradual updates.
      \end{itemize}

    \item \textbf{Curse of Dimensionality}
      \begin{itemize}
        \item Definition: Exponential growth of required data with state dimensions.
        \item Example: Sparse data leading to inaccuracies.
        \item Mitigation: State-space reduction techniques like PCA.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Future Directions in Function Approximation - Overview}
  \begin{block}{Emerging Trends}
    As we look to the future of function approximation in reinforcement learning, several promising trends and research directions are emerging:
    \begin{itemize}
      \item Advanced Neural Network Architectures
      \item Transfer Learning and Adaptation
      \item Meta-Learning
      \item Uncertainty Estimation
      \item Integration of Symbolic Reasoning
      \item Improved Exploration Strategies
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Future Directions in Function Approximation - Details}
  \begin{enumerate}
    \item \textbf{Advanced Neural Network Architectures}
      \begin{itemize}
        \item Explore novel architectures like Graph Neural Networks (GNNs) and Transformers.
        \item \textit{Example}: GNNs can represent complex environments, enhancing state and action representations.
      \end{itemize}
    
    \item \textbf{Transfer Learning and Adaptation}
      \begin{itemize}
        \item Knowledge transfer helps models generalize better with less data.
        \item \textit{Example}: Training in simulations before applying to real-world scenarios.
      \end{itemize}

    \item \textbf{Meta-Learning}
      \begin{itemize}
        \item Focus on algorithms that adapt quickly to new tasks.
        \item \textit{Example}: A model applying knowledge from one game to another using few examples.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Future Directions in Function Approximation - Continued}
  \begin{enumerate}[resume]
    \item \textbf{Uncertainty Estimation}
      \begin{itemize}
        \item Addressing prediction uncertainty enhances decision-making.
        \item \textit{Key Point}: Important in risk-sensitive environments like healthcare and finance.
      \end{itemize}

    \item \textbf{Integration of Symbolic Reasoning}
      \begin{itemize}
        \item Bridging neural networks with symbolic AI improves logic-based learning.
        \item \textit{Example}: Combining deep learning with symbolic methods for better causal understanding.
      \end{itemize}

    \item \textbf{Improved Exploration Strategies}
      \begin{itemize}
        \item Focus on exploration techniques that encourage agents to explore unfamiliar states.
        \item \textit{Key Point}: Balancing exploration and exploitation enhances learning efficacy.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Future Directions in Function Approximation - Conclusion}
  \begin{block}{Summary}
    \begin{itemize}
      \item New architectures can enhance representation capabilities.
      \item Techniques like transfer learning and meta-learning promote rapid adaptation.
      \item Uncertainty estimation aids in critical decision-making.
      \item Symbolic reasoning strengthens understanding in AI.
      \item Improved exploration strategies are essential for robust learning agents.
    \end{itemize}
  \end{block}
  \begin{block}{Conclusion}
    The evolution of function approximation techniques will revolutionize diverse AI applications, enhancing efficiency, adaptability, and intelligence.
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Code Snippet for Transfer Learning}
  \begin{lstlisting}[language=Python]
# Importing required libraries
import torch
import torchvision.models as models

# Load a pre-trained model (e.g., ResNet) for transfer learning
model = models.resnet18(pretrained=True)

# Freeze the early layers
for param in model.parameters():
    param.requires_grad = False

# Replace the last layer for new task
num_features = model.fc.in_features
model.fc = torch.nn.Linear(num_features, num_classes)  # Customize for new number of classes
  \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Summary and Key Takeaways: Function Approximation and Generalization in Reinforcement Learning}
    \begin{block}{Key Concepts Recap}
        \begin{itemize}
            \item \textbf{Function Approximation}: A method crucial for managing large state/action spaces by using parameterized functions instead of explicit representation.
            \item \textbf{Generalization}: Enables models to predict on unseen data, vital for diverse environments.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Relevance and Techniques}
    \begin{block}{Relevance to Reinforcement Learning}
        \begin{itemize}
            \item \textbf{Handling Complexity}: Function approximation helps agents learn useful representations, facilitating scalability.
            \item \textbf{Bias-Variance Tradeoff}: Balancing model complexity is essential; too complex can lead to overfitting, too simple may underfit.
        \end{itemize}
    \end{block}
    
    \begin{block}{Important Techniques}
        \begin{itemize}
            \item \textbf{Linear Function Approximators}: Effective for simpler tasks.
            \item \textbf{Nonlinear Function Approximators (Neural Networks)}: Necessary for capturing complex patterns; require careful tuning.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Illustrative Example and Key Points}
    \begin{block}{Illustrative Code Snippet}
        \begin{lstlisting}[language=Python]
import numpy as np

# Example state-action features
def feature_extractor(state, action):
    return np.array([1, state, action])  # Feature vector [1, state, action]

# Linear Q-value approximation
def q_value(state, action, weights):
    features = feature_extractor(state, action)
    return np.dot(weights, features)

# Example usage
weights = np.array([0.1, 0.5, -0.3])  # Sample weights
state = 2
action = 1
q_val = q_value(state, action, weights)
print(f"Q-value for state {state} and action {action}: {q_val}")
        \end{lstlisting}
    \end{block}

    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item \textbf{Need for Approximation}: Essential for RL to tackle real-world problems effectively.
            \item \textbf{Importance of Generalization}: Agent strategies must apply to new scenarios.
            \item \textbf{Continuous Development}: Advances in techniques enhance RL capabilities.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Q\&A Session - Overview}
  \begin{block}{Overview}
    In this Q\&A session, we will address your questions and clarify any concepts related to function approximation and generalization in reinforcement learning.
    This interactive discussion aims to deepen your understanding and resolve any uncertainties that may have arisen during the chapter.
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Q\&A Session - Key Concepts to Recall}
  \begin{enumerate}
    \item \textbf{Function Approximation}
    \begin{itemize}
      \item A method used to estimate complex functions when precise models are impractical.
      \item Essential for representing value functions or policies in high-dimensional state spaces.
    \end{itemize}
    \textbf{Example:} Approximating the value function in a game using a neural network that predicts future rewards.

    \item \textbf{Generalization}
    \begin{itemize}
      \item The ability of a model to perform well on unseen data.
      \item Critical as models should handle actions not explicitly encountered during training.
    \end{itemize}
    \textbf{Example:} A robot adapting to new, similar rooms without extensive retraining.
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Q\&A Session - Key Points to Emphasize}
  \begin{itemize}
    \item \textbf{Balancing Bias and Variance}
      \begin{itemize}
        \item Overfitting: Captures noise, leading to high variance.
        \item Underfitting: Overly simplistic models lead to high bias.
      \end{itemize}

    \item \textbf{Importance of Exploration}
      \begin{itemize}
        \item Generalization relies on a structured exploration strategy.
        \item Diverse training data improves model generalization.
      \end{itemize}

    \item \textbf{Transfer Learning}
      \begin{itemize}
        \item Leveraging knowledge from one task to enhance performance on related tasks.
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Q\&A Session - Formulas and Questions}
  \begin{block}{Formulas}
    \textbf{Mean Squared Error (MSE)}:
    \begin{equation}
      \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
    \end{equation}

    \textbf{Regularization Techniques}:
    \begin{equation}
      \text{Loss}_{\text{regularized}} = \text{MSE} + \lambda \sum_{j=1}^{m} w_j^2
    \end{equation}
    where \(\lambda\) is the regularization parameter.
  \end{block}

  \begin{block}{Questions to Consider}
    \begin{itemize}
      \item What challenges have you faced while implementing function approximation?
      \item How have generalization issues impacted your projects or homework?
    \end{itemize}
  \end{block}
\end{frame}


\end{document}