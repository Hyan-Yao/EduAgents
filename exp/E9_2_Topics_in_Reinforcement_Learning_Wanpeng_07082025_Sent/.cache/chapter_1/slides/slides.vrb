\frametitle{Agents and Environments - Environments and Interaction}
    \begin{block}{2. What are Environments?}
        \begin{itemize}
            \item \textbf{Definition}: The environment encompasses everything the agent interacts with and provides context for the agent's operations.
            \item \textbf{Key Characteristics}:
                \begin{itemize}
                    \item \textbf{State Representation}: Describes all possible scenarios in the environment.
                    \item \textbf{Response to Actions}: Modifies its state based on agent actions and provides feedback (reward).
                \end{itemize}
            \item \textbf{Example}: The layout of the room for the robot vacuum cleaner, including furniture and dirt.
        \end{itemize}
    \end{block}
\
    \begin{block}{3. The Interaction Between Agents and Environments}
        \begin{itemize}
            \item \textbf{Feedback Loop}:
                \begin{enumerate}
                    \item Agent perceives environment's state (S).
                    \item Agent selects action (A) based on policy.
                    \item Environment responds with new state (S') and provides a reward (R).
                \end{enumerate}
            \item \textbf{Equation}:
            \begin{equation}
                S_{t+1} = f(S_t, A_t) \quad \text{and} \quad R_t = g(S_t, A_t)
            \end{equation}
            \text{Where:}
            \begin{itemize}
                \item \( S_t \): state at time \( t \)
                \item \( A_t \): action taken at time \( t \)
                \item \( S_{t+1} \): new state after action
                \item \( R_t \): reward received after taking action
            \end{itemize}
        \end{block}
