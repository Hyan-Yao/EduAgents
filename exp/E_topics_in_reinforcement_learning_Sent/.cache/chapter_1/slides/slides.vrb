\frametitle{Formula: The Bellman Equation}
    A common framework in RL is the \textbf{Bellman Equation}, which expresses the relationship between the value of a state and the values of its successor states:
    \begin{equation}
        V(s) = R(s) + \gamma \sum P(s'|s,a)V(s')
    \end{equation}
    Where:
    \begin{itemize}
        \item \( V(s) \) = Value of state \( s \).
        \item \( R(s) \) = Immediate reward.
        \item \( \gamma \) = Discount factor (0 \leq \gamma < 1).
        \item \( P(s'|s,a) \) = Transition probability to the next state \( s' \) given state \( s \) and action \( a \).
    \end{itemize}
