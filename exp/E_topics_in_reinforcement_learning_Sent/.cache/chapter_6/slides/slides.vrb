\frametitle{Future Directions in Policy Gradients - Formula Highlight}
    \begin{block}{Policy Gradient Theorem}
        The Policy Gradient Theorem provides the foundation for policy optimization:
        \begin{equation}
            \nabla J(\theta) = \mathbb{E}_{\tau \sim \pi_{\theta}} \left[ \nabla \log \pi_{\theta}(a | s) \cdot Q^{\pi}(s, a) \right]
        \end{equation}
        This equation underscores the core of policy optimization and guides future implementations of policy gradient methods.
    \end{block}
