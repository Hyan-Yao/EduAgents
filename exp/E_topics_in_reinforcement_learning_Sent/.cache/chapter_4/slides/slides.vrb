\frametitle{Q-Learning Update Rule}
    The core of Q-learning is the Q-value update rule, defined mathematically as:

    \begin{equation}
        Q(s, a) \leftarrow Q(s, a) + \alpha \left( r + \gamma \max_{a'} Q(s', a') - Q(s, a) \right)
    \end{equation}

    Where:
    \begin{itemize}
        \item \( Q(s, a) \) = Current Q-value for action \( a \) at state \( s \)
        \item \( \alpha \) = Learning rate (0 < \( \alpha \) ≤ 1)
        \item \( r \) = Reward received after moving to the next state
        \item \( \gamma \) = Discount factor (0 ≤ \( \gamma \) < 1)
        \item \( s' \) = New state after action \( a \) is taken
        \item \( a' \) = Possible next actions from the new state
    \end{itemize}
