\frametitle{How TD Learning Works}
    \begin{enumerate}
        \item \textbf{Value Estimation}
        \begin{equation}
        V(s) \gets V(s) + \alpha \left( R + \gamma V(s') - V(s) \right)
        \end{equation}
        where:
        \begin{itemize}
            \item $V(s)$: Estimated value of the current state $s$
            \item $R$: Reward received after taking action
            \item $\gamma$: Discount factor (0 ≤ $\gamma$ < 1)
            \item $\alpha$: Learning rate (0 < $\alpha$ ≤ 1)
        \end{itemize}

        \item \textbf{Learning from Experience}: Continuously updates value estimates through various episodes.
        \item \textbf{Convergence}: With sufficient exploration, TD Learning converges to the optimal value function.
    \end{enumerate}
