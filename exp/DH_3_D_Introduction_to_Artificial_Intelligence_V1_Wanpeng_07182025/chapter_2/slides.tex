\documentclass[aspectratio=169]{beamer}

% Theme and Color Setup
\usetheme{Madrid}
\usecolortheme{whale}
\useinnertheme{rectangles}
\useoutertheme{miniframes}

% Additional Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}
\usepackage{hyperref}

% Custom Colors
\definecolor{myblue}{RGB}{31, 73, 125}
\definecolor{mygray}{RGB}{100, 100, 100}
\definecolor{mygreen}{RGB}{0, 128, 0}
\definecolor{myorange}{RGB}{230, 126, 34}
\definecolor{mycodebackground}{RGB}{245, 245, 245}

% Set Theme Colors
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=white, bg=myblue}
\setbeamercolor{title}{fg=myblue}
\setbeamercolor{section in toc}{fg=myblue}
\setbeamercolor{item projected}{fg=white, bg=myblue}
\setbeamercolor{block title}{bg=myblue!20, fg=myblue}
\setbeamercolor{block body}{bg=myblue!10}
\setbeamercolor{alerted text}{fg=myorange}

% Set Fonts
\setbeamerfont{title}{size=\Large, series=\bfseries}
\setbeamerfont{frametitle}{size=\large, series=\bfseries}
\setbeamerfont{caption}{size=\small}
\setbeamerfont{footnote}{size=\tiny}

% Footer and Navigation Setup
\setbeamertemplate{footline}{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
    \usebeamerfont{author in head/foot}\insertshortauthor
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.5\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
    \usebeamerfont{title in head/foot}\insertshorttitle
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.2\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}%
    \usebeamerfont{date in head/foot}
    \insertframenumber{} / \inserttotalframenumber
  \end{beamercolorbox}}%
  \vskip0pt%
}

% Turn off navigation symbols
\setbeamertemplate{navigation symbols}{}

% Title Page Information
\title[Machine Learning Basics]{Chapter 2: Core Concepts: Machine Learning Basics}
\author[J. Smith]{John Smith, Ph.D.}
\institute[University Name]{
  Department of Computer Science\\
  University Name\\
  \vspace{0.3cm}
  Email: email@university.edu\\
  Website: www.university.edu
}
\date{\today}

% Document Start
\begin{document}

\frame{\titlepage}

\begin{frame}[fragile]
    \frametitle{Introduction to Machine Learning - Overview}
    \begin{block}{What is Machine Learning?}
        Machine Learning (ML) is a branch of artificial intelligence (AI) that empowers systems to learn from data, identify patterns, and make decisions without explicit programming.
    \end{block}
    \begin{block}{Significance of ML}
        \begin{itemize}
            \item \textbf{Data-Driven Decisions:} ML allows organizations to harness vast amounts of data to inform choices and optimize processes.
            \item \textbf{Automation:} By automating routine tasks, ML saves time and increases efficiency.
            \item \textbf{Personalization:} Enhances user experiences through personalized recommendations based on individual behaviors and preferences.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Introduction to Machine Learning - Goals of This Chapter}
    \begin{enumerate}
        \item \textbf{Define Key Concepts:} Clarify essential terms related to ML, such as algorithms, training, data sets, and prediction.
        \item \textbf{Explore Algorithm Types:} Gain insight into different ML algorithms, including supervised and unsupervised learning, and their applications.
        \item \textbf{Understand the Learning Process:} Focus on how models are trained and evaluated to provide a foundation for grasping more complex methodologies.
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Introduction to Machine Learning - Key Points and Example}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item \textbf{Subset of AI:} Machine Learning is a pivotal subset of Artificial Intelligence.
            \item \textbf{Real-World Applications:} Applications include fraud detection in banking, predictive maintenance in manufacturing, and recommendation systems in e-commerce.
            \item \textbf{Continual Learning:} ML models improve over time as they access more data, emphasizing data quality and relevance.
        \end{itemize}
    \end{block}
    \begin{block}{Illustrative Example}
        \begin{itemize}
            \item \textbf{Task:} Classifying emails as "Spam" or "Not Spam."
            \item \textbf{Training Data:} A dataset with labeled emails.
            \item \textbf{Algorithm:} A decision tree learns patterns from the data.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Core Concepts - Part 1}
    \begin{block}{1. Machine Learning (ML)}
        \textbf{Definition:}  
        Machine Learning is a subset of artificial intelligence focused on developing algorithms that enable computers to learn from and make predictions based on data.

        \begin{itemize}
            \item Learning from examples, rather than explicit rules.
            \item Building mathematical models to capture patterns in data.
        \end{itemize}
    \end{block}
    
    \begin{block}{2. Algorithms}
        \textbf{Definition:}  
        An algorithm is a step-by-step set of instructions that a machine follows to perform a task or solve a problem.

        \textbf{Example:} Decision Tree Algorithm - sorts data points based on feature values and creates a tree structure for classification or regression tasks.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Core Concepts - Part 2}
    \begin{block}{Key Formula}
        For a given dataset \( D \) and a prediction function \( f \), the task of learning can be expressed as finding the best function \( f^* \) that minimizes the prediction error:
        \begin{equation}
            f^* = \arg\min_f \mathbb{E}_{(x,y) \sim D} \left[\text{Loss}(f(x), y)\right]
        \end{equation}
        where Loss is a measure of prediction error.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Core Concepts - Part 3}
    \begin{block}{3. Data}
        \textbf{Definition:}  
        Data represents the information collected for analysis, which comes in various formats (numbers, text, images).

        \textbf{Types of Data:}
        \begin{itemize}
            \item \textbf{Training Data:} Used to train the machine learning model.
            \item \textbf{Test Data:} Separate data used to evaluate the performance of the trained model.
        \end{itemize}
        
        \textbf{Example:} In a spam detection model, training data may consist of emails labeled as "spam" or "not spam."
    \end{block}

    \begin{block}{4. Training}
        \textbf{Definition:}  
        Training is the process of teaching a machine learning model by feeding it data and allowing the algorithm to learn patterns.

        \textbf{Key Process:}
        \begin{itemize}
            \item Tuning model parameters iteratively to minimize prediction error.
            \item Typically divided into epochs.
        \end{itemize}

        \textbf{Example:} In linear regression, training involves calculating optimal coefficients for the best-fit line.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Core Concepts - Part 4}
    \begin{block}{5. Prediction}
        \textbf{Definition:}  
        Prediction is the capability of the trained machine learning model to infer outcomes based on new, unseen data.

        \textbf{Example:} A spam filter predicts whether a new email is spam or not based on learned patterns.
    \end{block}

    \begin{block}{Conclusion: Key Takeaways}
        \begin{itemize}
            \item Machine Learning enables automated learning from data.
            \item Algorithms guide how models interpret data.
            \item Understanding data and the processes of training and prediction is crucial for effective implementation.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Machine Learning - Overview}
    Machine Learning (ML) can be broadly classified into three categories:
    
    \begin{itemize}
        \item \textbf{Supervised Learning}
        \item \textbf{Unsupervised Learning}
        \item \textbf{Reinforcement Learning}
    \end{itemize}
    
    Each type addresses different types of problems and is utilized in various applications.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Machine Learning - Supervised Learning}
    \textbf{Definition:} In supervised learning, the model is trained on a labeled dataset.
    
    \begin{itemize}
        \item \textbf{How it Works:} 
        The algorithm learns to map inputs to outputs based on the training data.
        
        \item \textbf{Examples:}
        \begin{itemize}
            \item \textbf{Classification:} Determining if an email is spam or not.
            \item \textbf{Regression:} Predicting house prices based on size and location.
        \end{itemize}
        
        \item \textbf{Key Concept:} Loss Function
        The goal is to minimize the error using a loss function like Mean Squared Error (MSE).
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Machine Learning - Unsupervised and Reinforcement Learning}
    \textbf{Unsupervised Learning:}
    \begin{itemize}
        \item \textbf{Definition:} Uses unlabeled data to find hidden patterns.
        
        \item \textbf{Examples:}
        \begin{itemize}
            \item \textbf{Clustering:} Grouping customers based on purchasing behavior.
            \item \textbf{Dimensionality Reduction:} Techniques like PCA to simplify data.
        \end{itemize} 
        
        \item \textbf{Key Concept:} Clustering Techniques (e.g., K-Means).
    \end{itemize}
    
    \vspace{0.5cm}

    \textbf{Reinforcement Learning:}
    \begin{itemize}
        \item \textbf{Definition:} Training an agent to make decisions to maximize cumulative rewards.
        
        \item \textbf{Examples:}
        \begin{itemize}
            \item \textbf{Game Playing:} Algorithms like AlphaGo.
            \item \textbf{Autonomous Driving:} Vehicles navigating efficiently.
        \end{itemize} 
        
        \item \textbf{Key Concept:} Q-Learning Algorithm.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Differences Summary}
    \begin{table}[ht]
        \centering
        \begin{tabular}{|l|l|l|l|}
        \hline
        \textbf{Feature} & \textbf{Supervised Learning} & \textbf{Unsupervised Learning} & \textbf{Reinforcement Learning} \\ \hline
        Data Type & Labeled & Unlabeled & Interactive (State, Action, Reward) \\ \hline
        Goal & Predict outcomes (Lazy learner) & Discover patterns & Learn optimal strategies (Active learner) \\ \hline
        Examples & Classification, Regression & Clustering, PCA & Game AI, Robotics \\ \hline
        \end{tabular}
        \caption{Key differences among types of machine learning}
    \end{table}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Suggested Code Snippet}
    \textbf{Conclusion:} 
    Understanding these types of machine learning is foundational to applying ML techniques effectively.

    \begin{itemize}
        \item Each type serves distinct purposes.
        \item Driven by different data requirements and methodologies.
        \item Suitable for various real-world applications.
    \end{itemize}

    \textbf{Suggested Code Snippet for Supervised Learning (Python):}
    \begin{lstlisting}[language=Python]
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Sample dataset
X = [[1], [2], [3], [4]]  # Feature
y = [1, 3, 2, 3]          # Labels

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Model training
model = LinearRegression()
model.fit(X_train, y_train)

# Predictions
predictions = model.predict(X_test)
    \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Components of a Machine Learning System - Introduction}
    \begin{itemize}
        \item Understanding components of a machine learning (ML) system is essential.
        \item Key components include:
        \begin{itemize}
            \item Data
            \item Model 
            \item Learning Algorithm
            \item Evaluation Metrics
        \end{itemize}
        \item Each component plays a vital role from data gathering to model deployment.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Components of a Machine Learning System - Data}
    \begin{block}{Data}
        \begin{itemize}
            \item \textbf{Definition:} Raw information used to train and validate ML models.
            \item \textbf{Types of Data:}
            \begin{itemize}
                \item \textit{Structured Data:} Organized and easily searchable (e.g., spreadsheets).
                \item \textit{Unstructured Data:} Unorganized and complex (e.g., images, text).
            \end{itemize}
            \item \textbf{Importance of Data Quality:}
            \begin{itemize}
                \item Example: High-quality data leads to better accuracy.
                \item Poor data quality can result in biased or incorrect outputs.
            \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Components of a Machine Learning System - Model}
    \begin{block}{Model}
        \begin{itemize}
            \item \textbf{Definition:} Mathematical representation capturing patterns from data.
            \item \textbf{Types of Models:}
            \begin{itemize}
                \item \textit{Linear Regression:} Predicts continuous outcomes.
                \item \textit{Decision Trees:} Used for classification tasks.
            \end{itemize}
            \item \textbf{Illustration:}
            \begin{verbatim}
            Is Age > 30?
               ├── Yes: Predict High Income
               └── No: Predict Low Income
            \end{verbatim}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Components of a Machine Learning System - Learning Algorithm}
    \begin{block}{Learning Algorithm}
        \begin{itemize}
            \item \textbf{Definition:} Method used to adjust model parameters based on data.
            \item \textbf{Common Algorithms:}
            \begin{itemize}
                \item \textit{Gradient Descent:} Minimizes error by iteratively updating weights.
                \item \textit{Support Vector Machines (SVM):} Classifies by finding the optimal hyperplane.
            \end{itemize}
            \item \textbf{Example (Gradient Descent):}
            \begin{equation}
                \theta := \theta - \alpha \cdot \nabla J(\theta)
            \end{equation}
            Where:
            \begin{itemize}
                \item $\theta$ = model parameters
                \item $\alpha$ = learning rate
                \item $\nabla J(\theta)$ = gradient of the cost function
            \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Components of a Machine Learning System - Evaluation Metrics}
    \begin{block}{Evaluation Metrics}
        \begin{itemize}
            \item \textbf{Definition:} Measurements for assessing model performance.
            \item \textbf{Common Metrics:}
            \begin{itemize}
                \item \textit{Accuracy:} Proportion of correct predictions.
                \item \textit{Precision and Recall:} Measure of true positives versus false positives.
            \end{itemize}
            \item \textbf{Key Point:} 
            \begin{itemize}
                \item Evaluating model performance aids in refining and selecting the best model.
            \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Components of a Machine Learning System - Summary}
    \begin{itemize}
        \item Understanding components: Data, Model, Learning Algorithm, and Evaluation Metrics is crucial for ML applications.
        \item Each component significantly contributes to the system's success.
        \item Recognizing the interplay between these elements enhances the learning process in ML.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data: The Foundation of Machine Learning}
    
    \begin{block}{Key Concepts}
        \begin{itemize}
            \item The role of data as the backbone of machine learning models.
            \item Importance of data quality for model performance.
        \end{itemize}
    \end{block}

\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Data: Structured vs Unstructured}
    
    \begin{enumerate}
        \item \textbf{Structured Data}
        \begin{itemize}
            \item \textbf{Definition:} Organized into a fixed schema, rows, and columns.
            \item \textbf{Examples:}
            \begin{itemize}
                \item Databases (SQL tables, customer data).
                \item Spreadsheets (Excel files).
            \end{itemize}
            \item \textbf{Characteristics:}
            \begin{itemize}
                \item Easy to store and analyze.
                \item Compatible with machine learning algorithms.
            \end{itemize}
        \end{itemize}
        
        \item \textbf{Unstructured Data}
        \begin{itemize}
            \item \textbf{Definition:} Lacks a predefined format.
            \item \textbf{Examples:}
            \begin{itemize}
                \item Text data (emails, social media posts).
                \item Multimedia (images, audio, videos).
            \end{itemize}
            \item \textbf{Characteristics:}
            \begin{itemize}
                \item Requires complex processing (NLP, image processing).
                \item Contains rich information but challenging to analyze.
            \end{itemize}
        \end{itemize}
    \end{enumerate}

\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance of Data Quality}
    
    \begin{block}{Impact of Data Quality}
        High-quality data is crucial as it significantly affects model performance. Poor quality data can lead to:
        \begin{itemize}
            \item \textbf{Bias:} Misleading results from non-representative data.
            \item \textbf{Noise:} Irrelevant variations that obscure true patterns.
            \item \textbf{Missing Values:} Incomplete datasets causing misinterpretation.
        \end{itemize}
    \end{block}

    \begin{block}{Key Points}
        \begin{itemize}
            \item \textbf{Garbage in, Garbage out:} The quality of output depends on input quality.
            \item \textbf{Data Cleaning and Preprocessing:}
            \begin{itemize}
                \item Remove duplicates.
                \item Handle missing values.
                \item Normalize or standardize data.
            \end{itemize}
        \end{itemize}
    \end{block}

\end{frame}

\begin{frame}[fragile]
    \frametitle{The Machine Learning Process - Introduction}
    \begin{block}{Overview}
        The machine learning process consists of structured steps that guide practitioners from problem identification to model deployment. Understanding each component is crucial for successful machine learning projects.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{The Machine Learning Process - Key Steps}
    \begin{enumerate}
        \item Data Collection
        \item Data Preprocessing
        \item Model Training
        \item Evaluation
        \item Deployment
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data Collection}
    \begin{itemize}
        \item \textbf{Definition}: Gathering relevant data to inform the model.
        \item \textbf{Sources}: Databases, APIs, web scraping, sensors.
        \item \textbf{Example}: Collecting sales data for retail to predict trends.
        \item \textbf{Key Point}: Quality and relevance of data are critical for model accuracy.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data Preprocessing}
    \begin{itemize}
        \item \textbf{Definition}: Cleaning and transforming raw data to prepare it for analysis.
        \item \textbf{Key Techniques}:
        \begin{itemize}
            \item \textbf{Handling Missing Values}: Replace with mean, median, or mode; remove records.
            \item \textbf{Normalization}: Scale features to a range [0, 1].
            \begin{equation}
                X_{norm} = \frac{X - X_{min}}{X_{max} - X_{min}}
            \end{equation}
        \end{itemize}
        \item \textbf{Key Point}: Effective preprocessing can significantly enhance model performance.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Model Training}
    \begin{itemize}
        \item \textbf{Definition}: Teaching the machine learning model using preprocessed data.
        \item \textbf{Selection}: Choosing an appropriate algorithm (e.g., linear regression, decision trees).
        \item \textbf{Example}: Training a decision tree model using features like age and income to predict customer churn.
        \item \textbf{Key Point}: Proper parameter tuning during training enhances model performance.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Evaluation}
    \begin{itemize}
        \item \textbf{Definition}: Assessing model performance using metrics such as accuracy, precision, and recall.
        \item \textbf{Example}: Evaluating a classification model using a confusion matrix to understand true positives and false negatives.
        \item \textbf{Key Point}: This step ensures that the model generalizes well to unseen data.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Deployment}
    \begin{itemize}
        \item \textbf{Definition}: Integrating the trained model into a production environment for real-world use.
        \item \textbf{Example}: Deploying a recommendation system to suggest products on an e-commerce site.
        \item \textbf{Key Point}: Ongoing monitoring and maintenance are essential for model performance in production.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{The Machine Learning Process - Conclusion}
    \begin{block}{Key Summary Points}
        \begin{itemize}
            \item Effective data collection and preprocessing are foundational.
            \item Selecting the right model and parameters is critical during training.
            \item Evaluation metrics help gauge model effectiveness.
            \item Proper deployment ensures that the model serves its intended purpose.
        \end{itemize}
    \end{block}
    
    \begin{block}{Additional Considerations}
        \begin{itemize}
            \item Consider ethical implications and biases in data.
            \item Stay updated on evolving techniques in the machine learning landscape.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Training and Testing in Machine Learning - Overview}
    \begin{block}{Key Concepts}
        \begin{itemize}
            \item **Training Data**: Dataset used to train the model to recognize patterns.
            \item **Test Data**: Separate dataset to evaluate the model's performance.
            \item Focus on avoiding \textbf{overfitting} and \textbf{underfitting}.
        \end{itemize} 
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Training Data and Test Data}
    \begin{block}{Training Data}
        \begin{itemize}
            \item \textbf{Definition}: Dataset used to train the model, containing input features and labels.
            \item \textbf{Purpose}: Allows the model to learn the underlying patterns.
            \item \textbf{Example}: Features like square footage and number of bedrooms predicting house prices.
        \end{itemize}
    \end{block}
    
    \begin{block}{Test Data}
        \begin{itemize}
            \item \textbf{Definition}: Dataset separate from training data for evaluating performance.
            \item \textbf{Purpose}: Assesses the model's ability to generalize to new, unseen data.
            \item \textbf{Example}: Predicting prices of houses not included in the training set.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Overfitting and Underfitting}
    \begin{block}{Overfitting}
        \begin{itemize}
            \item \textbf{Definition}: Model learns training data too well, including noise.
            \item \textbf{Symptoms}: High accuracy on training data but poor on test data.
            \item \textbf{Solutions}:
                \begin{itemize}
                    \item Regularization (L1, L2)
                    \item Cross-validation
                    \item Pruning in decision trees
                \end{itemize}
        \end{itemize}
    \end{block}
    
    \begin{block}{Underfitting}
        \begin{itemize}
            \item \textbf{Definition}: Model is too simple to capture the data's structure.
            \item \textbf{Symptoms}: Low accuracy on both training and test sets.
            \item \textbf{Solutions}:
                \begin{itemize}
                    \item Increase model complexity
                    \item Add more features
                    \item Reduce regularization constraints
                \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Mathematical Insights}
    \begin{block}{Key Points}
        \begin{itemize}
            \item Proper data splitting into train and test sets is crucial.
            \item Common practice: \textbf{70-80\%} for training and \textbf{20-30\%} for testing.
            \item Cross-validation (like k-fold) ensures robust model evaluation.
        \end{itemize}
    \end{block}
    
    \begin{block}{Formula Notation}
        \begin{equation}
            \text{Accuracy} = \frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}} \times 100
        \end{equation}
        
        \begin{lstlisting}[language=Python]
from sklearn.model_selection import train_test_split

# Assuming 'data' is your features and 'labels' are your targets
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)
        \end{lstlisting}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Performance Metrics - Introduction}
    In machine learning, evaluating the effectiveness of a model is critical. Performance metrics provide quantitative measures to understand how well a model predicts outcomes. 
    
    Here, we'll discuss five key performance metrics: 
    \begin{itemize}
        \item \textbf{Accuracy}
        \item \textbf{Precision}
        \item \textbf{Recall}
        \item \textbf{F1 Score}
        \item \textbf{ROC-AUC}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Performance Metrics - Accuracy and Precision}
    \begin{block}{Accuracy}
        \textbf{Definition}: The ratio of correctly predicted observations to the total observations.
        
        \textbf{Formula}:
        \begin{equation}
            \text{Accuracy} = \frac{\text{True Positives} + \text{True Negatives}}{\text{Total Observations}}
        \end{equation}
        
        \textbf{Example}: If a model predicts 80 out of 100 instances correctly, the accuracy is 80\%.
    \end{block}
    
    \begin{block}{Precision}
        \textbf{Definition}: The ratio of correctly predicted positive observations to the total predicted positives.
        
        \textbf{Formula}:
        \begin{equation}
            \text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
        \end{equation}
        
        \textbf{Example}: If a model predicts 10 as positive but only 7 are actually positive, the precision is:
        \begin{equation}
            \text{Precision} = \frac{7}{10} = 0.7
        \end{equation}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Performance Metrics - Recall, F1 Score, and ROC-AUC}
    \begin{block}{Recall (Sensitivity)}
        \textbf{Definition}: The ratio of correctly predicted positive observations to all actual positives.
        
        \textbf{Formula}:
        \begin{equation}
            \text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
        \end{equation}
        
        \textbf{Example}: If there are 15 actual positives and the model identifies 10 correctly, but misses 5:
        \begin{equation}
            \text{Recall} = \frac{10}{15} = 0.67
        \end{equation}
    \end{block}

    \begin{block}{F1 Score}
        \textbf{Definition}: The harmonic mean of precision and recall.
        
        \textbf{Formula}:
        \begin{equation}
            F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
        \end{equation}
        
        \textbf{Example}: If precision is 0.7 and recall is 0.67:
        \begin{equation}
            F1 \approx 0.685
        \end{equation}
    \end{block}

    \begin{block}{ROC-AUC}
        \textbf{Definition}: A plot illustrating a binary classifier's diagnostic ability.
        
        \textbf{Key Points}: 
        \begin{itemize}
            \item AUC = 0.5 suggests no discrimination.
            \item AUC = 1.0 indicates perfect classification.
        \end{itemize}
        
        \textbf{Example}: A model with an AUC of 0.85 shows good predictive accuracy.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points to Emphasize}
    \begin{itemize}
        \item \textbf{Accuracy} can be misleading in imbalanced datasets.
        \item \textbf{Precision} and \textbf{Recall} are critical in contexts where false positives and false negatives have different consequences.
        \item The \textbf{F1 Score} balances precision and recall.
        \item \textbf{ROC-AUC} visualizes performance trade-offs at various thresholds, aiding model selection.
    \end{itemize}
    
    Understanding these performance metrics is crucial for interpreting model effectiveness and making data-driven decisions in machine learning applications.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Common Algorithms in Machine Learning}
    \begin{block}{Overview of Widely Used Algorithms}
        Machine Learning (ML) relies on various algorithms to analyze data and make predictions. The choice of algorithm significantly affects the performance and accuracy of a model. Below are some of the core algorithms used in machine learning.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Linear Regression}
    \begin{itemize}
        \item \textbf{Concept:} A statistical method to model the relationship between a dependent variable (Y) and independent variables (X) assuming a linear relationship.
        \item \textbf{Equation:} 
        \begin{equation}
            Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_nX_n + \epsilon
        \end{equation}
        \begin{itemize}
            \item Where $\beta_0$ is the y-intercept, $\beta_1, \beta_2, ..., \beta_n$ are coefficients, and $\epsilon$ is the error term.
        \end{itemize}
        \item \textbf{Example:} Predicting house prices based on features like size, location, and number of bedrooms.
        \item \textbf{Key Point:} Best for problems where the relationship between variables is straightforward or linear.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Decision Trees}
    \begin{itemize}
        \item \textbf{Concept:} A flowchart-like structure where each internal node represents a decision based on a feature, branches represent outcomes, and leaf nodes represent class labels.
        \item \textbf{Example:} Classifying whether an email is spam based on keywords.
        \item \textbf{Algorithm Steps:}
        \begin{enumerate}
            \item Select the best feature that splits the data using Gini Impurity or Information Gain.
            \item Create branches until reaching leaf nodes.
        \end{enumerate}
        \item \textbf{Key Point:} Intuitive and easy to interpret but may lead to overfitting without pruning techniques.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Support Vector Machines (SVM)}
    \begin{itemize}
        \item \textbf{Concept:} SVM finds the optimal hyperplane that separates classes in high-dimensional space, maximizing the margin between data points.
        \item \textbf{Equation:} The decision boundary is given by:
        \begin{equation}
            w \cdot x + b = 0
        \end{equation}
        \begin{itemize}
            \item Where $w$ is the weight vector and $b$ is the bias term.
        \end{itemize}
        \item \textbf{Example:} Image classification distinguishing between cats and dogs.
        \item \textbf{Key Point:} Effective in high dimensions where the number of dimensions exceeds the number of samples.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Neural Networks}
    \begin{itemize}
        \item \textbf{Concept:} Inspired by the human brain, consisting of interconnected neurons organized in layers (input, hidden, output) to model complex relationships.
        \item \textbf{Architecture:}
        \begin{itemize}
            \item Input Layer: Takes input features.
            \item Hidden Layers: Perform computations.
            \item Output Layer: Produces predictions.
        \end{itemize}
        \item \textbf{Example:} Image recognition using Convolutional Neural Networks (CNNs).
        \item \textbf{Key Point:} Highly flexible for complex tasks but require substantial data and computational resources.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Summary and Visual Aids}
    \begin{itemize}
        \item Understanding these algorithms is crucial for selecting appropriate tools for machine learning tasks.
        \item Consider model complexity, interpretability, and dataset characteristics when choosing algorithms.
    \end{itemize}
    \begin{block}{Visual Aids}
        % Visual aids to be added: 
        \begin{itemize}
            \item Flowchart of Decision Trees.
            \item Diagrams of linear regression and SVM decision boundaries.
            \item Neural network architecture illustration.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Code Snippet for Linear Regression}
    \begin{lstlisting}[language=Python]
from sklearn.linear_model import LinearRegression

# Example data
X = [[1], [2], [3], [4]]
y = [1, 2, 3, 4]

# Create and fit the model
model = LinearRegression()
model.fit(X, y)

# Coefficients
print(model.coef_, model.intercept_)
    \end{lstlisting}
\end{frame}

\begin{frame}
    \frametitle{Ethical Considerations in Machine Learning}
    \begin{block}{Importance of Ethics}
        Ethics in machine learning (ML) refers to the moral implications of algorithms. 
        Integrating ethical considerations is crucial to ensure technology benefits society.
    \end{block}
    \begin{itemize}
        \item \textbf{Responsibility:} Developers must take responsibility for algorithmic outcomes.
        \item \textbf{Transparency:} Decision-making should be clear and understandable to users.
        \item \textbf{Accountability:} Mechanisms should exist for holding individuals or organizations accountable.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Bias in Algorithms and Its Importance}
    \begin{block}{Understanding Bias}
        Machine learning models can incorporate existing biases from training data, leading to discriminatory outcomes.
    \end{block}
    \begin{itemize}
        \item \textbf{Data Bias:} 
        \begin{itemize}
            \item Example: Facial recognition performs poorly on darker-skinned individuals due to unrepresentative training data.
        \end{itemize}
        \item \textbf{Algorithmic Bias:} 
        \begin{itemize}
            \item Example: Hiring algorithms penalizing candidates from certain demographics based on historical data.
        \end{itemize}
    \end{itemize}
    \begin{block}{Importance of Addressing Bias}
        \begin{itemize}
            \item Promotes fairness in ML applications.
            \item Maintains public trust in AI systems.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Implications of AI on Society}
    \begin{block}{Potential Impacts}
        \begin{itemize}
            \item \textbf{Positive:} 
            \begin{itemize}
                \item Enhanced efficiency in industries.
                \item Improved decision-making through data insights.
            \end{itemize}
            \item \textbf{Negative:} 
            \begin{itemize}
                \item Job displacement due to automation.
                \item Privacy concerns linked to surveillance.
            \end{itemize}
        \end{itemize}
    \end{block}
    \begin{block}{Key Considerations}
        \begin{itemize}
            \item Establishing regulations to mitigate negative impacts of AI.
            \item Fostering collaboration among technologists, ethicists, and policymakers.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Code Snippet: Identifying Bias in Data}
    \begin{lstlisting}[language=Python]
import pandas as pd

# Load dataset
data = pd.read_csv('dataset.csv')

# Check for bias in gender representation
gender_counts = data['gender'].value_counts(normalize=True)
print("Gender Representation:", gender_counts)

# Visualize any discrepancies in employment rates
employment_rates = data.groupby('gender')['employed'].mean()
employment_rates.plot(kind='bar', title='Employment Rate by Gender')
    \end{lstlisting}
\end{frame}

\begin{frame}
    \frametitle{Conclusion}
    Addressing ethical considerations and biases in machine learning is vital to ensure that technology serves society equitably. Understanding these issues leads to the development of responsible and beneficial AI systems.
\end{frame}

\begin{frame}[fragile]
  \frametitle{Conclusion and Future Trends - Part 1}
  
  \textbf{Importance of Machine Learning in AI} 

  \begin{itemize}
      \item \textbf{Data-Driven Decisions:} 
      ML enables organizations to utilize extensive data to generate actionable insights.
      \item \textbf{Automation of Processes:} 
      ML models streamline repetitive tasks, allowing human resources to focus on complex challenges.
      \item \textbf{Personalization:} 
      Applications, such as recommendation systems (e.g., Amazon, Netflix), depend heavily on ML to create tailored user experiences.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Conclusion and Future Trends - Part 2}
  
  \textbf{Future Trends and Advancements}

  \begin{enumerate}
      \item \textbf{Explainable AI (XAI)}
      \begin{itemize}
          \item \textbf{Description:} 
          Understanding decision-making processes in ML models is crucial for trust in sensitive domains.
          \item \textbf{Example:} 
          Tools like LIME or SHAP are used to interpret model predictions.
      \end{itemize}
      
      \item \textbf{Integration with Edge Computing}
      \begin{itemize}
          \item \textbf{Description:} 
          Processing data locally in IoT devices reduces latency and bandwidth needs.
          \item \textbf{Example:} 
          Smart cameras performing real-time analytics using local ML models.
      \end{itemize}
      
      \item \textbf{Advancements in Natural Language Processing (NLP)}
      \begin{itemize}
          \item \textbf{Description:} 
          Enhancements will facilitate better human-computer interactions.
          \item \textbf{Example:} 
          BERT and GPT-3 exemplify breakthroughs in understanding human language.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Conclusion and Future Trends - Part 3}
  
  \begin{enumerate}[resume]     
      \item \textbf{Advanced Transfer Learning and Few-Shot Learning}
      \begin{itemize}
          \item \textbf{Description:} 
          These methods allow generalization across tasks with minimal data, reducing the need for labeled training data.
          \item \textbf{Example:} 
          A model trained on one language can adapt to another with fewer examples.
      \end{itemize}
      
      \item \textbf{Focus on Ethical AI}
      \begin{itemize}
          \item \textbf{Description:} 
          Ensuring fairness and transparency in ML algorithms is critical to avoid biases.
          \item \textbf{Example:} 
          Regular auditing frameworks for evaluating ML system impact on demographics.
      \end{itemize}
  \end{enumerate}

  \textbf{Conclusion:} 
  Machine learning is crucial for enhancing AI capabilities. As we advance, we must balance its potential with ethical considerations to ensure beneficial outcomes for humanity.
\end{frame}


\end{document}