\documentclass[aspectratio=169]{beamer}

% Theme and Color Setup
\usetheme{Madrid}
\usecolortheme{whale}
\useinnertheme{rectangles}
\useoutertheme{miniframes}

% Additional Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}
\usepackage{hyperref}

% Custom Colors
\definecolor{myblue}{RGB}{31, 73, 125}
\definecolor{mygray}{RGB}{100, 100, 100}
\definecolor{mygreen}{RGB}{0, 128, 0}
\definecolor{myorange}{RGB}{230, 126, 34}
\definecolor{mycodebackground}{RGB}{245, 245, 245}

% Set Theme Colors
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=white, bg=myblue}
\setbeamercolor{title}{fg=myblue}
\setbeamercolor{section in toc}{fg=myblue}
\setbeamercolor{item projected}{fg=white, bg=myblue}
\setbeamercolor{block title}{bg=myblue!20, fg=myblue}
\setbeamercolor{block body}{bg=myblue!10}
\setbeamercolor{alerted text}{fg=myorange}

% Set Fonts
\setbeamerfont{title}{size=\Large, series=\bfseries}
\setbeamerfont{frametitle}{size=\large, series=\bfseries}
\setbeamerfont{caption}{size=\small}
\setbeamerfont{footnote}{size=\tiny}

% Code Listing Style
\lstdefinestyle{customcode}{
  backgroundcolor=\color{mycodebackground},
  basicstyle=\footnotesize\ttfamily,
  breakatwhitespace=false,
  breaklines=true,
  commentstyle=\color{mygreen}\itshape,
  keywordstyle=\color{blue}\bfseries,
  stringstyle=\color{myorange},
  numbers=left,
  numbersep=8pt,
  numberstyle=\tiny\color{mygray},
  frame=single,
  framesep=5pt,
  rulecolor=\color{mygray},
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=2,
  captionpos=b
}
\lstset{style=customcode}

% Custom Commands
\newcommand{\hilight}[1]{\colorbox{myorange!30}{#1}}
\newcommand{\source}[1]{\vspace{0.2cm}\hfill{\tiny\textcolor{mygray}{Source: #1}}}
\newcommand{\concept}[1]{\textcolor{myblue}{\textbf{#1}}}
\newcommand{\separator}{\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}}

% Footer and Navigation Setup
\setbeamertemplate{footline}{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
    \usebeamerfont{author in head/foot}\insertshortauthor
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.5\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
    \usebeamerfont{title in head/foot}\insertshorttitle
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.2\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}%
    \usebeamerfont{date in head/foot}
    \insertframenumber{} / \inserttotalframenumber
  \end{beamercolorbox}}%
  \vskip0pt%
}

% Turn off navigation symbols
\setbeamertemplate{navigation symbols}{}

% Title Page Information
\title[Introduction to Function Approximation]{Week 6: Introduction to Function Approximation}
\author[J. Smith]{John Smith, Ph.D.}
\institute[University Name]{
  Department of Computer Science\\
  University Name\\
  \vspace{0.3cm}
  Email: email@university.edu\\
  Website: www.university.edu
}
\date{\today}

% Document Start
\begin{document}

\frame{\titlepage}

\begin{frame}[fragile]
    \titlepage
\end{frame}

\begin{frame}[fragile]
    \frametitle{Overview of Function Approximation}
    Function approximation is a fundamental concept in reinforcement learning (RL) used to estimate the representation of the value function or policy when dealing with high-dimensional and continuous state spaces.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance of Function Approximation}
    \begin{itemize}
        \item \textbf{Scalability:} Generalizes from seen states to unseen states in complex environments.
        \item \textbf{Efficiency:} Allows learning useful behaviors with fewer samples than computing exact values for each state.
        \item \textbf{Real-World Applicability:} Effectively navigates challenges in continuous spaces such as robotics and financial modeling.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts}
    \begin{block}{Value Function Approximation}
        - Approximate the value function \( V(s) \) that estimates the expected return from state \( s \).
        - Common forms: linear functions, polynomial functions, and deep neural networks.
    \end{block}
    \begin{block}{Policy Approximation}
        - Model the policy \( \pi(a | s) \) through parameters, enabling efficient exploration and exploitation.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Examples of Function Approximation in RL}
    \begin{enumerate}
        \item \textbf{Linear Function Approximation:}
            \begin{equation}
                V(s) = w_0 + w_1 \cdot x_1 + w_2 \cdot x_2
            \end{equation}
            where \( x_1, x_2 \) are features representing state \( s \) and \( w_0, w_1, w_2 \) are the learned weights.
        
        \item \textbf{Deep Q-Networks (DQN):}
            \begin{itemize}
                \item A neural network is used to approximate the Q-value function \( Q(s, a) \) based on the current state \( s \).
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points to Emphasize}
    \begin{itemize}
        \item Function approximation simplifies complex problems into manageable computations.
        \item Choosing the right approximation method (linear, polynomial, or deep learning) is essential for success in RL.
        \item Function approximation utilizes generalization to predict outputs for unseen inputs based on learned patterns.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion}
    In reinforcement learning, function approximation serves as a crucial bridge between computation and application. By effectively estimating value functions and policies, it empowers agents to thrive in complex environments, solidifying its role as a cornerstone of modern RL methodologies.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Generalization - Part 1}
    \begin{block}{What is Generalization in Machine Learning?}
        Generalization is the ability of a model to perform well on unseen data.
    \end{block}
    
    \begin{itemize}
        \item **Definition**: The model's capacity to make accurate predictions on new inputs not in the training set.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Generalization - Part 2}
    \begin{block}{Importance of Generalization}
        \begin{itemize}
            \item **Primary Goal**: Create models that capture underlying patterns rather than merely memorizing training data.
            \item **Overfitting vs. Underfitting**:
                \begin{itemize}
                    \item **Overfitting**: Learning too much from the training data, resulting in poor prediction on new data.
                    \item **Example**: Complex models that fit noise.
                    \item **Underfitting**: Failing to capture underlying patterns leading to poor performance overall.
                    \item **Example**: Simple models failing to comprehend complex relationships.
                \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Generalization - Part 3}
    \begin{block}{Practical Example of Generalization}
        \begin{itemize}
            \item **Scenario**: Classifying images of cats and dogs.
            \item **Key Point**: A good model learns general features such as shape and size, rather than specific details like background color.
        \end{itemize}
    \end{block}

    \begin{block}{Key Points to Emphasize}
        \begin{enumerate}
            \item **Training vs. Test Data**: Assess generalization using a separate test dataset.
            \item **Model Complexity**: Balance model complexity for optimal generalization.
            \item **Cross-validation**: Use k-fold cross-validation to evaluate generalization.
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Generalization - Formulas}
    \begin{block}{Error Decomposition}
        \begin{equation}
            \text{Total Error} = \text{Bias}^2 + \text{Variance} + \text{Irreducible Error}
        \end{equation}
        \begin{itemize}
            \item **Bias**: Error from overly simplistic assumptions.
            \item **Variance**: Error due to excessive sensitivity to training set fluctuations.
        \end{itemize}
    \end{block}
    
    \begin{block}{Conclusion}
        Generalization is essential in machine learning and directly impacts model real-world applicability. Techniques to improve it include reducing overfitting and ensuring the right model complexity.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Linear Function Models - Overview}
    Linear function models are mathematical representations that assume a linear relationship between input variables and output. In the context of reinforcement learning (RL), they are used to approximate:
    \begin{itemize}
        \item Value Functions
        \item Policies
        \item Environment Models
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Linear Function Models - Definition}
    \begin{block}{Definition}
        A linear function can be expressed as:
        \begin{equation}
        y = w_1 x_1 + w_2 x_2 + \ldots + w_n x_n + b
        \end{equation}
        where:
        \begin{itemize}
            \item \(y\) is the predicted output.
            \item \(x_i\) are the input features (state representations).
            \item \(w_i\) are the weights that determine the influence of each input.
            \item \(b\) is the bias term.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Benefits and Limitations}
    \textbf{Benefits:}
    \begin{itemize}
        \item \textbf{Simplicity:} Easy to understand and implement.
        \item \textbf{Computational Efficiency:} Requires less computational power.
        \item \textbf{Interpretability:} Straightforward interpretation of the effect of each feature \(x_i\).
        \item \textbf{Rapid Convergence:} Efficient convergence to optimal solution when linearity holds.
    \end{itemize}
    
    \bigskip
    
    \textbf{Limitations:}
    \begin{itemize}
        \item \textbf{Inflexibility:} Inability to capture complex relationships.
        \item \textbf{Underfitting:} Significant errors in highly nonlinear settings.
        \item \textbf{Limited Expressiveness:} Difficulty in modeling feature interactions.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Example in Reinforcement Learning}
    Consider a simple grid-world scenario:
    \begin{itemize}
        \item The state is represented by \(x_1\) (agent's x-coordinate) and \(x_2\) (agent's y-coordinate).
        \item The value of states is estimated using:
        \begin{equation}
        V(s) = w_1 \cdot x_1 + w_2 \cdot x_2 + b
        \end{equation}
        \item Weights \(w_1\) and \(w_2\) indicate how much each coordinate influences the state value.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Takeaways and Conclusion}
    \begin{itemize}
        \item Linear models are foundational in understanding more complex models in RL.
        \item Evaluating the context of use is crucial to determine when to implement linear models versus more complex approximators.
        \item While offering simplicity and efficiency, their limitations must be acknowledged.
    \end{itemize}
    
    \bigskip
    
    \textbf{Formula Recap:}
    \begin{equation}
        y = w_1 x_1 + w_2 x_2 + \ldots + w_n x_n + b
    \end{equation}
    
    \bigskip
    
    As you progress in this course, consider the comparison of linear models with other function approximation techniques.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance of Function Approximation - Overview}
    \begin{block}{Understanding Function Approximation in Reinforcement Learning (RL)}
        In RL, function approximation is a method to estimate value functions or policies when state or action spaces are too large to handle explicitly. This approach enables a simplified function that generalizes to unseen states, optimizing the learning process significantly.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance of Function Approximation - Key Benefits}
    \begin{enumerate}
        \item \textbf{Scalability}  
            \begin{itemize}
                \item Allows RL algorithms to scale effectively with larger state and action spaces.
                \item \textit{Example:} In robot navigation, function approximators, such as neural networks, reduce memory usage and complexity by generalizing across similar configurations.
            \end{itemize}
        \item \textbf{Efficiency}
            \begin{itemize}
                \item Speeds up learning by minimizing the need for exhaustive exploration of every state-action pair.
                \item \textit{Example:} In Chess, a neural network approximates position values based on extracted features, significantly reducing strategy computation time.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Use Cases and Illustrative Example}
    \begin{block}{When to Use Function Approximation}
        \begin{itemize}
            \item High-dimensional state spaces (e.g., images, continuous values).
            \item Complex environments where explicit representation is infeasible.
            \item Fast decision-making requirements in time-sensitive applications like robotics or online gaming.
        \end{itemize}
    \end{block}
    
    \begin{block}{Illustrative Example: Linear Function Approximation}
        Using a linear function to approximate the value \( V(s) \):
        \[
        V(s) = \theta_0 + \theta_1 \cdot f_1(s) + \theta_2 \cdot f_2(s) + \ldots + \theta_n \cdot f_n(s)
        \]
        This provides fast and efficient estimations, allowing RL agents to converge more quickly than without approximation.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Generalization Techniques}
    \textbf{Overview:} Generalization techniques in function approximation are essential for creating models that can effectively predict and make decisions based on unseen data. 
    \begin{itemize}
        \item Enable models to learn from specific samples.
        \item Crucial for scalable and efficient reinforcement learning (RL) applications.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts - Part 1}
    \begin{enumerate}
        \item \textbf{Bias-Variance Tradeoff}
        \begin{itemize}
            \item \textbf{Bias}: Error due to assumptions in the learning algorithm. High bias can lead to underfitting.
            \item \textbf{Variance}: Error from excessive sensitivity to training data fluctuations. High variance can lead to overfitting.
            \item \textbf{Goal}: Balance bias and variance to improve generalization.
        \end{itemize}
        \item \textbf{Regularization Techniques}
        \begin{itemize}
            \item \textbf{L1 Regularization (Lasso)}: Adds an absolute value penalty to discourage large coefficients.
            \item \textbf{L2 Regularization (Ridge)}: Adds a squared penalty to shrink weights without zeroing coefficients.
        \end{itemize}
        \begin{equation}
            \text{Loss}_{\text{Lasso}} = \text{Loss}_{\text{original}} + \lambda \sum |w_i|
        \end{equation}
        \begin{equation}
            \text{Loss}_{\text{Ridge}} = \text{Loss}_{\text{original}} + \lambda \sum w_i^2
        \end{equation}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts - Part 2}
    \begin{enumerate}
        \setcounter{enumi}{2}
        \item \textbf{Early Stopping}
        \begin{itemize}
            \item Monitor validation performance and stop training when performance degrades.
        \end{itemize}
        \item \textbf{Cross-Validation}
        \begin{itemize}
            \item Split data into subsets. Train on some, validate on others to ensure robustness.
        \end{itemize}
        \item \textbf{Ensemble Methods}
        \begin{itemize}
            \item Combine predictions from multiple models to improve accuracy (e.g., Random Forests).
        \end{itemize}
        \item \textbf{Data Augmentation}
        \begin{itemize}
            \item Increase training data diversity by modifying existing data points.
        \end{itemize}
        \item \textbf{Parameterized Models}
        \begin{itemize}
            \item Use parameterized functions like neural networks to learn optimal weights.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Example and Conclusion}
    \textbf{Example: Linear Function Approximation}
    \begin{itemize}
        \item Approximate \( f(x) = 2x + 1 \) using a linear model.
        \item Regularization helps prevent overfitting in the presence of noisy data.
    \end{itemize}
    
    \textbf{Conclusion:}
    \begin{itemize}
        \item Effective generalization ensures reliable model performance in unseen situations.
        \item Utilize principles of bias-variance tradeoff, regularization methods, and validation techniques.
    \end{itemize}
    
    \textbf{Key Points to Remember:}
    \begin{itemize}
        \item Generalization is essential for performance in real-world applications.
        \item Balancing bias and variance is critical.
        \item Techniques like regularization and cross-validation play vital roles.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Linear Regression in Reinforcement Learning}
    Linear Regression is a powerful method for modeling relationships between variables. In Reinforcement Learning (RL), it helps estimate value functions or policies.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts}
    \begin{itemize}
        \item \textbf{Function Approximation in RL:} 
            \begin{itemize}
                \item Handles high-dimensional state and action spaces.
                \item Generalizes learning over states and actions.
            \end{itemize}
        
        \item \textbf{Linear Regression:} 
            \begin{equation}
            y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n + \epsilon
            \end{equation}
            Where:
            \begin{itemize}
                \item \( y \): dependent variable (e.g., expected future rewards)
                \item \( x_1, x_2, \ldots, x_n \): independent variables
                \item \( \beta_0, \beta_1, \ldots, \beta_n \): coefficients
                \item \( \epsilon \): error term
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Application in RL}
    \begin{itemize}
        \item \textbf{Value Function Approximation:}
            \begin{itemize}
                \item Uses linear regression to approximate value function \( V(s) \).
                \item Input features may include state attributes such as proximity to goals and presence of obstacles.
            \end{itemize}

        \item \textbf{Example:}
            \begin{equation}
            V(s) = 0.5 \times \text{distance from goal} - 2 \times \text{number of obstacles} + 3
            \end{equation}
            \begin{itemize}
                \item Indicates expected value decreases with distance and obstacles.
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Benefits and Challenges}
    \begin{block}{Benefits}
        \begin{itemize}
            \item \textbf{Simplicity:} Easy to implement and understand.
            \item \textbf{Efficiency:} Less computationally intensive than complex models.
            \item \textbf{Extrapolation:} Generalizes well across similar states due to learned weights.
        \end{itemize}
    \end{block}

    \begin{block}{Challenges}
        \begin{itemize}
            \item \textbf{Overfitting:} Can overfit with too many features.
            \item \textbf{Bias:} May introduce bias if the true relationship is non-linear.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Key Takeaways}
    \begin{itemize}
        \item Linear regression provides an effective method for value function approximation in RL.
        \item There are challenges, particularly with non-linearity.
        \item \textbf{Key Takeaways:}
            \begin{itemize}
                \item Understanding of linear regression in RL.
                \item Recognizing benefits and challenges.
                \item Familiarity with the linear regression formula.
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges in Function Approximation - Introduction}
    \begin{block}{Overview}
        Function approximation is crucial in machine learning and reinforcement learning (RL). 
        Despite its importance in modeling complex relationships, several inherent challenges can impede its effectiveness.
    \end{block}
    \begin{block}{Key Takeaway}
        Understanding these challenges is essential for developing robust models in RL.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges in Function Approximation - Common Challenges}
    \begin{enumerate}
        \item \textbf{Overfitting}
            \begin{itemize}
                \item \textbf{Definition:} Learning noise in training data, hurting performance on unseen data.
                \item \textbf{Symptoms:} High training accuracy, significantly lower validation accuracy.
                \item \textbf{Example:} High-degree polynomial regression fitting all data points but failing to generalize.
                \item \textbf{Prevention Strategies:}
                    \begin{itemize}
                        \item Cross-Validation
                        \item Regularization (L1 or L2)
                    \end{itemize}
            \end{itemize}

        \item \textbf{Bias}
            \begin{itemize}
                \item \textbf{Definition:} Error from overly simplistic assumptions in the learning algorithm; leads to underfitting.
                \item \textbf{Symptoms:} Poor performance on both training and validation datasets.
                \item \textbf{Example:} Using a linear model for non-linear relationships.
                \item \textbf{Correction Techniques:}
                    \begin{itemize}
                        \item Feature Engineering
                        \item Complex Models (e.g., decision trees or neural networks)
                    \end{itemize}
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges in Function Approximation - Key Points}
    \begin{itemize}
        \item \textbf{Balance Complexity:} Finding the right balance between bias and variance is key to effective function approximation.
        \item \textbf{Monitor Performance:} Regular evaluation using different datasets can help identify overfitting and bias.
        \item \textbf{Utilizing Techniques:} Adopt best practices like regularization and feature engineering to enhance model robustness.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges in Function Approximation - Important Formula}
    \begin{equation}
        L(w) = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{m} w_j^2 
    \end{equation}
    \begin{itemize}
        \item Where:
        \begin{itemize}
            \item $n$: number of samples
            \item $y_i$: actual value
            \item $\hat{y}_i$: predicted value
            \item $w_j$: weight of feature $j$
            \item $\lambda$: regularization parameter
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges in Function Approximation - Conclusion}
    \begin{block}{Summary}
        Addressing challenges like overfitting and bias is fundamental for building effective function approximations in machine learning, leading to more accurate and generalizable models in RL applications.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Case Study: Function Approximation in Practice}
    \begin{block}{Overview}
        Function approximation is essential in reinforcement learning (RL), allowing agents to generalize from limited experiences. This presentation covers practical examples and techniques across various industries.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts of Function Approximation}
    \begin{itemize}
        \item \textbf{Definition:} 
        Function approximation refers to techniques predicting function values based on observed data (e.g., value functions, policy functions).
        
        \item \textbf{Importance:}
        \begin{itemize}
            \item Enables operation in high-dimensional state spaces where exact representation is infeasible.
            \item Decreases the sample size needed to learn optimal policies, increasing learning efficiency.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Real-World Applications of Function Approximation}
    \begin{enumerate}
        \item \textbf{Robotics:}
        \begin{itemize}
            \item Scenario: Robot learning to navigate through a maze.
            \item Technique: Neural network approximating the value function.
            \item Result: Efficient route finding through trial and error.
        \end{itemize}

        \item \textbf{Finance:}
        \begin{itemize}
            \item Scenario: Automated trading systems managing portfolios.
            \item Technique: Function approximation (e.g., linear regression) analyzing historical data.
            \item Result: Better trading decisions by predicting market movements.
        \end{itemize}

        \item \textbf{Healthcare:}
        \begin{itemize}
            \item Scenario: Personalized treatment recommendations for patients.
            \item Technique: Policy function approximation based on patient data.
            \item Result: Improved treatment efficacy tailored to individual profiles.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Techniques in Function Approximation}
    \begin{block}{Linear Function Approximation}
        \begin{equation} 
            V(s) = \theta^T \phi(s) 
        \end{equation}
        Used where relationships are well-defined and interpretable.
    \end{block}

    \begin{block}{Non-linear Function Approximation}
        Often implemented with neural networks (deep learning).
        Example: Deep Q-Networks (DQN) using multiple layers for Q-value functions.
    \end{block}

    \begin{block}{Example Code Snippet}
        \begin{lstlisting}[language=Python]
import numpy as np
from sklearn.linear_model import LinearRegression

# Sample data: states and corresponding values
states = np.array([[1], [2], [3], [4], [5]])
values = np.array([10, 20, 30, 40, 50])  # Example values

# Create and fit the model
model = LinearRegression()
model.fit(states, values)

# Predict a state value
predicted_value = model.predict(np.array([[6]]))
print(f"Predicted value for state 6: {predicted_value[0]}")
        \end{lstlisting}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Overview of Function Approximation}
    Function approximation is a critical technique in reinforcement learning (RL) that allows us to estimate complex functions when the state or action space is too large to represent explicitly. 
    \begin{itemize}
        \item Enables generalization from observed states to unvisited ones.
        \item Crucial for effective decision-making in RL environments.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance of Function Approximation in RL}
    \begin{enumerate}
        \item \textbf{Scalability:} Handles large state and action spaces (e.g., chess, Go).
        \item \textbf{Generalization:} Leverages information from previously encountered states for new predictions.
        \item \textbf{Efficiency:} Reduces computational load and time for learning, leading to faster convergence.
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Techniques in Function Approximation}
    \begin{itemize}
        \item \textbf{Linear Function Approximation:}
        \begin{equation}
            V(s) \approx \theta^T \phi(s)
        \end{equation}
        Where \( \theta \) are weights and \( \phi(s) \) are feature vectors.
        
        \item \textbf{Non-linear Function Approximation:} 
        \begin{equation}
            V(s) = f_{\text{NN}}(s; \theta)
        \end{equation}
        
        \item \textbf{Tile Coding:} Discretizes continuous spaces using overlapping tiles for generalization.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Practical Applications of Function Approximation}
    Real-world examples include:
    \begin{itemize}
        \item \textbf{Autonomous Driving:} Approximates driving policies under various conditions.
        \item \textbf{Game Playing:} Algorithms like Deep Q-Networks (DQN) use deep neural networks for complex games.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points to Emphasize}
    \begin{itemize}
        \item Function approximation bridges computational capacity with real-world complexity in RL.
        \item Different methods have trade-offs in bias, variance, and efficiency.
        \item Understanding the mathematics behind methods is essential for optimizing algorithms.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Closing Note}
    As we move forward, we will explore the implementation of these methodologies and their impact on improving RL algorithms. Mastering function approximation is crucial for advancing in sophisticated RL applications.
\end{frame}


\end{document}