\frametitle{Markov Decision Processes (MDPs) Review - Key Points & Representation}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item MDPs systematically model rational behavior in complex, uncertain environments, seen in AI, robotics, and economics.
            \item They balance immediate rewards with long-term consequences of actions.
            \item Understanding MDP components is crucial for advanced reinforcement learning and optimization topics.
        \end{itemize}
    \end{block}

    \begin{block}{Mathematical Representation}
        The MDP can be represented as a tuple $(S, A, R, P)$ where:
        \begin{itemize}
            \item $S$: finite set of states
            \item $A$: finite set of actions
            \item $R$: reward function $R: S \times A \rightarrow \mathbb{R}$
            \item $P$: state transition function $P(s'|s,a)$: probability of reaching state $s'$ from state $s$ after action $a.
        \end{itemize}
    \end{block}
