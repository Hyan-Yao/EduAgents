\frametitle{Introduction to Markov Decision Processes - Objective}
    The expected cumulative reward for an agent in MDP can be expressed using the following formulation:

    \begin{block}{Objective}
        Maximize the expected return from state $ S $:
        \begin{equation}
            R = \sum_{t=0}^{\infty} \gamma^t r_t
        \end{equation}
        where $ r_t $ is the reward at time $ t $, and $ \gamma $ (0 â‰¤ $ \gamma $ < 1) is the discount factor that balances immediate and future rewards.
    \end{block}
