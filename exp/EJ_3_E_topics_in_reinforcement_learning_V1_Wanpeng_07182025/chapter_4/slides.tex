\documentclass[aspectratio=169]{beamer}

% Theme and Color Setup
\usetheme{Madrid}
\usecolortheme{whale}
\useinnertheme{rectangles}
\useoutertheme{miniframes}

% Additional Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}
\usepackage{hyperref}

% Custom Colors
\definecolor{myblue}{RGB}{31, 73, 125}
\definecolor{mygray}{RGB}{100, 100, 100}
\definecolor{mygreen}{RGB}{0, 128, 0}
\definecolor{myorange}{RGB}{230, 126, 34}
\definecolor{mycodebackground}{RGB}{245, 245, 245}

% Set Theme Colors
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=white, bg=myblue}
\setbeamercolor{title}{fg=myblue}
\setbeamercolor{section in toc}{fg=myblue}
\setbeamercolor{item projected}{fg=white, bg=myblue}
\setbeamercolor{block title}{bg=myblue!20, fg=myblue}
\setbeamercolor{block body}{bg=myblue!10}
\setbeamercolor{alerted text}{fg=myorange}

% Set Fonts
\setbeamerfont{title}{size=\Large, series=\bfseries}
\setbeamerfont{frametitle}{size=\large, series=\bfseries}
\setbeamerfont{caption}{size=\small}
\setbeamerfont{footnote}{size=\tiny}

% Custom Commands
\newcommand{\hilight}[1]{\colorbox{myorange!30}{#1}}
\newcommand{\concept}[1]{\textcolor{myblue}{\textbf{#1}}}

% Title Page Information
\title[Monte Carlo Methods]{Week 4: Monte Carlo Methods}
\author[J. Smith]{John Smith, Ph.D.}
\institute[University Name]{
  Department of Computer Science\\
  University Name\\
  \vspace{0.3cm}
  Email: email@university.edu\\
  Website: www.university.edu
}
\date{\today}

% Document Start
\begin{document}

\frame{\titlepage}

\begin{frame}[fragile]
    \frametitle{Introduction to Monte Carlo Methods}
    \begin{block}{Overview}
        A brief overview of Monte Carlo methods in reinforcement learning, their significance, and applications.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Monte Carlo Methods in Reinforcement Learning - Concepts}
    \begin{itemize}
        \item \textbf{What are Monte Carlo Methods?}
        \begin{itemize}
            \item Statistical techniques utilizing random sampling to achieve numerical results.
            \item Estimates value of actions or states from sampled experiences.
            \item Useful for unknown or complex environment models.
        \end{itemize}
        
        \item \textbf{Importance and Significance}
        \begin{itemize}
            \item Estimate value functions (V and Q) by averaging returns from multiple episodes.
            \item Model-free learning, suitable for environments with unpredictable dynamics.
            \item Faster convergence to accurate estimates in plentiful samples.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Characteristics and Applications}
    \begin{itemize}
        \item \textbf{Key Characteristics}
        \begin{itemize}
            \item \textbf{Episode-based:} Operate by collecting complete experiences rather than incremental updates.
            \item \textbf{Exploration:} Require state space exploration for accurate estimates; often utilize exploration strategies like $\epsilon$-greedy.
        \end{itemize}
        
        \item \textbf{Applications}
        \begin{itemize}
            \item \textbf{Game Playing:} Used to train agents in games (e.g., Go, Chess) through simulated plays to learn strategies.
            \item \textbf{Finance:} Employed in risk assessment and option pricing using random sampling of asset prices.
            \item \textbf{Robotics:} Assist in planning and decision-making amidst uncertainty in navigation tasks.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Example: Estimating State Value using Monte Carlo}
    Imagine training a robot to navigate a maze:
    \begin{enumerate}
        \item \textbf{Simulate Episodes:} Start from different positions and navigate to the goal, recording returns.
        \item \textbf{Average Returns:} Compute average returns for each state visited:
        \begin{equation}
            V(s) \approx \frac{1}{N(s)} \sum_{i=1}^{N(s)} R_i
        \end{equation}
        where \(N(s)\) is the number of visits to state \(s\) and \(R_i\) is the return after visiting \(s\).
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Next Steps}
    \begin{itemize}
        \item Monte Carlo methods are crucial for model-free reinforcement learning.
        \item Rely on random sampling and episodic experience to estimate value functions.
        \item Applications span diverse fields, making them versatile tools in AI and beyond.
    \end{itemize}
    
    \textbf{Next Steps:}
    In the next slide, we will delve deeper into the fundamental concepts of Monte Carlo methods, including the distinctions between First-Visit and Every-Visit Monte Carlo methods.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts of Monte Carlo Methods - Introduction}
    \begin{block}{Introduction to Monte Carlo Methods}
        Monte Carlo methods are a class of algorithms that rely on repeated random sampling to compute their results. They are widely used in reinforcement learning (RL) to estimate the value of states and actions. Understanding Monte Carlo methods helps in building robust RL models through simulation.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts of Monte Carlo Methods - Fundamental Concepts}
    \begin{enumerate}
        \item \textbf{First-Visit Monte Carlo (FVMC)}
        \begin{itemize}
            \item \textbf{Definition}: FVMC estimates the value of a state by averaging returns following the first time the state is visited in each episode.
            \item \textbf{Approach}:
            \begin{itemize}
                \item Track the states visited in each episode.
                \item Record the return \( G_t \) when state \( S \) is first encountered.
                \item Update the value \( V(S) \) as the average of all returns.
            \end{itemize}
            \item \textbf{Mathematical Update}:
            \begin{equation}
              V(S) \leftarrow V(S) + \frac{1}{N(S)} \left( G_t - V(S) \right)
            \end{equation}
            where \( N(S) \) is the number of times state \( S \) has been visited.
            \item \textbf{Use Case}: Best in environments like games where episodes can be easily defined.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts of Monte Carlo Methods - Every-Visit Monte Carlo}
    \begin{enumerate}
        \setcounter{enumi}{1}
        \item \textbf{Every-Visit Monte Carlo (EVMC)}
        \begin{itemize}
            \item \textbf{Definition}: EVMC estimates the value of a state by averaging returns following every visit to that state within an episode.
            \item \textbf{Approach}:
            \begin{itemize}
                \item In each episode, record the return \( G_t \) every time state \( S \) is visited.
                \item Update the estimated value by averaging the returns over all visits.
            \end{itemize}
            \item \textbf{Mathematical Update}:
            \begin{equation}
              V(S) \leftarrow V(S) + \frac{1}{N(S)} \left( G_t - V(S) \right)
            \end{equation}
            where \( N(S) \) is the total number of visits to state \( S \).
            \item \textbf{Use Case}: More effective in environments with repeated state visits, leading to stable estimates.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts of Monte Carlo Methods - Key Points and Conclusion}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item \textbf{Exploration vs. Exploitation}: Both methods stress the importance of exploring the state space for unbiased estimates.
            \item \textbf{Episode Sampling}: Reliance on episodes for the learning process.
            \item \textbf{Convergence}: FVMC and EVMC converge to the true value function with sufficient episodes.
        \end{itemize}
    \end{block}

    \begin{block}{Conclusion}
        Monte Carlo methods, especially FVMC and EVMC, are valuable for estimating state values in reinforcement learning. By understanding their differences, learners can effectively choose the method for their specific scenarios to optimize policies.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts of Monte Carlo Methods - Practical Implementation}
    \begin{block}{Python Code Snippet for FVMC}
    \begin{lstlisting}[language=Python]
def first_visit_mc(env, num_episodes):
    returns = {}
    for episode in range(num_episodes):
        state = env.reset()
        visited = set()  # Track visited states in this episode
        G = 0
        done = False
        while not done:
            action = env.sample_action()  # Implement an exploration strategy
            next_state, reward, done = env.step(action)
            G += reward
        
        for s in visited:
            if s not in returns:
                returns[s] = []
            returns[s].append(G)
            value_estimate[s] = sum(returns[s]) / len(returns[s])
    \end{lstlisting}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{First-Visit Monte Carlo - Overview}
    \begin{itemize}
        \item First-Visit Monte Carlo (FVMC) is used in reinforcement learning to estimate expected returns for states.
        \item Focuses on the first occurrence of each state in an episode, unlike Every-Visit Monte Carlo.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{First-Visit Monte Carlo - Approach}
    \begin{enumerate}
        \item \textbf{Episode Generation:} Generate episodes using a policy, from initial states to terminal states.
        
        \item \textbf{Identifying First Visits:} Keep track of the first encounter for each state in the episode.
        
        \item \textbf{Calculating Returns:} Compute return \( G_t \) from the first visit of state \( S_t \):
        \begin{equation}
            G_t = R_{t+1} + R_{t+2} + R_{t+3} + \ldots + R_T
        \end{equation}

        \item \textbf{Updating Value Estimates:} Adjust value estimate \( V(S) \) when a state is first visited:
        \begin{equation}
            V(S) \leftarrow V(S) + \alpha (G_t - V(S))
        \end{equation}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{First-Visit Monte Carlo - Applications and Key Points}
    \begin{itemize}
        \item \textbf{When to Use FVMC:}
        \begin{itemize}
            \item In non-static environments that may change over time.
            \item When states are visited infrequently (rare events).
            \item For exploratory policies ensuring diverse state visits.
        \end{itemize}
        
        \item \textbf{Example:} 
        - Episode: A → B → C with rewards: 1 (A to B), 0 (B to C), 5 (C to terminal).
        - First Visit Values:
        \begin{itemize}
            \item At A: \( G_A = 1 + 0 + 5 = 6 \)
            \item At B: \( G_B = 0 + 5 = 5 \)
            \item At C: \( G_C = 5 \)
        \end{itemize}
        
        \item \textbf{Key Points:}
        \begin{itemize}
            \item Focus on first occurrence reduces redundancy.
            \item Adaptive learning by combining new returns with existing estimates.
            \item Simple to implement, making it a good choice for practitioners.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Every-Visit Monte Carlo - Overview}
    \begin{block}{What is Every-Visit Monte Carlo?}
        Every-Visit Monte Carlo (EVMC) is a method in reinforcement learning and Monte Carlo simulations used to estimate the value of states in a Markov Decision Process (MDP). Unlike the First-Visit Monte Carlo method, which considers only the first occurrence of each state in an episode, EVMC accounts for every visit to each state in an episode. This provides a more robust estimate of the state’s value.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Every-Visit Monte Carlo - Characteristics}
    \begin{enumerate}
        \item \textbf{Value Estimation}:
        \begin{itemize}
            \item EVMC computes the average return received after each visit to a state.
            \item Update formula:
            \begin{equation}
                V(s) \leftarrow V(s) + \alpha (G - V(s))
            \end{equation}
            where \( G \) is the return from the visit and \( \alpha \) is the step-size parameter (0 < \( \alpha \) ≤ 1).
        \end{itemize}
        
        \item \textbf{Incremental Updates}:
        \begin{itemize}
            \item Value function updates can be performed incrementally, improving accuracy as states are visited multiple times.
        \end{itemize}
        
        \item \textbf{Data Utilization}:
        \begin{itemize}
            \item Uses all state visits in an episode, leading to efficient learning especially in high variance environments.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Every-Visit Monte Carlo - Use Cases}
    \begin{itemize}
        \item \textbf{Continuous Learning Environments}: Effective in scenarios with frequent state visits:
        \begin{itemize}
            \item Chess
            \item Video games (e.g., OpenAI Gym environments)
            \item Robotics
        \end{itemize}
        
        \item \textbf{Policy Evaluation}: Used to evaluate policy performance by averaging over many episodes, providing thorough state value estimations.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Every-Visit Monte Carlo - Example Illustration}
    Consider a simple game grid where an agent receives various rewards for visiting different states:
    
    \begin{itemize}
        \item Suppose the agent visits state \( S1 \) three times with returns of \( 2, 4, \) and \( 1 \):
        \begin{equation}
            V(S1) = \frac{2 + 4 + 1}{3} = \frac{7}{3} \approx 2.33
        \end{equation}
        \item By continuously updating \( V(S1) \) with each visit, the value stabilizes as more data is collected.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Every-Visit Monte Carlo - Key Points}
    \begin{enumerate}
        \item \textbf{Scalability}: EVMC enhances effectiveness in environments with repeated state visits compared to First-Visit method.
        
        \item \textbf{Robustness}: Averages multiple returns, providing a more representative estimate of the true value and reducing variance.
        
        \item \textbf{Step-Size Sensitivity}: The choice of \( \alpha \) influences convergence; selecting a well-suited \( \alpha \) can balance stability and convergence speed.
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{Monte Carlo vs Dynamic Programming}
    \begin{itemize}
        \item Comparison of Monte Carlo methods and Dynamic Programming
        \item Discussing advantages and disadvantages
    \end{itemize}
\end{frame}

\begin{frame}{Clear Explanations of Concepts}
    \begin{block}{Monte Carlo Methods}
        \begin{itemize}
            \item Computational algorithms using repeated random sampling.
            \item Example: Updates value estimates based on complete episodes in reinforcement learning.
        \end{itemize}
    \end{block}

    \begin{block}{Dynamic Programming}
        \begin{itemize}
            \item Optimization technique solving complex problems via simpler subproblems.
            \item Example: Calculates Fibonacci numbers using previously computed values.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}{Comparison of Techniques}
    \begin{columns}
        \begin{column}{0.5\textwidth}
            \textbf{Advantages of Monte Carlo:}
            \begin{itemize}
                \item Flexibility: Applicable to diverse problems without needing full understanding.
                \item Simplicity: Easier to implement for complex problems.
                \item No need for environment dynamics: Focuses on sampling.
            \end{itemize}

            \textbf{Disadvantages of Monte Carlo:}
            \begin{itemize}
                \item High variance: Requires large samples for accurate estimates.
                \item Long convergence time: Slow to converge, especially with delayed rewards.
            \end{itemize}
        \end{column}

        \begin{column}{0.5\textwidth}
            \textbf{Advantages of Dynamic Programming:}
            \begin{itemize}
                \item Guaranteed convergence: Faster convergence to optimal solutions.
                \item Lower variance: Produces lower-variance estimates.
            \end{itemize}

            \textbf{Disadvantages of Dynamic Programming:}
            \begin{itemize}
                \item Computationally expensive: High resource demands in larger state spaces.
                \item Requires full knowledge of the model: Needs complete state transitions.
            \end{itemize}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Key Points to Emphasize}
    \begin{itemize}
        \item Monte Carlo methods and Dynamic Programming serve different purposes.
        \item Choice depends on problem structure, available information, and computational resources.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{Code Snippet Example}
    \textbf{Monte Carlo Estimation:}
    \begin{lstlisting}[language=Python]
import numpy as np

def monte_carlo_estimate(n_episodes):
    returns = []
    for episode in range(n_episodes):
        returns.append(simulate_episode()) 
    return np.mean(returns)

def simulate_episode():
    pass
    \end{lstlisting}

    \textbf{Dynamic Programming Example for Fibonacci:}
    \begin{lstlisting}[language=Python]
def fibonacci(n):
    fib_table = [0] * (n + 1)
    fib_table[1] = 1
    for i in range(2, n + 1):
        fib_table[i] = fib_table[i - 1] + fib_table[i - 2]
    return fib_table[n]
    \end{lstlisting}
\end{frame}

\begin{frame}{Conclusion}
    \begin{itemize}
        \item Understanding both Monte Carlo methods and Dynamic Programming equips us with tools to solve complex problems.
        \item The choice of method depends on the scenario at hand.
    \end{itemize}
\end{frame}

\begin{frame}{Applications of Monte Carlo Methods}
    \begin{block}{Overview}
        Monte Carlo methods are a class of computational algorithms that rely on repeated random sampling to obtain numerical results, particularly useful for problems involving uncertainty.
    \end{block}
\end{frame}

\begin{frame}{Key Applications}
    \begin{enumerate}
        \item \textbf{Finance and Risk Assessment}
        \item \textbf{Physics and Engineering}
        \item \textbf{Computer Graphics}
        \item \textbf{Healthcare and Medicine}
        \item \textbf{Supply Chain Management}
    \end{enumerate}
\end{frame}

\begin{frame}{Finance and Risk Assessment}
    \begin{itemize}
        \item \textbf{Portfolio Optimization}: Assesses performance of portfolio strategies under various market conditions.
        \item \textbf{Option Pricing}: Prices complex financial derivatives using simulations of stock price paths.
    \end{itemize}
    \begin{block}{Example}
        To estimate the expected value of a complex derivative, simulate multiple paths and calculate the average value.
    \end{block}
\end{frame}

\begin{frame}[fragile]{Option Pricing Example}
    \begin{lstlisting}[language=Python]
import numpy as np

# Example of Monte Carlo simulation for option pricing
S0 = 100  # Initial stock price
K = 100   # Strike price
T = 1     # Time to maturity
r = 0.05  # Risk-free rate
sigma = 0.2  # Volatility
n = 10000  # Number of simulations

# Simulating end stock prices
ST = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * np.random.normal(0, 1, n))
option_payoffs = np.maximum(ST - K, 0)  # Call option payoff
option_price = np.exp(-r * T) * np.mean(option_payoffs)  # Present value of expected payoff
print(option_price)
    \end{lstlisting}
\end{frame}

\begin{frame}{Other Applications}
    \begin{itemize}
        \item \textbf{Physics and Engineering}
            \begin{itemize}
                \item Particle Simulation: Analyzes particle interactions in mediums.
                \item Heat Transfer Modeling: Simulates heat distribution in complex systems.
            \end{itemize}
        \item \textbf{Computer Graphics}
            \begin{itemize}
                \item Rendering Techniques: Utilizes ray tracing to simulate light interactions.
                \item Global Illumination: Simulates light bouncing between surfaces.
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Additional Applications}
    \begin{itemize}
        \item \textbf{Healthcare and Medicine}
            \begin{itemize}
                \item Epidemiology: Models spread of diseases.
                \item Clinical Trials: Simulates patient responses to treatments.
            \end{itemize}
        \item \textbf{Supply Chain Management}
            \begin{itemize}
                \item Inventory Optimization: Understands demand and supply fluctuations.
                \item Logistical Planning: Evaluates transport and supply chain routes.
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Conclusion}
    \begin{block}{Key Points}
        \begin{itemize}
            \item \textbf{Versatility}: Handles complex problems across various scientific domains.
            \item \textbf{Robustness}: Quantifies uncertainty offering insights beyond deterministic methods.
            \item \textbf{Efficiency with Complexity}: Maintains efficiency as problems become intricate.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}{Engagement & Exploration}
    \begin{block}{Note to Students}
        Engage with practical coding exercises to understand the full power of Monte Carlo methods. Explore platforms like Python for implementation and analysis.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges and Limitations of Monte Carlo Methods - Overview}
    \begin{itemize}
        \item Monte Carlo Methods (MCM) are powerful statistical tools for numerical analysis and simulation.
        \item Despite their versatility, they present inherent challenges and limitations.
        \item Acknowledging these factors is crucial for effective implementation.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges of Monte Carlo Methods}
    \begin{enumerate}
        \item \textbf{Computational Intensity}
            \begin{itemize}
                \item Requires large samples for accuracy, leading to high computational demands.
                \item \emph{Example:} Simulating option prices may need millions of sample paths.
            \end{itemize}
        \item \textbf{Convergence Issues}
            \begin{itemize}
                \item Accuracy improves with sample size, but convergence can be slow.
                \item \emph{Key Point:} Central Limit Theorem; reliability depends on sufficient samples.
            \end{itemize}
        \item \textbf{High Variance in Estimates}
            \begin{itemize}
                \item Random sampling may yield high variance, leading to misleading results.
                \item \emph{Example:} Poor sample representation can significantly deviate area estimates.
            \end{itemize}
        \item \textbf{Dependence on Random Number Quality}
            \begin{itemize}
                \item Accuracy is sensitive to the quality of random number generators.
                \item \emph{Key Point:} Use high-quality pseudo-random number generators.
            \end{itemize}
        \item \textbf{Parameter Sensitivity}
            \begin{itemize}
                \item Estimates can vary significantly based on chosen parameters.
                \item \emph{Example:} Variations in volatility drastically alter risk assessments.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Limitations of Monte Carlo Methods}
    \begin{enumerate}
        \item \textbf{Dimensionality Problem}
            \begin{itemize}
                \item Increasing dimensionality exponentially raises sample requirements.
                \item \emph{Illustration:} Multi-dimensional volume increases non-linearly, reducing sample density.
            \end{itemize}
        \item \textbf{Not Always the Best Approach}
            \begin{itemize}
                \item Deterministic methods might be more efficient for some problems.
                \item \emph{Example:} Numerical quadrature may outperform Monte Carlo for low-dimensional integrals.
            \end{itemize}
        \item \textbf{Difficulties in Analyzing Output}
            \begin{itemize}
                \item Interpreting Monte Carlo results is complex, especially regarding uncertainty.
                \item \emph{Key Point:} Analyze distribution, not just mean results.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion}
    \begin{itemize}
        \item Recognizing the challenges and limitations of Monte Carlo methods is vital for effective application.
        \item This understanding leads to more tailored and efficient deployment in practical scenarios.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Quick Reference Formula}
    The Monte Carlo estimate for an integral \( I \) over a region \( D \):
    \begin{equation}
        I \approx \frac{V_D}{N} \sum_{i=1}^{N} f(X_i)
    \end{equation}
    Where:
    \begin{itemize}
        \item \( V_D \) = volume of region \( D \)
        \item \( N \) = number of random samples
        \item \( f(X_i) \) = function value at sample point \( X_i \)
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Future Directions - Summary}
    \begin{block}{Key Points Covered in the Chapter}
        \begin{enumerate}
            \item \textbf{Understanding Monte Carlo Methods}: 
            Monte Carlo methods utilize random sampling for numerical results across various fields.

            \item \textbf{Implementation Techniques}:
            \begin{itemize}
                \item Basic Monte Carlo Simulation for estimations.
                \item Variance Reduction Techniques to enhance precision.
            \end{itemize}

            \item \textbf{Challenges and Limitations}: 
            Considerations for computational expenses and noise in results.
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Future Directions - Applications}
    \begin{block}{Potential Applications of Monte Carlo Methods}
        \begin{enumerate}
            \item \textbf{Finance}:
            Pricing complex derivatives and optimizing portfolios.
            
            \item \textbf{Artificial Intelligence}:
            Application in reinforcement learning through Monte Carlo Tree Search (MCTS) in strategic games.
            
            \item \textbf{Healthcare}:
            Evaluating treatment strategies and optimizing resource allocation.
            
            \item \textbf{Climate Modeling}:
            Assessing uncertainties in predicting extreme weather events.
            
            \item \textbf{Engineering}:
            Reliability analysis and risk assessment for systems.
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Future Directions - Formulas}
    \begin{block}{Summarizing Formulas & Concepts}
        \textbf{Basic Estimator}:
        \begin{equation}
            \hat{\mu} = \frac{1}{N} \sum_{i=1}^{N} X_i \quad \text{where } X_i \text{ are random samples}
        \end{equation}

        \textbf{Variance Reduction Techniques}:
        \begin{itemize}
            \item \textbf{Stratified Sampling}: Divide the population into strata and sample within each.
            \item \textbf{Importance Sampling}: Sample from a distribution that focuses on significant regions.
        \end{itemize}
    \end{block}
    
    \begin{block}{Final Emphasis}
        \begin{itemize}
            \item Diverse applications and innovations in Monte Carlo methods.
            \item Understanding limitations can enhance their effectiveness.
        \end{itemize}
    \end{block}
\end{frame}


\end{document}