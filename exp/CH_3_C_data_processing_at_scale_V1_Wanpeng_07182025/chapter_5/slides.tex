\documentclass[aspectratio=169]{beamer}

% Theme and Color Setup
\usetheme{Madrid}
\usecolortheme{whale}
\useinnertheme{rectangles}
\useoutertheme{miniframes}

% Additional Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}
\usepackage{hyperref}

% Custom Colors
\definecolor{myblue}{RGB}{31, 73, 125}
\definecolor{mygray}{RGB}{100, 100, 100}
\definecolor{mygreen}{RGB}{0, 128, 0}
\definecolor{myorange}{RGB}{230, 126, 34}
\definecolor{mycodebackground}{RGB}{245, 245, 245}

% Set Theme Colors
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=white, bg=myblue}
\setbeamercolor{title}{fg=myblue}
\setbeamercolor{section in toc}{fg=myblue}
\setbeamercolor{item projected}{fg=white, bg=myblue}
\setbeamercolor{block title}{bg=myblue!20, fg=myblue}
\setbeamercolor{block body}{bg=myblue!10}
\setbeamercolor{alerted text}{fg=myorange}

% Set Fonts
\setbeamerfont{title}{size=\Large, series=\bfseries}
\setbeamerfont{frametitle}{size=\large, series=\bfseries}
\setbeamerfont{caption}{size=\small}
\setbeamerfont{footnote}{size=\tiny}

% Code Listing Style
\lstdefinestyle{customcode}{
  backgroundcolor=\color{mycodebackground},
  basicstyle=\footnotesize\ttfamily,
  breakatwhitespace=false,
  breaklines=true,
  commentstyle=\color{mygreen}\itshape,
  keywordstyle=\color{blue}\bfseries,
  stringstyle=\color{myorange},
  numbers=left,
  numbersep=8pt,
  numberstyle=\tiny\color{mygray},
  frame=single,
  framesep=5pt,
  rulecolor=\color{mygray},
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=2,
  captionpos=b
}
\lstset{style=customcode}

% Custom Commands
\newcommand{\hilight}[1]{\colorbox{myorange!30}{#1}}
\newcommand{\source}[1]{\vspace{0.2cm}\hfill{\tiny\textcolor{mygray}{Source: #1}}}
\newcommand{\concept}[1]{\textcolor{myblue}{\textbf{#1}}}
\newcommand{\separator}{\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}}

% Title Page Information
\title[Week 5: Data Processing Frameworks]{Week 5: Data Processing Frameworks - Apache Hadoop}
\author[J. Smith]{John Smith, Ph.D.}
\institute[University Name]{
  Department of Computer Science\\
  University Name\\
  \vspace{0.3cm}
  Email: email@university.edu\\
  Website: www.university.edu
}
\date{\today}

% Document Start
\begin{document}

\frame{\titlepage}

\begin{frame}[fragile]
    \titlepage
\end{frame}

\begin{frame}[fragile]
    \frametitle{Overview of Apache Hadoop}

    \begin{block}{Definition}
        Apache Hadoop is a widely-used open-source framework designed for processing and storing vast amounts of data in a distributed computing environment.
    \end{block}

    \begin{itemize}
        \item Efficient handling of large datasets.
        \item Overcomes limitations of traditional data processing solutions.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Components of Hadoop}

    \begin{enumerate}
        \item \textbf{Hadoop Distributed File System (HDFS)}
            \begin{itemize}
                \item Stores data across multiple machines.
                \item High availability and fault tolerance.
                \item Data is split into large blocks (usually 128 MB).
            \end{itemize}

        \item \textbf{MapReduce}
            \begin{itemize}
                \item A programming model for processing large datasets.
                \item \textbf{Map}: Processes input data into key-value pairs.
                \item \textbf{Reduce}: Aggregates the results from Map.
                \item \textbf{Example}: Counting word occurrences.
            \end{itemize}

        \item \textbf{YARN (Yet Another Resource Negotiator)}
            \begin{itemize}
                \item Resource management layer.
                \item Manages tasks across the cluster.
            \end{itemize}

        \item \textbf{Hadoop Common}
            \begin{itemize}
                \item Common utilities and libraries for Hadoop modules.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Why Use Hadoop?}

    \begin{itemize}
        \item \textbf{Scalability}: Scales up from one server to thousands.
        \item \textbf{Cost-Effectiveness}: Utilizes commodity hardware.
        \item \textbf{Flexibility}: Handles various data formats.
        \item \textbf{Fault Tolerance}: Prevents data loss through replication.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Real-World Applications}

    \begin{itemize}
        \item \textbf{Data Warehousing}: Used by organizations for storage and querying.
        \item \textbf{Log Analysis}: Monitoring performance and security using server logs.
        \item \textbf{Data Mining}: Applications in recommendation systems and fraud detection.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Takeaways}

    \begin{itemize}
        \item Hadoop is vital for efficient big data processing.
        \item Major components: HDFS, MapReduce, YARN.
        \item Offers flexibility and scalability for modern data needs.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Example Code Snippet (MapReduce)}

    \begin{lstlisting}[language=Java]
public class WordCount {
    public static class TokenizerMapper extends Mapper<Object, Text, Text, IntWritable> {
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();

        public void map(Object key, Text value, Context context) 
                throws IOException, InterruptedException {
            StringTokenizer itr = new StringTokenizer(value.toString());
            while (itr.hasMoreTokens()) {
                word.set(itr.nextToken());
                context.write(word, one);
            }
        }
    }
    ...
}
    \end{lstlisting}

    Use this code snippet as a foundation for your own MapReduce jobs.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Big Data}
    \begin{block}{Definition}
        Big Data refers to extremely large datasets that can be analyzed computationally to reveal patterns, trends, and associations, particularly related to human behavior and interactions.
    \end{block}
    \begin{block}{Characteristics}
        Big Data is often defined by the "3 Vs":
        \begin{itemize}
            \item \textbf{Volume}: Massive amounts of data generated every second.
            \item \textbf{Velocity}: The speed at which data is generated and processed.
            \item \textbf{Variety}: Different data types (structured, semi-structured, unstructured).
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Terminology - Data Processing and Storage}
    \begin{enumerate}
        \item \textbf{Data Processing}:
            \begin{itemize}
                \item Transformation of raw data into meaningful information.
                \item Essential for generating insights to inform strategic decisions in various industries.
            \end{itemize}
        \item \textbf{Data Lake vs. Data Warehouse}:
            \begin{itemize}
                \item \textbf{Data Lake}: 
                    A repository for storing vast amounts of raw data in its native format.
                \item \textbf{Data Warehouse}: 
                    A centralized repository that stores structured data, optimized for querying.
            \end{itemize}
            \item \textit{Illustration}: A Data Lake is like a reservoir for raw data, while a Data Warehouse is like a library for structured data.
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Terminology - NoSQL and Frameworks}
    \begin{enumerate}
        \setcounter{enumi}{3}
        \item \textbf{NoSQL Databases}:
            \begin{itemize}
                \item Designed to store and retrieve data in a non-relational format.
                \item Suitable for handling big data types.
                \item \textbf{Examples}: MongoDB, Cassandra, Redis.
            \end{itemize}
        \item \textbf{Data Processing Frameworks}:
            \begin{itemize}
                \item Tools and libraries for processing and analyzing big data efficiently.
                \item \textbf{Example}: Apache Hadoop for distributed processing of large data sets.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{What is Apache Hadoop?}
    \begin{block}{Introduction}
        Apache Hadoop is an open-source software framework designed for the distributed storage and processing of large data sets using simple programming models.
    \end{block}
    \begin{itemize}
        \item Scales from single servers to thousands of machines.
        \item Handles vast amounts of unstructured data.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Components of Apache Hadoop}
    \begin{enumerate}
        \item \textbf{Hadoop Distributed File System (HDFS)}
        \begin{itemize}
            \item Provides high-throughput access to application data.
            \item Splits large files into smaller blocks and distributes them across a cluster for fault tolerance.
        \end{itemize}

        \item \textbf{MapReduce}
        \begin{itemize}
            \item Programming model for processing large data sets.
            \item Consists of:
            \begin{itemize}
                \item \textit{Map}: Transforms input data into key-value pairs.
                \item \textit{Reduce}: Merges mapped data to produce final results.
            \end{itemize}
        \end{itemize}

        \item \textbf{YARN (Yet Another Resource Negotiator)}
        \begin{itemize}
            \item Manages and schedules resources across the cluster.
            \item Allows multiple data processing engines to run simultaneously.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Purpose and Real-World Application}
    \begin{block}{Purpose of Apache Hadoop}
        \begin{itemize}
            \item \textbf{Scalability:} Efficiently scales to handle increased data.
            \item \textbf{Cost-Effectiveness:} Uses commodity hardware for large data sets.
            \item \textbf{Fault Tolerance:} Automatically replicates data and components against failures.
        \end{itemize}
    \end{block}
    
    \begin{block}{Real-World Example}
        Consider a global e-commerce platform:
        \begin{itemize}
            \item Collects millions of transactions daily.
            \item Uses HDFS for storage and MapReduce for insights on sales patterns and customer behavior.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Conclusion}
    \begin{itemize}
        \item Apache Hadoop is foundational to Big Data analytics.
        \item Core components (HDFS, MapReduce, YARN) are crucial for maximizing data processing capabilities.
        \item Community-driven development leads to continuous enhancements and features.
    \end{itemize}

    \begin{block}{Conclusion}
        Apache Hadoop is critical in the data ecosystem, enabling efficient storage and processing, thus unlocking valuable insights while remaining scalable and cost-effective.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Hadoop's Ecosystem - Overview}
    \begin{block}{Overview of Hadoop's Ecosystem}
        Apache Hadoop is a powerful framework designed to process and store large datasets across clusters of computers using simple programming models. Its ecosystem consists of various components that work together for efficient data processing, storage, and management.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Hadoop's Ecosystem - Key Components}
    \begin{enumerate}
        \item \textbf{Hadoop Distributed File System (HDFS)}
        \begin{itemize}
            \item A distributed file system for commodity hardware.
            \item Features:
                \begin{itemize}
                    \item High fault tolerance through data replication.
                    \item Divides files into large blocks (default size: 128MB or 256MB).
                    \item Example: Splits files into blocks replicated across different machines.
                \end{itemize}
        \end{itemize}
        
        \item \textbf{YARN (Yet Another Resource Negotiator)}
        \begin{itemize}
            \item Resource management layer allowing multiple data processing engines.
            \item Functionality:
                \begin{itemize}
                    \item Manages cluster resources for various applications.
                    \item Supports multi-tenancy for concurrent application execution.
                \end{itemize}
            \item Example: Runs MapReduce and Spark simultaneously.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Hadoop's Ecosystem - MapReduce}
    \begin{block}{MapReduce}
        A programming model for processing large datasets using a parallel, distributed algorithm on a cluster.
        
        \begin{itemize}
            \item \textbf{Map}: Produces intermediate key-value pairs.
            \begin{lstlisting}[language=java]
public class MapExample extends Mapper<LongWritable, Text, Text, IntWritable> {
    public void map(LongWritable key, Text value, Context context) {
        // Your map logic here
    }
}
            \end{lstlisting}
            
            \item \textbf{Reduce}: Aggregates intermediate pairs to produce final results.
            \begin{lstlisting}[language=java]
public class ReduceExample extends Reducer<Text, IntWritable, Text, IntWritable> {
    public void reduce(Text key, Iterable<IntWritable> values, Context context) {
        // Your reduce logic here
    }
}
            \end{lstlisting}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Hadoop's Ecosystem - Other Components}
    \begin{itemize}
        \item \textbf{Apache Hive}: Data warehouse software with SQL-like querying (HiveQL).
        \item \textbf{Apache Pig}: Platform for creating programs using a high-level scripting language (Pig Latin).
        \item \textbf{Apache HBase}: Non-relational (NoSQL) database on top of HDFS.
        \item \textbf{Apache ZooKeeper}: Centralized service for configuration and distributed synchronization.
        \item \textbf{Apache Sqoop}: Tool for data transfer between Hadoop and relational databases.
        \item \textbf{Apache Flume}: Service for collecting and moving large volumes of log data into Hadoop.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Hadoop's Ecosystem - Conclusion}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item Robust design allows efficient and reliable processing of vast data.
            \item Each component serves a unique role in data management.
            \item Understanding these components is crucial for utilizing Hadoop in big data solutions.
        \end{itemize}
    \end{block}
    \begin{block}{Conclusion}
        Hadoop's ecosystem is a powerful toolset integrating various components for big data processing and analytics. Familiarity with these elements is essential for practitioners addressing data-related challenges.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{HDFS Architecture - Overview}
    \begin{block}{Overview of HDFS}
        The Hadoop Distributed File System (HDFS) is a key component of the Hadoop ecosystem, designed to handle large volumes of data across clusters of computers. It provides high-throughput access to application data suitable for storing large datasets efficiently.
    \end{block}
    
    \begin{itemize}
        \item \textbf{Scalability:} Can scale out to manage petabytes of data by adding more nodes.
        \item \textbf{Fault Tolerance:} Data is replicated to ensure reliability in hardware failures.
        \item \textbf{Designed for Large Files:} Optimized for large files (ideal block size is 128 MB or 256 MB).
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{HDFS Architecture - Components}
    \begin{block}{HDFS Architecture Components}
        \begin{enumerate}
            \item \textbf{NameNode:}
                \begin{itemize}
                    \item The master server managing the filesystem namespace.
                    \item \textbf{Responsibilities:}
                        \begin{itemize}
                            \item Maintains metadata (filename, permissions, block locations).
                            \item Coordinates replication ensuring data reliability.
                        \end{itemize}
                \end{itemize}
                
            \item \textbf{DataNodes:}
                \begin{itemize}
                    \item Slave nodes that store the actual data blocks.
                    \item \textbf{Responsibilities:}
                        \begin{itemize}
                            \item Serve read/write requests.
                            \item Send heartbeats and block reports to the NameNode.
                        \end{itemize}
                \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{HDFS Architecture - Data Blocks and Replication}
    \begin{block}{Data Blocks and Replication}
        \begin{itemize}
            \item \textbf{Data Blocks:}
                \begin{itemize}
                    \item HDFS divides each file into blocks (typically 128 MB).
                    \item Each block is stored in a DataNode, allowing parallel processing and fault tolerance.
                \end{itemize}
            \item \textbf{Replication:}
                \begin{itemize}
                    \item Each data block is replicated across multiple DataNodes (default is 3 replicas).
                    \item \textbf{Strategy:} Blocks stored across different racks to prevent loss in case of rack failure.
                \end{itemize}
            \item \textbf{Example:}
                \begin{itemize}
                    If a 1 GB file is stored with a block size of 256 MB, it is divided into four blocks with three copies each, distributed across various DataNodes.
                \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{HDFS Architecture - Key Points and Conclusion}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item HDFS's architecture is designed to provide reliability and efficiency for large-scale data.
            \item Separation of NameNode and DataNodes enhances performance and fault tolerance.
            \item Understanding block replication is critical for data availability/integrity in distributed systems.
        \end{itemize}
    \end{block}
    
    \begin{block}{Conclusion}
        Understanding HDFS’s architecture (NameNode, DataNodes, data blocks, and replication) is crucial for effective implementation and management of big data solutions.
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{Data Processing Techniques in Hadoop}
    \begin{block}{Overview}
        Discuss essential processing techniques using Hadoop, such as MapReduce and data flow.
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{Key Processing Techniques}
    \begin{itemize}
        \item Hadoop is a robust framework for large-scale data processing.
        \item **Two primary techniques**:
        \begin{enumerate}
            \item MapReduce
            \item Data Flow
        \end{enumerate}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{MapReduce}
    \begin{itemize}
        \item **Definition**: A programming model for distributed processing of large datasets.
        \item **Components**:
        \begin{itemize}
            \item \textbf{Mapper}: Processes input data as key/value pairs.
            \item \textbf{Reducer}: Aggregates outputs from the Mapper.
        \end{itemize}
        \item **Workflow**:
        \begin{enumerate}
            \item Mapping Phase
            \item Shuffling \& Sorting
            \item Reducing Phase
        \end{enumerate}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{MapReduce Examples}
    \begin{itemize}
        \item **Mapping Phase Example**: Counting word frequency.
        \begin{lstlisting}[language=Python]
def mapper(key, value):
    for word in value.split():
        emit(word, 1)
        \end{lstlisting}
        \item **Reducing Phase Example**: Summing word counts.
        \begin{lstlisting}[language=Python]
def reducer(key, values):
    total = sum(values)
    emit(key, total)
        \end{lstlisting}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Data Flow in Hadoop}
    \begin{itemize}
        \item **Definition**: Describes data movement and processing in Hadoop.
        \item **Pipeline Structure**:
        \begin{enumerate}
            \item Data is stored in HDFS.
            \item MapReduce jobs read from HDFS and write results back.
        \end{enumerate}
        \item **Example**: Running a Hive query with HDFS and MapReduce.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Key Points to Emphasize}
    \begin{itemize}
        \item **Scalability**: Techniques are designed to scale horizontally.
        \item **Fault Tolerance**: Hadoop ensures reliable process recovery.
        \item **Flexibility**: Supports various programming languages in MapReduce.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Summary}
    \begin{block}{Conclusion}
        Understanding these data processing techniques is crucial for using Hadoop effectively. MapReduce allows efficient data processing and describes how data is managed, making big data analysis feasible.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Advantages of Using Hadoop - Introduction}
    \begin{itemize}
        \item Apache Hadoop is a powerful data processing framework for large datasets.
        \item It is essential for organizations to understand Hadoop's advantages for effective big data leverage.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Advantages of Using Hadoop - Key Advantages}
    \begin{enumerate}
        \item Fault Tolerance
        \item Scalability
        \item Cost-Effectiveness
        \item Flexibility
        \item High Throughput
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Advantages of Using Hadoop - Fault Tolerance}
    \begin{block}{Definition}
        The capability of a system to continue functioning properly despite component failures.
    \end{block}
    \begin{itemize}
        \item Data replicas are stored across different nodes in a cluster.
        \item \textbf{Example:} If Node A fails, tasks redirect to Node B.
        \item \textbf{Key Point:} This redundancy allows for uninterrupted processing.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Advantages of Using Hadoop - Scalability}
    \begin{block}{Definition}
        Ability to increase system capacity by adding resources without disrupting operations.
    \end{block}
    \begin{itemize}
        \item \textbf{Horizontal Scaling:} Add nodes to the cluster vs. vertical scaling (upgrading hardware).
        \item \textbf{Example:} Adding nodes to accommodate growing data.
        \item \textbf{Key Point:} Flexibility for handling increasing data volumes without significant redesign.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Advantages of Using Hadoop - Cost-Effectiveness}
    \begin{itemize}
        \item Hadoop operates on commodity hardware, reducing costs.
        \item \textbf{Example:} Use affordable machines instead of expensive servers.
        \item As an open-source framework, it eliminates licensing fees.
        \item \textbf{Key Point:} This leads to significant reductions in total cost of ownership.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Advantages of Using Hadoop - Flexibility}
    \begin{block}{Handling Varied Data Types}
        Hadoop processes structured, semi-structured, and unstructured data.
    \end{block}
    \begin{itemize}
        \item \textbf{Example:} Analyze data from diverse sources like social media and databases.
        \item \textbf{Key Point:} Enables comprehensive data analysis to extract valuable insights.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Advantages of Using Hadoop - High Throughput}
    \begin{block}{Optimized for Large-Scale Data}
        Hadoop is designed for high throughput, processing vast amounts of data quickly.
    \end{block}
    \begin{itemize}
        \item Batch processing improves efficiency through task distribution across nodes.
        \item \textbf{Key Point:} Faster insights enable timely decision-making.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Advantages of Using Hadoop - Conclusion}
    \begin{itemize}
        \item Hadoop is a robust and flexible framework for modern data processing.
        \item Key advantages: fault tolerance, scalability, cost-effectiveness, and high throughput.
        \item Essential for businesses to harness the full potential of big data.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Advantages of Using Hadoop - Takeaway}
    \begin{itemize}
        \item Understanding Hadoop's strengths supports informed decisions in data processing.
        \item The next slide will explore practical applications with real-world datasets.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Implementing Hadoop – Practical Assignment}
    \begin{block}{Overview}
        In this practical assignment, students will engage with real-world data processing tasks using Apache Hadoop to familiarize themselves with its ecosystem.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Assignment Objective}
    \begin{itemize}
        \item Gain hands-on experience with Hadoop tools.
        \item Understand the data processing workflow.
        \item Analyze and summarize data insights.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Steps to Complete the Assignment - Part 1}
    \begin{enumerate}
        \item \textbf{Dataset Selection}
            \begin{itemize}
                \item Select a large dataset relevant to your field of study (e.g., social media sentiments, public health data).
                \item Ensure the dataset has a suitable size (>10,000 records).
            \end{itemize}
        
        \item \textbf{Setting Up Hadoop Environment}
            \begin{itemize}
                \item Install Hadoop locally or use a cloud-based service.
                \item Configure HDFS for data storage.
            \end{itemize}
        
        \item \textbf{Data Ingestion}
            \begin{itemize}
                \item Upload your dataset to HDFS:
                \begin{lstlisting}[language=Shell]
hadoop fs -put /path/to/local/dataset.csv /user/hadoop/
                \end{lstlisting}
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Steps to Complete the Assignment - Part 2}
    \begin{enumerate}[resume]
        \item \textbf{Data Processing with MapReduce}
            \begin{itemize}
                \item Implement a MapReduce job to process your data.
                \item Example of Mapper function:
                \begin{lstlisting}[language=Java]
public static class TokenizerMapper extends Mapper<Object, Text, Text, IntWritable> {
    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
        // Splitting data lines and emitting key-value pairs
    }
}
                \end{lstlisting}
                \item Example of Reducer function:
                \begin{lstlisting}[language=Java]
public static class IntSumReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
    public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
        // Calculating the sum
    }
}
                \end{lstlisting}
            \end{itemize}

        \item \textbf{Execution}
            \begin{itemize}
                \item Compile and run your MapReduce job:
                \begin{lstlisting}[language=Shell]
yarn jar my-hadoop-job.jar my.package.MyDriver /user/hadoop/dataset.csv /user/hadoop/output
                \end{lstlisting}
            \end{itemize}
            
        \item \textbf{Data Analysis}
            \begin{itemize}
                \item Retrieve and analyze results from HDFS:
                \begin{lstlisting}[language=Shell]
hadoop fs -cat /user/hadoop/output/part-r-00000
                \end{lstlisting}
                \item Identify trends, calculate statistics, etc.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Reporting and Key Points}
    \begin{itemize}
        \item \textbf{Reporting Results:}
            \begin{itemize}
                \item Summarize findings, processing techniques used, insights, and challenges.
            \end{itemize}
        
        \item \textbf{Key Points to Emphasize:}
            \begin{itemize}
                \item Essential components of Hadoop: HDFS and MapReduce.
                \item Data processing cycle: Ingestion → Processing → Analysis.
                \item Choosing the right dataset is critical for practical insights.
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Additional Considerations}
    \begin{itemize}
        \item Explore other Hadoop ecosystem tools (e.g., Apache Hive, Apache Pig) for advanced tasks.
        \item Document your code and findings for future reference and improvement.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Hadoop Use Cases}
    Examine various case studies where Hadoop has been effectively utilized to solve real-world data processing challenges.
\end{frame}

\begin{frame}
    \frametitle{Introduction to Hadoop Use Cases}
    \begin{itemize}
        \item Apache Hadoop has transformed data processing by distributing storage and computation.
        \item Allows processing of large datasets in a fault-tolerant and scalable manner.
        \item Case studies demonstrate its effectiveness in real-world data processing challenges.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Case Study: Yahoo! and Web Indexing}
    \begin{itemize}
        \item \textbf{Challenge:} Process extensive web index to optimize search results.
        \item \textbf{Solution:} Distributed search index using Hadoop's MapReduce across multiple nodes.
        \item \textbf{Outcome:} Improved search algorithms, resulting in faster and more relevant results.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Case Study: Netflix and Data Analytics}
    \begin{itemize}
        \item \textbf{Challenge:} Enhance user experience through personalized recommendations.
        \item \textbf{Solution:} Analyze viewing habits and preferences using Hadoop to process terabytes of data.
        \item \textbf{Outcome:} Developed algorithms for personalized content delivery, increasing engagement.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Case Study: Facebook and Log Processing}
    \begin{itemize}
        \item \textbf{Challenge:} Manage and analyze massive log data from user interactions.
        \item \textbf{Solution:} Utilized Hadoop for parallel log processing and queried data with Hive.
        \item \textbf{Outcome:} Gained insights into user behavior, improving features and advertising.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Case Study: Bank of America and Risk Management}
    \begin{itemize}
        \item \textbf{Challenge:} Efficiently assess risk and comply with regulations.
        \item \textbf{Solution:} Deployed Hadoop for real-time transaction data analysis to identify fraud.
        \item \textbf{Outcome:} Enhanced risk management processes and compliance reporting.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Key Points to Emphasize}
    \begin{itemize}
        \item \textbf{Scalability:} Easily scale horizontally by adding machines to the cluster.
        \item \textbf{Flexibility:} Handle structured, semi-structured, and unstructured data.
        \item \textbf{Cost-Effectiveness:} Utilize commodity hardware to minimize costs.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Code Snippet Example (MapReduce)}
    \begin{lstlisting}[language=java]
public class WordCount {
    public static class TokenizerMapper
        extends Mapper<Object, Text, Text, IntWritable> {
      
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();

        public void map(Object key, Text value, Context context) 
            throws IOException, InterruptedException {
            StringTokenizer itr = new StringTokenizer(value.toString());
            while (itr.hasMoreTokens()) {
                word.set(itr.nextToken());
                context.write(word, one);
            }
        }
    }

    public static class IntSumReducer
        extends Reducer<Text, IntWritable, Text, IntWritable> {
        private IntWritable result = new IntWritable();

        public void reduce(Text key, Iterable<IntWritable> values, 
                           Context context) throws IOException, InterruptedException {
            int sum = 0;
            for (IntWritable val : values) {
                sum += val.get();
            }
            result.set(sum);
            context.write(key, result);
        }
    }
}
    \end{lstlisting}
\end{frame}

\begin{frame}
    \frametitle{Conclusion}
    Hadoop is a robust framework for solving complex data processing challenges across various industries. 
    \begin{itemize}
        \item Scalability, flexibility, and cost-effectiveness empower organizations to leverage data.
        \item Understanding these use cases highlights its applications in real-world contexts.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Directions of Data Processing Frameworks}
    \begin{block}{Emerging Trends in Data Processing Frameworks}
        \begin{itemize}
            \item Rise of Real-Time Processing
            \item Cloud-Native Architecture
            \item Machine Learning Integration
            \item Improved Data Governance and Security
            \item Serverless Architectures
            \item Ecosystem Collaboration
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Emerging Trends in Data Processing Frameworks - Part 1}
    \begin{itemize}
        \item \textbf{Rise of Real-Time Processing:}
            \begin{itemize}
                \item Increasing demand for real-time analytics
                \item Examples: Fraud detection and recommendation systems
                \item Tools: Apache Kafka, Apache Flink for live insights
            \end{itemize}
        \item \textbf{Cloud-Native Architecture:}
            \begin{itemize}
                \item Evolution towards leveraging cloud solutions
                \item Examples: Azure HDInsight, AWS EMR, Google Cloud Dataproc
                \item Key Point: Enhances accessibility and flexibility
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Emerging Trends in Data Processing Frameworks - Part 2}
    \begin{itemize}
        \item \textbf{Machine Learning Integration:}
            \begin{itemize}
                \item Convergence of data processing frameworks and machine learning
                \item Example: Apache Spark's MLlib for scalable machine learning
            \end{itemize}
        \item \textbf{Improved Data Governance and Security:}
            \begin{itemize}
                \item Stricter governance due to data privacy regulations (e.g., GDPR)
                \item Tools: Apache Ranger, Apache Atlas for security and metadata management
            \end{itemize}
        \item \textbf{Serverless Architectures:}
            \begin{itemize}
                \item Focus on processing rather than server management
                \item Example: AWS Lambda for triggering data processing workflows
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ecosystem Collaboration and Hadoop's Evolution}
    \begin{itemize}
        \item \textbf{Ecosystem Collaboration:}
            \begin{itemize}
                \item Synergy between open-source tools increases efficiency
                \item Example: Integration of Hadoop with Apache NiFi
            \end{itemize}
        \item \textbf{Hadoop's Evolution:}
            \begin{itemize}
                \item Adoption of features for real-time processing
                \item Key Components:
                    \begin{itemize}
                        \item YARN (Yet Another Resource Negotiator)
                        \item Hadoop 3.x enhancements for cloud compatibility
                    \end{itemize}
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Takeaways}
    \begin{block}{Summary}
        \begin{itemize}
            \item Data processing frameworks are evolving towards real-time analytics.
            \item Cloud-native architectures enhance accessibility and flexibility.
            \item Integration with machine learning and improved data governance is crucial.
            \item Collaborations between tools result in robust solutions.
            \item Continuous learning is essential for adapting to industry changes.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Key Takeaways - Summary}
    \begin{block}{Key Points}
        \begin{itemize}
            \item Apache Hadoop is a powerful open-source framework for large data processing.
            \item Core components include HDFS, MapReduce, and YARN.
            \item Benefits: Scalability, cost-effectiveness, and flexibility.
            \item Use cases span various industries for big data analytics and log processing.
            \item Hadoop has influenced the development of other technologies in the data ecosystem.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance of Hadoop in Data Processing}
    \begin{block}{Key Contributions}
        \begin{itemize}
            \item \textbf{Foundation of Big Data Technologies:} Essential infrastructure for storage, processing, and analysis.
            \item \textbf{Data Democratization:} Enables organizations of all sizes to leverage data for better decision-making.
            \item \textbf{Continuous Evolution:} Ongoing improvements keep it relevant for current demands.
        \end{itemize}
    \end{block}
    
    \begin{block}{Key Takeaways}
        \begin{itemize}
            \item Vital for managing and processing large datasets.
            \item Understanding its components is crucial for data science and analytics.
            \item Cost-effectiveness and scalability make Hadoop an unmatchable choice for big data.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Example Code Snippet}
    This Java code snippet demonstrates a basic implementation of the MapReduce paradigm in Hadoop:

    \begin{lstlisting}[language=Java]
public class WordCount {
    public static class TokenizerMapper extends Mapper<Object, Text, Text, IntWritable> {
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();

        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
            StringTokenizer itr = new StringTokenizer(value.toString());
            while (itr.hasMoreTokens()) {
                word.set(itr.nextToken());
                context.write(word, one);
            }
        }
    }
    // Reducer and driver classes follow...
}
    \end{lstlisting}
    
    This example underscores the power of Hadoop in processing data efficiently.
\end{frame}


\end{document}