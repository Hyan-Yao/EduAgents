Syllabus & Learning Objectives Design
=====================================

# Syllabus for Data Processing at Scale (Course Code: DPSC 101)

## Course Overview

### Course Description
This course provides a comprehensive understanding of data processing methodologies and technologies used in the context of big data and distributed computing. Students will explore data lifecycle management, implementation of processing techniques, and selection of appropriate frameworks for various scenarios. The course balances theoretical knowledge with practical application, aiming to equip students with essential skills in data processing.

### Course Objectives
1. Define key terms and concepts associated with data processing technologies.
2. Implement effective processing techniques on large datasets to enhance performance and accuracy.
3. Assess and recommend appropriate data processing frameworks for specific case studies.
4. Demonstrate knowledge of the entire data lifecycle from ingestion to storage and presentation.
5. Utilize a variety of data processing tools, achieving familiarity with industry-standard technologies.

### Learning Outcomes
By the end of this course, students will be able to:
- Clearly articulate data processing terminology.
- Execute practical assignments that demonstrate a quantitative improvement in processing efficiency.
- Analyze case studies to recommend suitable data processing frameworks.
- Understand the operational flow from data ingestion to visualization.
- Work collaboratively on projects using modern data processing technologies.

## Weekly Schedule

### Week 1: Introduction to Data Processing
- **Topics**: Overview of course, key terms in data processing, importance of big data.
- **Readings**: Chapter 1 from *Big Data: A Revolution That Will Transform How We Live, Work, and Think* by Viktor Mayer-Schönberger and Kenneth Cukier.
- **Objectives**: Understand fundamental concepts and prepare for advanced discussions.

### Week 2: The Data Lifecycle
- **Topics**: Stages of the data lifecycle, data ingestion techniques.
- **Readings**: Chapter 2 from *Data Management for Researchers* by Kristin Briney.
- **Objectives**: Map out the data lifecycle and identify key processes.

### Week 3: Introduction to Distributed Computing
- **Topics**: Basic principles of distributed computing, architectures.
- **Readings**: Chapter 3 of *Designing Data-Intensive Applications* by Martin Kleppmann.
- **Objectives**: Understand how distributed systems operate and their significance in data processing.

### Week 4: Data Storage Solutions
- **Topics**: Types of data storage (SQL vs NoSQL), choosing the right storage solution.
- **Readings**: Selected articles from online resources (links provided on course page).
- **Objectives**: Comprehend data storage types and strategies.

### Week 5: Data Processing Frameworks - Apache Hadoop
- **Topics**: Introduction to Hadoop, HDFS architecture.
- **Readings**: Chapters 4-5 of *Hadoop: The Definitive Guide* by Tom White.
- **Objectives**: Gain an understanding of Hadoop as a data processing framework.

### Week 6: Data Processing Frameworks - Apache Spark
- **Topics**: Overview of Spark, RDDs, and DataFrames.
- **Readings**: Chapters 1-3 of *Spark: The Definitive Guide* by Bill Chambers and Matei Zaharia.
- **Objectives**: Learn the features of Apache Spark and its applications.

### Week 7: Data Processing Techniques
- **Topics**: ETL processes, batch vs real-time processing.
- **Readings**: Chapter 6 from *Data Warehousing in the Age of Big Data* by Nina Jentzsch.
- **Objectives**: Implement ETL techniques within practical scenarios.

### Week 8: Performance Optimization in Data Processing
- **Topics**: Techniques for optimizing data processing tasks.
- **Readings**: Articles on performance optimization practices (provided in the course portal).
- **Objectives**: Analyze and apply optimization strategies.

### Week 9: Case Studies in Data Processing
- **Topics**: Review of real-world applications of data processing frameworks.
- **Readings**: Specific case studies shared in class.
- **Objectives**: Assess framework applicability through case studies.

### Week 10: Group Project Kick-off
- **Topics**: Introduction of group projects focusing on a chosen data processing case.
- **Readings**: Project guidelines distributed in class.
- **Objectives**: Encourage collaboration and practical application of learned concepts.

### Week 11: Develop and Present Project Drafts
- **Topics**: Work sessions for project development; peer feedback.
- **Objectives**: Refine projects based on peer and instructor feedback.

### Week 12: Project Presentations
- **Topics**: Group presentations of completed projects.
- **Objectives**: Demonstrate learning outcomes through the presentation and discussion of project findings.

### Week 13: Course Review and Future Directions
- **Topics**: Review of key course concepts; emerging trends in data processing.
- **Objectives**: Ensure comprehensive understanding and readiness for future applications.

## Assessment Methods

### Grading Breakdown:
- Participation: 10%
- Weekly Quizzes: 20%
- Assignments: 30%
- Group Project: 30%
- Final Exam: 10%

### Grading Scale:
- A: 90-100
- B: 80-89
- C: 70-79
- D: 60-69
- F: Below 60

## Required Readings
- *Big Data: A Revolution That Will Transform How We Live, Work, and Think* by Viktor Mayer-Schönberger and Kenneth Cukier.
- *Data Management for Researchers* by Kristin Briney.
- *Designing Data-Intensive Applications* by Martin Kleppmann.
- *Hadoop: The Definitive Guide* by Tom White.
- *Spark: The Definitive Guide* by Bill Chambers and Matei Zaharia.
- Related case studies and articles provided on the course portal.

## Academic Policies
- Attendance is mandatory; participation will contribute to overall grades.
- Late submissions will incur a penalty unless prior arrangements are made.
- Academic integrity is paramount; plagiarism or cheating will result in disciplinary action.

## Conclusion
This syllabus serves as a roadmap for students in understanding and mastering data processing at scale. Activities and assessments are designed to align with the learning outcomes, ensuring that students are equipped with key skills applicable in various data-driven contexts. Regular feedback and engagement will enhance the learning experience throughout the course.