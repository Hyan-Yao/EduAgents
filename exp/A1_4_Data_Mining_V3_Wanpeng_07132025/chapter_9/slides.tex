\documentclass[aspectratio=169]{beamer}

% Theme and Color Setup
\usetheme{Madrid}
\usecolortheme{whale}
\useinnertheme{rectangles}
\useoutertheme{miniframes}

% Additional Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}
\usepackage{hyperref}

% Custom Colors
\definecolor{myblue}{RGB}{31, 73, 125}
\definecolor{mygray}{RGB}{100, 100, 100}
\definecolor{mygreen}{RGB}{0, 128, 0}
\definecolor{myorange}{RGB}{230, 126, 34}
\definecolor{mycodebackground}{RGB}{245, 245, 245}

% Set Theme Colors
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=white, bg=myblue}
\setbeamercolor{title}{fg=myblue}
\setbeamercolor{section in toc}{fg=myblue}
\setbeamercolor{item projected}{fg=white, bg=myblue}
\setbeamercolor{block title}{bg=myblue!20, fg=myblue}
\setbeamercolor{block body}{bg=myblue!10}
\setbeamercolor{alerted text}{fg=myorange}

% Set Fonts
\setbeamerfont{title}{size=\Large, series=\bfseries}
\setbeamerfont{frametitle}{size=\large, series=\bfseries}
\setbeamerfont{caption}{size=\small}
\setbeamerfont{footnote}{size=\tiny}

% Code Listing Style
\lstdefinestyle{customcode}{
  backgroundcolor=\color{mycodebackground},
  basicstyle=\footnotesize\ttfamily,
  breakatwhitespace=false,
  breaklines=true,
  commentstyle=\color{mygreen}\itshape,
  keywordstyle=\color{blue}\bfseries,
  stringstyle=\color{myorange},
  numbers=left,
  numbersep=8pt,
  numberstyle=\tiny\color{mygray},
  frame=single,
  framesep=5pt,
  rulecolor=\color{mygray},
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=2,
  captionpos=b
}
\lstset{style=customcode}

% Custom Commands
\newcommand{\hilight}[1]{\colorbox{myorange!30}{#1}}
\newcommand{\source}[1]{\vspace{0.2cm}\hfill{\tiny\textcolor{mygray}{Source: #1}}}
\newcommand{\concept}[1]{\textcolor{myblue}{\textbf{#1}}}
\newcommand{\separator}{\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}}

% Footer and Navigation Setup
\setbeamertemplate{footline}{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
    \usebeamerfont{author in head/foot}\insertshortauthor
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.5\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
    \usebeamerfont{title in head/foot}\insertshorttitle
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.2\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}%
    \usebeamerfont{date in head/foot}
    \insertframenumber{} / \inserttotalframenumber
  \end{beamercolorbox}}%
  \vskip0pt%
}

% Turn off navigation symbols
\setbeamertemplate{navigation symbols}{}

% Title Page Information
\title[Week 13: Text Mining & Representation Learning]{Week 13: Text Mining \& Representation Learning}
\author[J. Smith]{John Smith, Ph.D.}
\institute[University Name]{
  Department of Computer Science\\
  University Name\\
  \vspace{0.3cm}
  Email: email@university.edu\\
  Website: www.university.edu
}
\date{\today}

% Document Start
\begin{document}

\frame{\titlepage}

\begin{frame}[fragile]
    \titlepage
\end{frame}

\begin{frame}[fragile]
    \frametitle{Overview of Text Mining}

    \begin{itemize}
        \item \textbf{Definition}: Text mining refers to the process of deriving meaningful information from unstructured text data by transforming it into a structured format that can be analyzed.
        \item \textbf{Significance in NLP}:
        \begin{itemize}
            \item Enables the extraction of insights from vast amounts of text—enriching decision-making processes and enhancing user experience in applications like search engines and chatbots.
            \item Key foundational element feeding into more advanced NLP tasks, such as sentiment analysis, topic modeling, and text classification.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Why Do We Need Text Mining?}

    \begin{itemize}
        \item \textbf{Growing Data Availability}:
        \begin{itemize}
            \item The exponential increase in unstructured data (e.g., social media posts, customer reviews, and scientific articles).
        \end{itemize}
        \item \textbf{Decision-Making}:
        \begin{itemize}
            \item Helps organizations leverage information from customer feedback, medical records, or legal documents to drive strategic decisions.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Real-World Example: Application of Text Mining}

    \begin{itemize}
        \item ChatGPT and similar AI models utilize text mining techniques to improve their natural language understanding.
        \item These models train on large datasets to recognize patterns, semantics, and context in language, showcasing the crucial role of text mining in modern AI applications.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Components of Text Mining}

    \begin{enumerate}
        \item \textbf{Information Retrieval}: Finding relevant documents from a large collection based on user queries.
        \item \textbf{Information Extraction}: Identifying structured information from unstructured text (e.g., named entity recognition).
        \item \textbf{Text Categorization}: Classifying text into predefined categories for easier management and retrieval.
        \item \textbf{Sentiment Analysis}: Assessing opinions or sentiments expressed in text data to gauge public opinion on various topics.
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Aims and Objectives of This Chapter}

    \begin{itemize}
        \item \textbf{Understand the Basics}: Grasp foundational concepts of text mining and its role in NLP.
        \item \textbf{Explore Techniques}: Familiarize with various text mining techniques and algorithms.
        \item \textbf{Practical Application}: Develop skills to implement text mining methods in real-world scenarios (e.g., using Python libraries like NLTK or spaCy).
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Summary Points}

    \begin{itemize}
        \item Text mining is crucial for making sense of unstructured data.
        \item It enhances the performance of NLP applications by enabling data-driven insights.
        \item Understanding text mining equips you with the skills to harness the power of language in technological advancements.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{What is Text Mining? - Definition}
    \begin{block}{Definition of Text Mining}
        Text mining, also known as text data mining or text analytics, is the computational process of extracting valuable insights and information from unstructured text data. This process utilizes various techniques and methodologies aimed at identifying patterns, relationships, and trends within textual content.
    \end{block}
    
    \begin{itemize}
        \item **Unstructured Data**: Deals with unstructured data lacking a predefined format or structure.
        \item **Integration of Techniques**: Combines natural language processing (NLP), machine learning, and data mining methodologies.
    \end{itemize}
    
\end{frame}

\begin{frame}[fragile]{What is Text Mining? - Differences from Traditional Data Mining}
    \begin{block}{Differences from Traditional Data Mining}
        \begin{tabular}{|l|l|l|}
            \hline
            \textbf{Feature} & \textbf{Text Mining} & \textbf{Traditional Data Mining} \\
            \hline
            **Data Type** & Primarily unstructured text data & Structured data (databases, spreadsheets) \\
            \hline
            **Techniques Used** & NLP, tokenization, sentiment analysis & Statistical analysis, classification, clustering \\
            \hline
            **Output** & Insights based on linguistic context & Numeric or categorical insights \\
            \hline
            **Focus** & Meaning and relationships in text & Patterns and correlations in numerical data \\
            \hline
        \end{tabular}
    \end{block}
    
\end{frame}

\begin{frame}[fragile]{What is Text Mining? - Purpose and Example}
    \begin{block}{Purpose of Text Mining}
        The main purpose of text mining is to transform unstructured text data into a structured format that can be analyzed for decision-making, including:
        \begin{enumerate}
            \item Identification of Trends: Discovering prevalent topics over time in customer reviews or social media posts.
            \item Sentiment Analysis: Understanding public opinion by analyzing the tone and emotion in text data.
            \item Information Retrieval: Extracting specific information from large corpora of unstructured text.
        \end{enumerate}
    \end{block}
    
    \begin{block}{Illustrative Example}
        Consider a company analyzing thousands of customer reviews. Text mining helps them:
        \begin{itemize}
            \item Identify common complaints (e.g., "battery life", "customer service").
            \item Determine overall customer satisfaction through sentiment analysis.
            \item Reveal emerging trends (e.g., interest in eco-friendly products).
        \end{itemize}
    \end{block}  
\end{frame}

\begin{frame}[fragile]{What is Text Mining? - Key Takeaways}
    \begin{block}{Key Takeaways}
        \begin{itemize}
            \item Text mining is essential for understanding vast amounts of unstructured text data in today’s digital landscape.
            \item It integrates advanced techniques from various fields to deliver actionable insights.
            \item Mastering text mining opens doors to numerous applications, enhancing decision-making processes.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Why Text Mining Matters}
    \begin{block}{Introduction to Text Mining}
        Text mining is an essential process of analyzing unstructured text data to extract meaningful insights. Its significance is growing rapidly as the volume of text data increases across various platforms, such as social media, research articles, customer feedback, and much more.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Real-World Applications of Text Mining}
    \begin{enumerate}
        \item \textbf{Sentiment Analysis}
            \begin{itemize}
                \item \textbf{Definition:} Determining and categorizing the emotional tone behind words.
                \item \textbf{Example:} Analyzing customer reviews on platforms like Amazon or Yelp.
                \item \textbf{Impact:} Enhances customer engagement and informs marketing strategies.
            \end{itemize}
        
        \item \textbf{Topic Modeling}
            \begin{itemize}
                \item \textbf{Definition:} Classifying large volumes of text into topics or themes.
                \item \textbf{Example:} Automatically categorizing articles and research papers for easier access.
                \item \textbf{Impact:} Facilitates efficient organization of content.
            \end{itemize}
        
        \item \textbf{Information Retrieval}
            \begin{itemize}
                \item \textbf{Definition:} Finding and retrieving information from large databases of unstructured text.
                \item \textbf{Example:} Google’s search algorithm using text mining techniques.
                \item \textbf{Impact:} Improves user experience by delivering pertinent search results quickly.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{The Role of AI in Text Mining}
    The integration of text mining techniques into modern AI applications is profound. For instance, systems like ChatGPT utilize:
    \begin{itemize}
        \item Advanced text analysis techniques.
        \item Contextual understanding to generate meaningful responses.
        \item Transformation of vast data sets into interactive conversational agents.
    \end{itemize}
    
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item Text mining transforms unstructured data into actionable insights.
            \item Critical role across industries including finance, healthcare, and marketing.
            \item Enhances capabilities in natural language processing in AI systems.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Representation Learning Overview}
    \begin{block}{What is Representation Learning?}
        Representation Learning is a set of techniques in machine learning that enables the automatic discovery of representations from raw data.
    \end{block}
    Its primary purpose is to transform complex and high-dimensional data into a lower-dimensional, compact format, making it easier for computational models to process and learn from the data.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Purpose of Representation Learning}
    \begin{itemize}
        \item \textbf{Reduction in Dimensionality:} Simplifies data without losing essential information, enhancing model performance.
        \item \textbf{Feature Extraction:} Automatically identifies relevant features, reducing the need for manual feature engineering.
        \item \textbf{Enhanced Generalization:} Improves the generalization ability of models for better performance on unseen data.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance of Representation Learning}
    \begin{itemize}
        \item \textbf{Real-world Applications:} Significant in fields like natural language processing and computer vision.
        \item \textbf{Support for Advanced Models:} Essential for tools like ChatGPT that rely on effective representation learning for context and semantic understanding.
    \end{itemize}
    \begin{block}{Key Points to Emphasize}
        \begin{enumerate}
            \item Automated Representation, reducing manual bias.
            \item Compactness and Meaningfulness of representations.
            \item Versatility across text, images, and videos.
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Examples of Representation Learning}
    \begin{itemize}
        \item \textbf{Word Embeddings:} Models like Word2Vec and GloVe convert words into low-dimensional vectors based on context.
        \item \textbf{Autoencoders:} Neural networks that compress data to reveal efficient representations.
        \item \textbf{Transformers:} Models like BERT and GPT use attention mechanisms to capture relationships in data.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Practical Insights}
    The effectiveness of representation learning is evident in tools like ChatGPT, where understanding and generating human-like text relies on learned language patterns from vast datasets.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Techniques in Representation Learning - Part 1}
    \begin{block}{Introduction to Representation Learning in Text Mining}
        Representation learning is essential for converting textual data into numerical formats that machine learning algorithms can utilize. This enables better understanding and processing of human languages across various applications such as sentiment analysis and chatbots.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Techniques in Representation Learning - Part 2}
    \begin{block}{Key Techniques}
        \begin{enumerate}
            \item \textbf{Word2Vec}
                \begin{itemize}
                    \item Developed by Google, it captures semantic meanings through context.
                    \item \textbf{Models:}
                        \begin{itemize}
                            \item \textit{Continuous Bag of Words (CBOW)}: Predicts a target word from its context.
                            \item \textit{Skip-gram}: Predicts the context from a given word.
                        \end{itemize}
                    \item \textbf{Key}: It embeds similar words close in vector space.
                \end{itemize}
            \item \textbf{GloVe}
                \begin{itemize}
                    \item Developed by Stanford, leverages global word co-occurrence statistics.
                    \item \textbf{Key Concept}: The dot product of two vectors approximates the logarithm of their co-occurrence probability ratio.
                \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Techniques in Representation Learning - Part 3}
    \begin{block}{Key Techniques (continued)}
        \begin{enumerate}
            \setcounter{enumi}{2} % Resume enumeration from 3
            \item \textbf{Embeddings}
                \begin{itemize}
                    \item Representations of words/phrases in fixed-size vectors.
                    \item \textbf{Types:}
                        \begin{itemize}
                            \item \textit{Static Embeddings}: Fixed vectors (e.g., Word2Vec, GloVe).
                            \item \textit{Contextualized Embeddings}: Vectors change based on context (e.g., BERT).
                        \end{itemize}
                    \item \textbf{Key}: Embeddings enable nuanced understanding in NLP tasks.
                \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Techniques in Representation Learning - Conclusion}
    \begin{block}{Conclusion: Why These Techniques Matter}
        These techniques lay the groundwork for many AI applications, from chatbots to recommendation systems. Converting text into numerical representations allows machines to perform complex understanding and processing tasks effectively.
    \end{block}
    \begin{block}{Summary of Key Points}
        \begin{itemize}
            \item Representation learning transforms text into numerical forms.
            \item Word2Vec leverages context through CBOW and Skip-gram.
            \item GloVe focuses on global similarities for relationship understanding.
            \item Different types of embeddings (static/contextualized) enhance applications.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Next Steps}
    In the following slide, we will define Natural Language Processing (NLP) and explore its relevance to these representation techniques in solving language-based tasks.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Natural Language Processing (NLP) Defined}
    \begin{block}{Definition of NLP}
        Natural Language Processing (NLP) is a field at the intersection of computer science, artificial intelligence, and linguistics. It focuses on enabling machines to understand, interpret, generate, and respond to human language in a valuable way.
    \end{block}
    
    \begin{block}{Key Components of NLP}
        \begin{enumerate}
            \item \textbf{Understanding Language:} Analyzing meaning, context, and intent behind words.
            \item \textbf{Generating Language:} Producing coherent and contextually relevant text or speech.
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Relevance to Text Mining and Representation Learning}
    \begin{block}{Overview}
        NLP plays a pivotal role in text mining and representation learning by transforming unstructured text data into structured information that can be processed computationally.
    \end{block}

    \begin{enumerate}
        \item \textbf{Text Mining:}
            \begin{itemize}
                \item \textbf{Explanation:} Extracting meaningful information from large datasets of text.
                \item \textbf{Example:} Analyzing customer reviews to identify sentiment (positive/negative) towards a product.
                \item \textbf{NLP Role:} Techniques like tokenization and sentiment analysis enable insight extraction from texts.
            \end{itemize}

        \item \textbf{Representation Learning:}
            \begin{itemize}
                \item \textbf{Explanation:} Converting text into numerical forms (vectors) that capture semantic meanings.
                \item \textbf{Example:} Using Word2Vec to convert "king" to a vector closer to "queen" than "car."
                \item \textbf{NLP Role:} Enables efficient processing and machine learning on text data, enhancing performance on language-based tasks.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Illustrative Example and Key Points}
    \begin{block}{Illustrative Example}
        \textbf{Task: Sentiment Analysis of Movie Reviews}  
        \begin{itemize}
            \item \textbf{Input:} "The movie was fantastic and exciting!"
            \item \textbf{Processing:} Use NLP techniques to tokenize, analyze sentiment, and convert words into vector representations.
            \item \textbf{Output:} Sentiment score (e.g., positive).
        \end{itemize}
    \end{block}

    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item NLP bridges human language and machine understanding.
            \item Essential for applications such as chatbots like ChatGPT, social media analytics, and automated text summarization.
            \item Continuous advancements in NLP enhance interactions with technology and data utilization.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion}
    Understanding NLP is crucial for harnessing the power of text mining and representation learning in solving complex language-based tasks effectively. The integration of NLP in various applications illustrates its importance in the modern data-driven landscape.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of NLP Components - Overview}
    \begin{block}{Natural Language Processing (NLP)}
        NLP encompasses several techniques that facilitate the manipulation and understanding of human language. 
    \end{block}
    \begin{itemize}
        \item Focus on three fundamental components: 
            \begin{itemize}
                \item Tokenization
                \item Stemming
                \item Lemmatization
            \end{itemize}
        \item These techniques are foundational for:
            \begin{itemize}
                \item Sentiment analysis
                \item Chatbots (e.g., ChatGPT)
                \item Document classification
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of NLP Components - Tokenization}
    \begin{block}{1. Tokenization}
        \textbf{Definition}: The process of breaking text into individual words or tokens. 
    \end{block}
    \begin{itemize}
        \item \textbf{Example}: 
            \begin{itemize}
                \item Sentence: "I love learning about NLP."
                \item Tokenized output: ["I", "love", "learning", "about", "NLP"]
            \end{itemize}
        \item \textbf{Key Points}: 
            \begin{itemize}
                \item Facilitates counting of word frequency.
                \item Types include word tokenization and sentence tokenization.
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of NLP Components - Stemming and Lemmatization}
    \begin{block}{2. Stemming}
        \textbf{Definition}: Reduces words to their base or root form, often by removing suffixes.
    \end{block}
    \begin{itemize}
        \item \textbf{Example}: 
            \begin{itemize}
                \item Input: ["running", "ran", "happily"]
                \item Stemming Output: ["run", "ran", "happi"]
            \end{itemize}
        \item \textbf{Key Points}: 
            \begin{itemize}
                \item May result in non-lexical roots ("happily" to "happi").
                \item Useful in information retrieval and search optimization.
            \end{itemize}
    \end{itemize}

    \begin{block}{3. Lemmatization}
        \textbf{Definition}: Reduces a word to its base form considering its context and part of speech.
    \end{block}
    \begin{itemize}
        \item \textbf{Example}: 
            \begin{itemize}
                \item Input: ["better", "running", "cats"]
                \item Lemmatization Output: ["good", "run", "cat"]
            \end{itemize}
        \item \textbf{Key Points}: 
            \begin{itemize}
                \item More sophisticated than stemming.
                \item Enhances semantic understanding in text processing.
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of NLP Components - Importance and Conclusion}
    \begin{block}{Importance in NLP Applications}
        Modern AI models, like ChatGPT, rely on these techniques to preprocess text data effectively:
    \end{block}
    \begin{itemize}
        \item Tokenizing, stemming, and lemmatizing improve understanding of user inputs.
        \item Enhances the generation of coherent responses.
        \item Improves overall interaction experience in AI applications.
    \end{itemize}

    \begin{block}{Conclusion}
        \begin{itemize}
            \item Tokenization, stemming, and lemmatization are essential NLP components.
            \item Understanding these techniques is crucial for implementing NLP solutions.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Text Mining Tools and Libraries - Introduction}
  \begin{block}{Introduction to Text Mining}
    Text mining is the process of extracting valuable information and insights from unstructured text data. 
    With the increasing volume of data generated daily (from social media, emails, articles, etc.), robust tools and libraries are essential for efficiently processing and analyzing this data.
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Text Mining Tools and Libraries - Key Tools}
  \begin{enumerate}
    \item \textbf{Natural Language Toolkit (NLTK)}
      \begin{itemize}
        \item \textbf{Overview:} Widely used Python library for symbolic and statistical NLP.
        \item \textbf{Functionalities:}
          \begin{itemize}
            \item Tokenization
            \item Stemming \& Lemmatization
            \item Part-of-Speech Tagging
            \item Sentiment Analysis
          \end{itemize}
        \item \textbf{Use Case:} Ideal for education, research, and prototyping NLP applications.
      \end{itemize}
    \item \textbf{SpaCy}
      \begin{itemize}
        \item \textbf{Overview:} Modern library for efficient large-scale NLP tasks.
        \item \textbf{Functionalities:}
          \begin{itemize}
            \item Dependency Parsing
            \item Named Entity Recognition (NER)
            \item Pre-trained Word Vectors
            \item Multi-language Support
          \end{itemize}
        \item \textbf{Use Case:} Best for production-level applications requiring speed and efficiency.
      \end{itemize}
    \item \textbf{Scikit-learn}
      \begin{itemize}
        \item \textbf{Overview:} Machine learning library with text mining tools.
        \item \textbf{Functionalities:}
          \begin{itemize}
            \item Feature Extraction (TF-IDF, CountVectorizer)
            \item Model Training (Naive Bayes, SVM)
            \item Clustering (K-means)
          \end{itemize}
        \item \textbf{Use Case:} Perfect for machine learning tasks involving text classification and clustering.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Text Mining Tools and Libraries - Examples}
  \begin{block}{NLTK Example Code}
    \begin{lstlisting}[language=Python]
import nltk
from nltk.tokenize import word_tokenize
nltk.download('punkt')
text = "Text mining enables the extraction of information from text."
tokens = word_tokenize(text)
print(tokens)
    \end{lstlisting}
  \end{block}
  
  \begin{block}{SpaCy Example Code}
    \begin{lstlisting}[language=Python]
import spacy
nlp = spacy.load("en_core_web_sm")
doc = nlp("Apple is looking at buying U.K. startup for $1 billion")
for entity in doc.ents:
    print(entity.text, entity.label_)
    \end{lstlisting}
  \end{block}

  \begin{block}{Scikit-learn Example Code}
    \begin{lstlisting}[language=Python]
from sklearn.feature_extraction.text import TfidfVectorizer
documents = ["This is a sample document.", "This document is another document."]
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(documents)
print(X.toarray())
    \end{lstlisting}
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Text Mining Tools and Libraries - Summary & Conclusion}
  \begin{block}{Summary of Key Points}
    \begin{itemize}
      \item \textbf{NLTK:} Best for educational and experimental purposes with extensive NLP functionalities.
      \item \textbf{SpaCy:} Excels in production environments with efficient performance.
      \item \textbf{Scikit-learn:} Provides machine learning tools that integrate well with text mining.
    \end{itemize}
  \end{block}
  
  \begin{block}{Conclusion}
    The choice of the right tool or library depends on specific text mining needs, including data scale, processing speed, and analysis type. Exploring these tools equips you to extract valuable insights from text data.
  \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges in Text Mining}
    \begin{block}{Introduction}
        Text mining, a crucial element of Natural Language Processing (NLP), aims to extract meaningful information from text data. However, various challenges hinder effective analysis and derive insights.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Handling Noise}
    \begin{itemize}
        \item \textbf{Definition}: Noise refers to irrelevant or extraneous data obscuring valuable insights, including typographical errors and inconsistent formatting.
        \item \textbf{Example}: Social media data often includes slang, emojis, or shorthand (e.g., "lol," "brb"), complicating text standardization and interpretation.
        \item \textbf{Key Point}: Utilizing preprocessing techniques such as tokenization, stemming, and filtering out stop words is essential for minimizing noise and improving analysis accuracy.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ambiguity in Language}
    \begin{itemize}
        \item \textbf{Definition}: Inherently ambiguous language can result in words or phrases with multiple meanings, leading to data misinterpretation.
        \item \textbf{Example}: The term "bank" might refer to a financial institution or the side of a river; algorithms may struggle to determine context without additional information.
        \item \textbf{Key Point}: Adopting context-aware models, such as word embeddings (e.g., Word2Vec or BERT), can enhance understanding by establishing contextual relationships between words.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Linguistic Variations}
    \begin{itemize}
        \item \textbf{Definition}: Linguistic variations encompass dialects, colloquialisms, spelling variations, and grammar discrepancies.
        \item \textbf{Example}: The spelling of "color" (American English) differs from "colour" (British English), yet both refer to the same concept.
        \item \textbf{Key Point}: Normalizing these variations through strategies like text normalization (e.g., lowercasing, standardizing dialects) is vital when building text mining systems.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Summary and Conclusion}
    \begin{block}{Summary Points}
        \begin{itemize}
            \item Text mining faces challenges that can compromise data quality:
            \begin{itemize}
                \item \textbf{Noise}: Irrelevant data needs filtering for clarity.
                \item \textbf{Ambiguity}: Context is crucial for accurate analysis of words with multiple meanings.
                \item \textbf{Linguistic Variations}: Standardization across different usages and dialects is necessary.
            \end{itemize}
        \end{itemize}
    \end{block}
    \begin{block}{Conclusion}
        Addressing these challenges is essential for extracting valuable insights from text data. Effective and robust preprocessing methods and context-aware models empower practitioners, enhancing the efficacy of applications like sentiment analysis, search engines, and conversational AI systems.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Analysis of Data Mining and Text Mining}
    \begin{block}{Data Mining}
        The process of discovering patterns and knowledge from large amounts of data. It incorporates:
        \begin{itemize}
            \item Techniques from statistics,
            \item Machine learning, and
            \item Databases to analyze structured data.
        \end{itemize}
        \textbf{Motivation}: Extract valuable insights to improve decision-making and predictive capabilities.
    \end{block}
    
    \begin{block}{Text Mining}
        A specialized branch of data mining focused on unstructured text data:
        \begin{itemize}
            \item Analyzes, interprets, and transforms text data into structured insights.
        \end{itemize}
        \textbf{Motivation}: Understand customer sentiments and trends in the digital text landscape.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Differences between Data Mining and Text Mining}
    \begin{enumerate}
        \item \textbf{Data Type}:
            \begin{itemize}
                \item Data Mining: Structured data (e.g., databases).
                \item Text Mining: Unstructured data (e.g., natural language texts).
            \end{itemize}
        \item \textbf{Methods of Analysis}:
            \begin{itemize}
                \item Data Mining: Algorithms like clustering, classification, and regression.
                \item Text Mining: NLP techniques, such as tokenization, stemming, and named entity recognition.
            \end{itemize}
        \item \textbf{Output}:
            \begin{itemize}
                \item Data Mining: Quantitative insights and trends.
                \item Text Mining: Qualitative insights, sentiment scores, and topic categorizations.
            \end{itemize}
        \item \textbf{Complexity of Language}:
            \begin{itemize}
                \item Data Mining: Relatively straightforward with quantifiable metrics.
                \item Text Mining: Must consider context, ambiguity, and linguistic variations.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Intersections of Text Mining and Traditional Data Mining}
    \begin{itemize}
        \item \textbf{Integration of Techniques}: Machine learning applies to both data types, aiding in predictive outcomes.
        \item \textbf{Hybrid Models}: Approaches like sentiment analysis merge textual and numerical data for richer insights.
    \end{itemize}

    \begin{block}{Example Applications}
        \begin{itemize}
            \item Customer Feedback Analysis: Correlating reviews with sales data via text and data mining.
            \item Social Media Monitoring: Gauging public sentiment from platforms like Twitter while analyzing engagement metrics through data mining.
        \end{itemize}
    \end{block}

    \begin{block}{Summary Points}
        \begin{itemize}
            \item Data Mining focuses on structured data; Text Mining on unstructured text data.
            \item Understanding NLP is crucial for effective text mining.
            \item The intersection enriches comprehensive data analysis.
        \end{itemize}
    \end{block}

\end{frame}

\begin{frame}[fragile]
    \frametitle{Recent Advances in NLP}
    \begin{block}{Overview}
        Explore developments in NLP, particularly the use of large language models (LLMs) like ChatGPT, and their dependency on data mining techniques.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{1. Introduction to Recent Advances in NLP}
    \begin{itemize}
        \item NLP has transformed due to computational power and data availability.
        \item Rise of LLMs, such as ChatGPT, is a notable development.
        \item \textbf{Motivation:} Understanding these advancements enhances applications (e.g., chatbots, content generation).
    \end{itemize}
    \begin{block}{Key Question}
        How do these models work, and what's the connection to data mining?
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{2. What Are Large Language Models (LLMs)?}
    \begin{itemize}
        \item Deep learning models trained on vast datasets to understand and generate human language.
        \item Utilize architectures like the Transformer for effective text processing.
    \end{itemize}
    \begin{block}{Example}
        \begin{itemize}
            \item \textbf{ChatGPT:} Trained on diverse internet text, capable of contextually relevant responses in conversations.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{3. Role of Data Mining in Training LLMs}
    \begin{itemize}
        \item LLMs rely on data mining for:
        \begin{itemize}
            \item Data Extraction: Preprocessing massive text data.
            \item Pattern Recognition: Learning context, sentiment, and semantics.
        \end{itemize}
    \end{itemize}
    \begin{block}{Key Techniques}
        \begin{itemize}
            \item \textbf{Web Scraping:} Automated collection of text data.
            \item \textbf{Text Preprocessing:} Cleaning data by removing noise, normalizing case, tokenizing.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{4. Recent Applications of NLP Innovations}
    Recent advancements in LLMs have enabled various innovative applications:
    \begin{itemize}
        \item \textbf{Conversational AI:} Enhanced chatbots for natural dialogues.
        \item \textbf{Content Creation:} Automating writing tasks for reports, articles, and creative writing.
        \item \textbf{Sentiment Analysis:} Real-time understanding of public sentiment from social media and reviews.
    \end{itemize}
    \begin{block}{Illustration}
        \begin{center}
        \begin{verbatim}
+----------------------+            +-----------------+
|   Web Scraping       |  --->     |   Text Corpus    |
|   (Data Mining)     |            +-----------------+
+----------------------+                     |
                                              |
+----------------------+               +--------------------+
|   Large Language     |  <------     |   LLM Training      |
|   Model (e.g., ChatGPT)           |   (with NLP tasks)  |
+----------------------+               +--------------------+
        \end{verbatim}
        \end{center}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{5. Key Takeaways}
    \begin{itemize}
        \item LLMs like ChatGPT represent a significant leap in NLP.
        \item Data mining is crucial for the training and functioning of LLMs.
        \item Recent applications demonstrate the versatility of LLMs across industries.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{6. Summary Points}
    \begin{itemize}
        \item Significant progress in NLP driven by LLMs.
        \item The intertwining of data mining and NLP for effective model training.
        \item Emerging applications revolutionizing human-computer interaction.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Introduction to Text Mining}
  \begin{itemize}
    \item Text Mining is the extraction of meaningful information from unstructured text data.
    \item Essential in various industries due to digital text growth.
    \item Helps derive insights, enhance decision-making, and improve operational efficiency.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Motivations for Text Mining}
  \begin{itemize}
    \item \textbf{Data Explosion:} Increasing textual data sources (social media, news articles).
    \item \textbf{Competitive Advantage:} Understand consumer sentiment, identify trends.
    \item \textbf{Enhanced Decision-Making:} Make informed decisions based on data-driven insights.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Case Study 1: Sentiment Analysis in Customer Feedback}
  \begin{itemize}
    \item \textbf{Industry:} Retail
    \item \textbf{Objective:} Assess customer sentiment from feedback.
    \item \textbf{Methodology:}
      \begin{itemize}
        \item Data Collection: Social media, product reviews, surveys.
        \item Preprocessing: Tokenization, stopword removal, stemming.
        \item Text Representation: TF-IDF for text vectorization.
        \item Sentiment Classification: Use algorithms (Naive Bayes, SVM).
      \end{itemize}
    \item \textbf{Outcomes:}
      \begin{itemize}
        \item Enhanced understanding of customer preferences.
        \item Increased customer satisfaction and loyalty.
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Case Study 2: Topic Modeling in Academic Research}
  \begin{itemize}
    \item \textbf{Industry:} Education \& Research
    \item \textbf{Objective:} Identify research topics in academic papers.
    \item \textbf{Methodology:}
      \begin{itemize}
        \item Data Collection: Compile publications from databases (PubMed, IEEE).
        \item Preprocessing: Lemmatization and removal of irrelevant data.
        \item Topic Modeling: Implement Latent Dirichlet Allocation (LDA).
      \end{itemize}
    \item \textbf{Outcomes:}
      \begin{itemize}
        \item Uncovered emerging areas of research.
        \item Facilitated collaboration among researchers.
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Case Study 3: Chatbot Development for Customer Service}
  \begin{itemize}
    \item \textbf{Industry:} Technology
    \item \textbf{Objective:} Enhance customer support with an AI-powered chatbot.
    \item \textbf{Methodology:}
      \begin{itemize}
        \item Data Collection: FAQs, support tickets, chat logs.
        \item NLP: Use pre-trained models (BERT, GPT) for understanding.
        \item Training: Fine-tune with domain-specific data.
        \item Deployment: Integrate on a website for real-time interaction.
      \end{itemize}
    \item \textbf{Outcomes:}
      \begin{itemize}
        \item Reduced response times and increased resolution rates.
        \item Improved customer satisfaction scores by 30\%.
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Key Points to Emphasize}
  \begin{itemize}
    \item Text mining provides actionable insights across various sectors.
    \item Leveraging methodologies like sentiment analysis and topic modeling enhances understanding and performance.
    \item Case studies demonstrate the practical implications and outcomes of text mining techniques.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Conclusion and Next Steps}
  \begin{itemize}
    \item Text mining's applications are vast, making it crucial in a data-driven landscape.
    \item Organizations can leverage unstructured text for enhanced operations and consumer engagement.
    \item For deeper insights and future directions in NLP and text mining, please refer to the upcoming slides.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Directions in Text Mining \& NLP - Introduction}
    \begin{block}{Overview}
        The field of Text Mining and Natural Language Processing (NLP) is rapidly evolving due to:
    \end{block}
    \begin{itemize}
        \item Advancements in algorithms
        \item Availability of massive datasets
        \item Continual improvement of computational power
    \end{itemize}
    As we look to the future, several trends emerge that will reshape industries and enhance our understanding of text data.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Trends in Text Mining \& NLP - Part 1}
    \begin{enumerate}
        \item \textbf{Enhanced Contextual Understanding}
        \begin{itemize}
            \item Future models to exhibit nuanced context comprehension.
            \item \textit{Example:} Models like BERT and GPT are already showcasing this capability.
        \end{itemize}
        
        \item \textbf{Multimodal Text Mining}
        \begin{itemize}
            \item Integration of multimodal data (text, images, audio) for richer insights.
            \item \textit{Example:} Analyzing social media posts along with images and audio clips.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Trends in Text Mining \& NLP - Part 2}
    \begin{enumerate}
        \setcounter{enumi}{2}
        \item \textbf{Automated Data Annotation and Curation}
        \begin{itemize}
            \item Automation of the annotation process through unsupervised learning.
            \item \textit{Example:} Tools using generative models for annotation of text datasets.
        \end{itemize}

        \item \textbf{Ethics and Bias Mitigation}
        \begin{itemize}
            \item The need for responsible AI to address ethical concerns and minimize biases.
            \item \textit{Example:} Frameworks to identify and rectify biases in training data.
        \end{itemize}

        \item \textbf{Conversational AI and Human-like Interaction}
        \begin{itemize}
            \item Deeper, more meaningful dialogues with users thanks to enhanced dialogue systems.
            \item \textit{Example:} Advanced AI like ChatGPT used in various sectors.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Implications for Industries}
    \begin{itemize}
        \item \textbf{Healthcare}: Improved patient outcomes through better electronic health record analysis.
        \item \textbf{Finance}: Enhanced sentiment analysis tools for predicting stock movements.
        \item \textbf{E-commerce}: Advanced recommendation systems based on customer reviews.
        \item \textbf{Education}: Personalized learning systems adapting content based on engagement.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Concluding Thoughts}
    \begin{block}{Key Takeaways}
        \begin{itemize}
            \item Contextual understanding and multimodal integration are at the forefront of future NLP capabilities.
            \item Automation in data annotation will enhance text mining processes.
            \item Ethical considerations and bias mitigation are essential for responsible AI development.
            \item Advances will result in more human-like interactions and improved comprehension of complex text.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Takeaways and Summary - Overview}
    
    \begin{block}{Overview of Text Mining and Representation Learning}
        \begin{enumerate}
            \item \textbf{Definition and Importance}
                \begin{itemize}
                    \item \textbf{Text Mining}: Deriving high-quality information from unstructured text data using techniques such as NLP, information retrieval, and sentiment analysis.
                    \item \textbf{Representation Learning}: Methods to automatically discover representations from raw data, transforming text into analyzable formats for machines.
                \end{itemize}
            \item \textbf{Motivation}
                \begin{itemize}
                    \item Efficient extraction of insights from vast text sources (e.g., social media, articles).
                    \item Aids businesses in data-driven decisions, enhancing customer experiences, and driving innovation.
                \end{itemize}
        \end{enumerate}
    \end{block}

\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Takeaways and Summary - Techniques}

    \begin{block}{Key Points Discussed}
        \begin{enumerate}
            \item \textbf{Techniques in Text Mining}
                \begin{itemize}
                    \item \textbf{Preprocessing}: Cleaning techniques (tokenization, stemming, stopword removal).
                    \item \textbf{Statistical Models}: Utilizing statistics to analyze text (e.g., TF-IDF, LDA).
                    \item \textbf{Sentiment Analysis}: Algorithms determining sentiment polarity (positive, neutral, negative) in text.
                \end{itemize}
            \item \textbf{Representation Learning}
                \begin{itemize}
                    \item \textbf{Word Embeddings}: Models like Word2Vec and GloVe preserve semantic relationships.
                    \item \textbf{Contextual Representations}: Methods like BERT and GPT consider context for deeper understanding.
                \end{itemize}
        \end{enumerate}
    \end{block}

\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Takeaways and Summary - Conclusion and Questions}

    \begin{block}{Recent Applications in AI}
        \begin{itemize}
            \item AI solutions (e.g., \textbf{ChatGPT}) leverage text mining and representation learning to generate human-like text and assist in applications from tutoring to content creation.
        \end{itemize}
    \end{block}

    \begin{block}{Importance of Mastery}
        \begin{itemize}
            \item Mastering these methodologies is essential for leveraging AI applications, preparing students for careers in data-driven industries.
        \end{itemize}
    \end{block}

    \begin{block}{Conclusion}
        Understanding the interplay between text mining and representation learning is foundational for developing smart applications that comprehend and interact with human language.
    \end{block}

    \begin{block}{Key Questions for Reflection}
        \begin{enumerate}
            \item Why is preprocessing essential in text mining?
            \item How do word embeddings improve the understandability of language for machines?
            \item What are the potential implications of leveraging representation learning in real-world applications?
        \end{enumerate}
    \end{block}

\end{frame}

\begin{frame}[fragile]
  \frametitle{Discussion and Q\&A - Introduction}
  \begin{block}{Importance of Discussion}
    \begin{itemize}
      \item Critical thinking about the content solidifies understanding.
      \item Open discussions clarify doubts, share insights, and foster collaboration.
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Discussion and Q\&A - Key Concepts}
  \begin{enumerate}
    \item \textbf{Text Mining:}
      \begin{itemize}
        \item \textbf{Definition:} Deriving high-quality information from text.
        \item \textbf{Importance:}
          \begin{itemize}
            \item Facilitates data-driven decisions for organizations.
            \item \textbf{Examples:}
              \begin{itemize}
                \item Sentiment analysis in social media monitoring.
                \item Automatic summarization in news articles.
              \end{itemize}
          \end{itemize}
      \end{itemize}
    
    \item \textbf{Representation Learning:}
      \begin{itemize}
        \item \textbf{Definition:} Techniques in machine learning to automatically discover representations for feature detection or classification.
        \item \textbf{Importance:}
          \begin{itemize}
            \item Enhances model performance by transforming data into informative formats.
            \item \textbf{Examples:}
              \begin{itemize}
                \item Word embeddings like Word2Vec.
                \item Transformers such as BERT.
              \end{itemize}
          \end{itemize}
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Discussion and Q\&A - Applications and Participation}
  \begin{block}{Applications in AI}
    \begin{itemize}
      \item \textbf{ChatGPT:}
        \begin{itemize}
          \item Utilizes text mining techniques on diverse datasets.
          \item Employs representation learning for coherent and contextually relevant responses.
        \end{itemize}
    \end{itemize}
  \end{block}

  \begin{block}{Guiding Questions}
    \begin{itemize}
      \item What limitations exist in current text mining techniques?
      \item How does representation learning impact AI model effectiveness?
      \item Other potential applications for these concepts?
    \end{itemize}
  \end{block}

  \begin{block}{Encouragement for Participation}
    \begin{itemize}
      \item Share insights on the relationship between text mining and user behavior analysis.
      \item Discuss specific challenges faced in text mining projects.
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Discussion and Q\&A - Key Points and Closing}
  \begin{itemize}
    \item Text mining is about deriving actionable insights, not just data extraction.
    \item Representation learning ensures AI models can generalize from data.
    \item Understanding these concepts is vital for those interested in AI technologies.
  \end{itemize}

  \begin{block}{Closing Thoughts}
    \begin{itemize}
      \item Foster an environment of questioning; all questions are valued.
      \item Use the Q\&A to deepen understanding of text mining and representation learning.
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Further Reading and Resources - Overview}
    \begin{block}{Motivation}
        Text mining allows for the extraction of valuable insights from unstructured textual data, enabling decision-making across various domains such as healthcare and business analytics. Representation learning transforms raw text into numerical representation for machine learning.
    \end{block}
    \begin{itemize}
        \item \textbf{Text Mining:} Extract actionable insights from text.
        \item \textbf{Representation Learning:} Convert text into machine-readable formats.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Further Reading and Resources - Recommended Readings}
    \begin{enumerate}
        \item \textbf{Books:}
        \begin{itemize}
            \item *Speech and Language Processing* by Daniel Jurafsky and James H. Martin
            \item *Deep Learning for Natural Language Processing* by Palash Goyal, et al.
        \end{itemize}
        \item \textbf{Research Papers:}
        \begin{itemize}
            \item "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" by Jacob Devlin et al.
            \item "Attention Is All You Need" by Ashish Vaswani et al.
        \end{itemize}
        \item \textbf{Online Articles and Tutorials:}
        \begin{itemize}
            \item *Introduction to Text Mining* by Towards Data Science: [URL]
            \item *Understanding Word Embeddings: An Introduction with Gensim* by Real Python: [URL]
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Further Reading and Resources - Online Resources}
    \begin{enumerate}
        \item \textbf{Courses:}
        \begin{itemize}
            \item Coursera: Text Mining and Analytics \href{https://www.coursera.org/learn/text-mining}{(Link)}
            \item edX: Natural Language Processing with Python \href{https://www.edx.org/course/natural-language-processing-with-python}{(Link)}
        \end{itemize}
        \item \textbf{Tools and Libraries:}
        \begin{itemize}
            \item \textbf{NLTK:} Natural Language Toolkit for Python.
            \item \textbf{spaCy:} Industrial-strength NLP library.
            \item \textbf{Gensim:} For topic modeling and document similarity.
        \end{itemize}
    \end{enumerate}
\end{frame}


\end{document}