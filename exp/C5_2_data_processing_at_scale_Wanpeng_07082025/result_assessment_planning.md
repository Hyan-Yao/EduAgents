Assessment & Evaluation Planning
================================

# Assessment and Evaluation Plan for CS 515: Data Processing at Scale

## Overview
The assessment strategy for this course is structured around project-based evaluations, milestone-driven assessments, and real-world applications to ensure practical skill development alongside theoretical understanding.

### Key Components

#### 1. Assessment Types
- **Quizzes**: Assess understanding of key readings and concepts.
- **Hands-on Labs**: Practical exercises for applying theoretical knowledge in real-world scenarios.
- **Group Projects**: Collaborative assessments focusing on the development of a data processing system.
- **Participation & Peer Evaluations**: Contributions to class discussions and group activities.
- **Cumulative Final Project**: A comprehensive project that integrates skills and knowledge gained during the course.

#### 2. Milestones for Group Projects
- **Milestone 1: Project Proposal (Week 8)**
  - **Submission Format**: PDF via Canvas.
  - **Grading Criteria**:
    - Clarity of objectives (25%)
    - Relevance of tools and methods (25%)
    - Feasibility (25%)
    - Group coordination (25%)

- **Milestone 2: Progress Report (Week 12)**
  - **Submission Format**: PDF via Canvas.
  - **Grading Criteria**:
    - Progress toward project goals (40%)
    - Team communication (30%)
    - Identification of challenges (30%)

- **Milestone 3: Draft Documentation (Week 15)**
  - **Submission Format**: PDF and code repository via GitHub.
  - **Grading Criteria**:
    - Completeness (30%)
    - Clarity and organization (30%)
    - Technical detail (40%)

#### Final Project Presentation (Week 16)
- **Submission Format**: PDF presentation and code repository via GitHub.
- **Grading Criteria**:
  - Effectiveness of solution (30%)
  - Teamwork and collaboration (25%)
  - Presentation clarity (25%)
  - Handling of questions (20%)

### Assessment Schedule

| Week | Assessment                    | Format                          | Weight |
|------|-------------------------------|---------------------------------|--------|
| 2    | Quiz 1                        | Online                          | 5%     |
| 4    | Quiz 2                        | Online                          | 5%     |
| 8    | Project Proposal              | PDF via Canvas                 | 10%    |
| 8    | Hands-on Lab 1                | Code and report via Canvas     | 10%    |
| 10   | Quiz 3                        | Online                          | 5%     |
| 12   | Progress Report               | PDF via Canvas                 | 10%    |
| 12   | Hands-on Lab 2                | Code and report via Canvas     | 10%    |
| 15   | Draft Documentation           | PDF and code via GitHub        | 15%    |
| 16   | Final Project                 | PDF and presentation via GitHub | 25%    |
| 16   | Participation & Peer Evaluation| Ongoing                        | 5%     |

## Grading Rubrics

### Example Grading Rubric for Project Proposal

| Criteria                      | Excellent (90-100)                     | Good (80-89)                          | Fair (70-79)                     | Poor (below 70)          |
|-------------------------------|-----------------------------------------|---------------------------------------|----------------------------------|--------------------------|
| Clarity of Objectives         | Clearly defined, specific, and measurable objectives. | Defined objectives; some clarity.    | Vague objectives; unclear scope. | No clear objectives.     |
| Relevance of Tools & Methods  | Tools/methods are appropriate and well justified. | Mostly appropriate; minor gaps.      | Some tools/methods are irrelevant. | Inappropriate tools/methods chosen. |
| Feasibility                   | Realistically achievable within the timeline. | Generally feasible; minor issues.    | Unclear feasibility; significant challenges identified. | Not feasible within the proposed timeline. |
| Group Coordination             | Evidence of effective collaboration and established communication channels. | Good coordination; some issues noted. | Minimal collaboration; weak communication strategy. | No evidence of group coordination. |

### Participation & Peer Evaluation
- **Participation**: Engagement during discussions and contribution to group work (5% total).
- **Peer Evaluation**: Feedback from group members regarding collaboration effectiveness.

## Submission Logistics
- All assessments are submitted via **Canvas**.
- Code submissions for hands-on labs must include a well-commented README file in the GitHub repository.
- Document submissions must be in **PDF** format.

### Real-World Relevance and Analysis
- Utilization of industry-standard tools fosters an understanding of data systems and cloud environments.
- Projects require consideration of ethical practices relevant to current industry standards.

### Continuous Improvement
- Feedback sessions will allow adjustments to be made to enhance course design and instruction.

This structured, milestone-driven assessment plan will support student learning while ensuring they acquire essential practical skills and theoretical knowledge for success in data processing at scale.