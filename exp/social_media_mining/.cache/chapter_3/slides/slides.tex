\documentclass{beamer}

% Theme choice
\usetheme{Madrid} % You can change to e.g., Warsaw, Berlin, CambridgeUS, etc.

% Encoding and font
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% Graphics and tables
\usepackage{graphicx}
\usepackage{booktabs}

% Code listings
\usepackage{listings}
\lstset{
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red},
  breaklines=true,
  frame=single
}

% Math packages
\usepackage{amsmath}
\usepackage{amssymb}

% Colors
\usepackage{xcolor}

% TikZ and PGFPlots
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}

% Hyperlinks
\usepackage{hyperref}

% Title information
\title{Chapter 3: Data Collection Techniques}
\author{Your Name}
\institute{Your Institution}
\date{\today}

\begin{document}

\frame{\titlepage}

\begin{frame}
    \titlepage
\end{frame}

\begin{frame}[fragile]
    \frametitle{Overview of Data Collection Techniques}
    Data collection is a critical step in research and analysis, particularly within social media. We will focus on two primary methods:

    \begin{enumerate}
        \item \textbf{APIs (Application Programming Interfaces)}
        \item \textbf{Web Scraping}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding APIs}
    \begin{block}{Definition}
        APIs act as intermediaries that allow software applications to communicate. Many social media platforms provide APIs for structured access to data.
    \end{block}

    \begin{itemize}
        \item \textbf{Advantages:}
        \begin{itemize}
            \item \textbf{Structured Data:} Data is returned in a predefined structure (e.g., JSON, XML).
            \item \textbf{Real-time Access:} Provides real-time data for timely insights.
        \end{itemize}
        
        \item \textbf{Example:} Twitter API
        \begin{itemize}
            \item Gather tweets based on keywords or user profiles.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Web Scraping}
    \begin{block}{Definition}
        Web scraping involves extracting data directly from web pages, providing access to information that may not be available via APIs.
    \end{block}

    \begin{itemize}
        \item \textbf{Advantages:}
        \begin{itemize}
            \item \textbf{Access to Unstructured Data:} Collect large amounts of data from web pages.
            \item \textbf{Customizable:} Tailor scraping to specific data needs.
        \end{itemize}
        
        \item \textbf{Example:} Scraping Product Reviews
        \begin{itemize}
            \item Gathering reviews and ratings from e-commerce sites for sentiment analysis.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Code Snippet}
    \begin{block}{Key Points}
        \begin{itemize}
            \item \textbf{Ethics and Legality:} Always ensure compliance with terms of use.
            \item \textbf{Data Format and Cleaning:} APIs usually provide cleaner data than web scraping.
        \end{itemize}
    \end{block}

    \begin{block}{Useful Code Snippet for API Access (Python)}
    \begin{lstlisting}[language=Python]
import requests

# Example of accessing Twitter API
url = "https://api.twitter.com/2/tweets"
headers = {"Authorization": "Bearer YOUR_ACCESS_TOKEN"}
response = requests.get(url, headers=headers)
data = response.json()
print(data)
    \end{lstlisting}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion}
    Understanding and utilizing APIs and web scraping techniques effectively can significantly enhance your ability to collect and analyze data from social media. 
    \begin{itemize}
        \item Remember the role each method plays based on your research goals.
        \item Always review ethical considerations and data handling processes.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Social Media Ecosystem}
    \begin{block}{Key Social Media Platforms}
        \begin{enumerate}
            \item \textbf{Facebook}
                \begin{itemize}
                    \item Functionality: Sharing text, photos, videos; personal profiles, groups, pages, and Marketplace.
                    \item Influence: Connects people; news source; facilitates movements; faces criticism for privacy issues.
                \end{itemize}
            \item \textbf{Twitter}
                \begin{itemize}
                    \item Functionality: Microblogging; posting tweets (max 280 characters); retweets and hashtags.
                    \item Influence: Real-time news; public discourse; amplifies hate speech and misinformation.
                \end{itemize}
            \item \textbf{Instagram}
                \begin{itemize}
                    \item Functionality: Photo/video sharing; Stories and Reels; aesthetic content.
                    \item Influence: Shapes trends; impacts self-image and mental health, especially for teenagers.
                \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Social Media Ecosystem - Part 2}
    \begin{block}{Key Social Media Platforms (cont.)}
        \begin{enumerate}
            \setcounter{enumi}{3}
            \item \textbf{LinkedIn}
                \begin{itemize}
                    \item Functionality: Professional networking; job postings; article publishing.
                    \item Influence: Transforms job searching; creates pressure to maintain an idealized persona.
                \end{itemize}
            \item \textbf{TikTok}
                \begin{itemize}
                    \item Functionality: Video-sharing platform; short clips often set to music; trends and challenges.
                    \item Influence: Changes entertainment and marketing; impacts youth culture.
                \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Analyzing Their Influence on Society and Culture}
    \begin{block}{Key Points}
        \begin{itemize}
            \item Social media platforms influence social behaviors and trends.
            \item Impact ranges from daily communication to global movements.
            \item Understanding both positive and negative influences is crucial.
        \end{itemize}
    \end{block}
    
    \begin{block}{Conclusion}
        Understanding the social media ecosystem is vital for effective data analysis. Be aware of their influence on relationships, culture, and society.
    \end{block}

    \begin{block}{References/Examples}
        \begin{itemize}
            \item Example: #MeToo movement on Twitter and Instagram.
            \item Study: Research on social media effects on mental health among adolescents.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Data Sources - Overview}
    Social media platforms serve as rich sources of data for researchers, marketers, and developers. 
    They facilitate content creation, social networking, and community engagement, leading to valuable user-generated data.
    
    We will discuss three prominent platforms:
    \begin{itemize}
        \item Twitter
        \item Facebook
        \item Instagram
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Data Sources - Twitter}
    \begin{block}{Twitter}
        \begin{itemize}
            \item \textbf{Type of Data:}
            \begin{itemize}
                \item Tweets (up to 280 characters)
                \item Retweets (shares of other users' tweets)
                \item Likes (user approval of tweets)
                \item Mentions and Hashtags (identify conversations and topics)
            \end{itemize}
            \item \textbf{Examples:}
            \begin{itemize}
                \item Sentiment Analysis: Analyzing tweets to gauge public sentiment
                \item Trending Topics: Data on currently popular hashtags
            \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Data Sources - Facebook and Instagram}
    \begin{block}{Facebook}
        \begin{itemize}
            \item \textbf{Type of Data:}
            \begin{itemize}
                \item Posts and Comments (text, images, videos)
                \item Reactions (various emotional responses)
                \item Groups and Events (community interactions)
            \end{itemize}
            \item \textbf{Examples:}
            \begin{itemize}
                \item Behavioral Analysis: Understanding interactions in groups
                \item Polls: Analyzing user feedback on topics
            \end{itemize}
        \end{itemize}
    \end{block}

    \begin{block}{Instagram}
        \begin{itemize}
            \item \textbf{Type of Data:}
            \begin{itemize}
                \item Images and Videos (indicate lifestyle preferences)
                \item Stories (temporary posts for user insights)
                \item Comments and Tags (user interactions)
            \end{itemize}
            \item \textbf{Examples:}
            \begin{itemize}
                \item Influencer Marketing: Studying engagement metrics
                \item Visual Trends: Analyzing popular aesthetics
            \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Data Sources - Key Points & Conclusion}
    \begin{itemize}
        \item \textbf{User Engagement:} Interactions like likes and comments gauge community sentiment.
        \item \textbf{Real-time Trends:} Social media data allows for live updates and analyses.
        \item \textbf{Diversity of Content:} Each platform offers unique data formats for analysis.
    \end{itemize}
    
    \begin{block}{Conclusion}
        Understanding the types of data available from platforms like Twitter, Facebook, and Instagram enhances research and marketing strategies.
    \end{block}

    \begin{block}{Further Considerations}
        \begin{itemize}
            \item Ethics in Data Collection: Privacy concerns and user consent must be prioritized.
            \item APIs for Data Access: Future discussions will cover how APIs can gather data from these platforms.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{API Data Collection - Introduction}
    \begin{block}{Introduction to APIs}
        APIs (Application Programming Interfaces) provide a standardized way for applications to communicate with each other over the internet. Using APIs allows access to a variety of data from sources like social media platforms, databases, and public datasets, enhancing data collection capabilities.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{API Data Collection - Steps}
    \begin{enumerate}
        \item \textbf{Find the API Documentation}
        \begin{itemize}
            \item Understand the specific API (e.g., Twitter API).
            \item Documentation includes endpoints, request methods, and data formats.
        \end{itemize}

        \item \textbf{Obtain API Keys and Tokens}
        \begin{itemize}
            \item Register for an account to obtain API credentials.
            \item Keys identify you and control access to the API.
        \end{itemize}

        \item \textbf{Authenticate Your Requests}
        \begin{itemize}
            \item APIs use methods like OAuth or Basic Authentication.
            \item Include your credentials in requests.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{API Data Collection - Making Calls and Key Points}
    \begin{enumerate}
        \setcounter{enumi}{3}
        \item \textbf{Making API Calls}
        \begin{itemize}
            \item Use appropriate HTTP methods (GET, POST).
            \item Specify query parameters to refine data retrieval.
        \end{itemize}

        \item \textbf{Processing the Retrieved Data}
        \begin{itemize}
            \item Data is often in JSON format; parse it using JSON libraries.
        \end{itemize}

        \begin{exampleblock}{Code Snippet}
            \begin{lstlisting}[language=Python]
import requests

url = "https://api.twitter.com/2/tweets"
headers = {
    "Authorization": "Bearer YOUR_ACCESS_TOKEN"
}
response = requests.get(url, headers=headers)
            \end{lstlisting}
        \end{exampleblock}

        \item \textbf{Key Points to Emphasize}
        \begin{itemize}
            \item API Rate Limits: Respect limits to avoid being blocked.
            \item Data Formats: Familiarize with JSON.
            \item Error Handling: Implement error-checking in requests.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{API Data Collection - Conclusion}
    \begin{block}{Conclusion}
        Using APIs for data collection provides a powerful way to access real-time data from various platforms. Understanding the steps of accessing, authenticating, and retrieving data enhances your capability to leverage these resources effectively in your projects.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Web Scraping Techniques}
    \begin{block}{Introduction to Web Scraping}
        Web scraping is the process of automatically extracting data from websites. It differs from APIs by accessing web pages directly and parsing their content. Useful for gathering large datasets unavailable through traditional means.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Common Methods of Web Scraping}
    \begin{enumerate}
        \item \textbf{HTML Parsing}: 
            \begin{itemize}
                \item Retrieve HTML content and parse it for data 
                \item Tools: Beautiful Soup, lxml
            \end{itemize}
        
        \item \textbf{DOM Manipulation}: 
            \begin{itemize}
                \item Automate browsers using headless approaches for JavaScript-heavy sites 
                \item Tools: Selenium
            \end{itemize}
        
        \item \textbf{APIs}: 
            \begin{itemize}
                \item Use available endpoints for clean data retrieval 
                \item Scraping can be a fallback when no API exists 
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Tools for Web Scraping}
    \begin{itemize}
        \item \textbf{Beautiful Soup}: 
            \begin{itemize}
                \item Python library for parsing HTML/XML 
                \item Creates parse trees from page source 
                \item Example Code:
                \begin{lstlisting}
from bs4 import BeautifulSoup
import requests

url = 'http://example.com'
response = requests.get(url)
soup = BeautifulSoup(response.content, 'html.parser')
title = soup.title.string
print(title)
                \end{lstlisting}
            \end{itemize}

        \item \textbf{Scrapy}:
            \begin{itemize}
                \item Open-source framework for web crawling 
                \item Defines link following and content extraction 
                \item Key Features: efficiency, request handling, data pipelines
            \end{itemize}

        \item \textbf{Selenium}:
            \begin{itemize}
                \item Used primarily for testing but suitable for dynamic content 
                \item Example Code:
                \begin{lstlisting}
from selenium import webdriver

driver = webdriver.Chrome()
driver.get('http://example.com')
print(driver.title)
driver.quit()
                \end{lstlisting}
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Considerations in Web Scraping}
    \begin{itemize}
        \item \textbf{Respect Robots.txt}: 
            \begin{itemize}
                \item Check the site's `robots.txt` for scraping permissions
            \end{itemize}

        \item \textbf{Rate Limiting}: 
            \begin{itemize}
                \item Avoid overwhelming servers; implement delays to mimic human behavior
            \end{itemize}

        \item \textbf{Data Privacy}: 
            \begin{itemize}
                \item Handle personal data responsibly, ensuring compliance with regulations like GDPR
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points to Remember}
    \begin{itemize}
        \item Web scraping is a powerful data collection method that must be conducted ethically.
        \item Familiarity with tools like Beautiful Soup, Scrapy, and Selenium enhances scraping capability.
        \item Always prioritize website policies, user privacy, and legal considerations in scraping projects.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Considerations in Data Collection - Introduction}
    \begin{block}{Introduction to Ethical Considerations}
        Ethics in data collection refers to the moral principles and guidelines that govern how we gather, use, and share data. 
        Ensuring ethical practices helps protect individuals' rights while maintaining the integrity of research.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Considerations in Data Collection - Key Frameworks}
    \begin{enumerate}
        \item \textbf{Data Privacy Laws}
            \begin{itemize}
                \item \textbf{Definition:} Safeguard personal information collected by organizations.
                \item \textbf{Examples:}
                    \begin{itemize}
                        \item \textbf{GDPR:} Regulates data processing in the EU, enhancing individual protection.
                        \item \textbf{CCPA:} Grants Californians rights over their personal data including access and opt-out options.
                    \end{itemize}
            \end{itemize}

        \item \textbf{Informed Consent}
            \begin{itemize}
                \item \textbf{Definition:} Individuals must be informed about data usage and access.
                \item \textbf{Importance:} Participants must voluntarily agree, understanding risks involved.
                \item \textbf{Example:} Consent forms in surveys detailing the study's aim and data practices.
            \end{itemize}

        \item \textbf{Responsible Data Use}
            \begin{itemize}
                \item \textbf{Definition:} Responsible collection and usage to avoid harm.
                \item \textbf{Considerations:} 
                    \begin{itemize}
                        \item Data minimization: Collect only necessary information.
                        \item Anonymization to protect individual identities.
                    \end{itemize}
                \item \textbf{Example:} Anonymizing user data in social media studies.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Considerations in Data Collection - Conclusions}
    \begin{enumerate}
        \item \textbf{Ethical Dilemmas}
            \begin{itemize}
                \item Balancing benefits vs. risks: Weighing social benefits against privacy concerns.
                \item Avoiding biased data: Ensuring collection methods do not perpetuate societal inequalities.
            \end{itemize}
        \item \textbf{Key Points}
            \begin{itemize}
                \item Prioritize privacy and informed consent.
                \item Familiarize with data privacy laws and regulations.
                \item Implement responsible data practices to build trust.
            \end{itemize}
        \item \textbf{Discussion Question}
            \begin{itemize}
                \item "How do you think researchers should handle data collection that might infringe on privacy rights but is deemed necessary for public good?"
            \end{itemize}
    \end{enumerate}

    \begin{block}{Conclusion}
        Understanding ethics in data collection is crucial for fostering trust, promoting accountability, and ensuring integrity in research endeavors.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Practical Case Study Examples - Overview}
    In today’s digital landscape, social media data is a valuable resource for understanding trends, opinions, and user behavior. This slide highlights two key methods of data collection: 
    \begin{itemize}
        \item \textbf{APIs}
        \item \textbf{Web Scraping}
    \end{itemize}
    Practical case studies will illustrate best practices in data collection.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data Collection via APIs}
    
    \begin{block}{Concept}
        APIs (Application Programming Interfaces) allow developers to access specific data from applications in a structured manner without engaging in web scraping.
    \end{block}
    
    \begin{block}{Case Study: Twitter API}
        \textbf{Objective}: Track sentiment regarding a political event.
        \begin{itemize}
            \item Use Twitter's API to collect tweets with a specific hashtag.
            \item Focus on real-time data fetching for up-to-date insights.
        \end{itemize}
    \end{block}
    
    \begin{lstlisting}[language=Python]
import tweepy

# Authenticate to Twitter API
auth = tweepy.OAuth1UserHandler(consumer_key, consumer_secret, access_token, access_token_secret)
api = tweepy.API(auth)

# Fetch tweets
tweets = api.search_tweets(q="#YourHashtag", count=100, lang="en")
for tweet in tweets:
    print(tweet.text)
    \end{lstlisting}
    
    \begin{block}{Best Practices}
        \begin{itemize}
            \item Ensure compliance with Twitter’s API rate limits to avoid being blocked.
            \item Use filtering options in the API to refine the data (e.g., language, date range).
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data Collection via Web Scraping}
    
    \begin{block}{Concept}
        Web scraping involves extracting data from web pages using scripts while respecting the website's \texttt{robots.txt} file.
    \end{block}
    
    \begin{block}{Case Study: Scraping Instagram Data}
        \textbf{Objective}: Analyze engagement metrics for selected influencers.
        \begin{itemize}
            \item Use libraries like BeautifulSoup and requests in Python to gather posts and engagement statistics from influencer profiles.
        \end{itemize}
    \end{block}
    
    \begin{lstlisting}[language=Python]
import requests
from bs4 import BeautifulSoup

# Target URL
url = "https://www.instagram.com/username/"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# Extract posts
for post in soup.find_all('div', class_='v1Nh3'):
    image_url = post.find('img')['src']
    print(image_url)
    \end{lstlisting}

    \begin{block}{Best Practices}
        \begin{itemize}
            \item Monitor the site’s terms of service to ensure web scraping is allowed.
            \item Implement delays between requests to avoid overloading the server.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Technical Challenges and Solutions in Data Collection}
    \begin{block}{Overview}
        Data collection, especially from APIs and web scraping, involves various technical challenges.   
        Recognizing these challenges is the first step toward effective solutions.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Common Technical Challenges}
    \begin{enumerate}
        \item \textbf{API Rate Limits}
        \begin{itemize}
            \item Description: Most APIs impose limits on the number of requests that can be made in a certain time frame.
            \item Example: Twitter API limits users to 900 requests per 15 minutes for user timelines.
            \item Solution: Implement exponential backoff strategies to manage multiple requests within constraints.
        \end{itemize}
        
        \item \textbf{Data Format and Structure Changes}
        \begin{itemize}
            \item Description: APIs and web pages can change their data structures unexpectedly, leading to broken scripts.
            \item Example: Changing HTML tags from `<div>` to `<span>` can break web scraping.
            \item Solution: Utilize robust error handling and regularly update scraping logic.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Common Technical Challenges (Continued)}
    \begin{enumerate}
        \setcounter{enumi}{2} % continue numbering from previous frame
        \item \textbf{Authentication and Authorization Issues}
        \begin{itemize}
            \item Description: Many data sources require authentication, complicating access.
            \item Example: OAuth tokens must be refreshed periodically.
            \item Solution: Automate token renewal processes and securely store credentials.
        \end{itemize}
        
        \item \textbf{Data Quality and Inconsistencies}
        \begin{itemize}
            \item Description: Collected data may have inconsistencies or missing values affecting analysis.
            \item Example: User-generated content can vary wildly in format.
            \item Solution: Employ data validation and cleaning techniques.
        \end{itemize}
        
        \item \textbf{Legal and Ethical Constraints}
        \begin{itemize}
            \item Description: Privacy laws restrict data collection and usage.
            \item Example: Scraping personal data without consent can lead to legal issues.
            \item Solution: Familiarize with relevant laws and anonymize data.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points to Emphasize}
    \begin{itemize}
        \item \textbf{Proactive Planning:} Anticipating challenges and implementing solutions can save time.
        \item \textbf{Automation is Key:} Automate processes to mitigate human error.
        \item \textbf{Continuous Monitoring:} Regularly review data collection methods for changes.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Example Code Snippet for Handling Rate Limits}
    \begin{lstlisting}[language=Python]
import time
import requests

def fetch_data(url):
    while True:
        response = requests.get(url)
        if response.status_code == 200:
            return response.json()
        elif response.status_code == 429:  # Too Many Requests
            print("Rate limit exceeded. Retrying after delay...")
            time.sleep(15)  # Wait before trying again
        else:
            print("Error:", response.status_code)
            break

# Usage
data = fetch_data("https://api.example.com/data")
    \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion}
    Understanding and addressing the technical hurdles of data collection enhances data reliability and ensures compliance. Implementing the outlined strategies can improve processes and outcomes significantly.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data Quality and Validation}
    \begin{block}{Introduction to Data Quality}
        Data Quality refers to the condition of a dataset, evaluated by factors including accuracy, completeness, reliability, and relevance.
        Ensuring high data quality is vital for achieving meaningful insights and informed decision-making.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance of Data Validation Techniques}
    \begin{itemize}
        \item Data Validation ensures data is accurate and useful.
        \item Essential for:
        \begin{itemize}
            \item Reducing errors that can lead to faulty conclusions.
            \item Enhancing the trustworthiness of analytics results.
            \item Complying with data governance standards and regulations.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Validation Techniques}
    \begin{enumerate}
        \item \textbf{Consistency Checks}: Ensure that data entries follow a predefined format.
        \begin{itemize}
            \item Example: Verifying valid email formats (e.g., user@domain.com).
        \end{itemize}
        \item \textbf{Range Checks}: Verifies numerical data falls within expected ranges.
        \begin{itemize}
            \item Example: Age should be between 0 and 120.
        \end{itemize}
        \item \textbf{Cross-Referencing}: Compare data against trustworthy datasets.
        \begin{itemize}
            \item Example: Verifying social media data with census data.
        \end{itemize}
        \item \textbf{Duplicate Detection}: Identify and merge duplicate records.
        \begin{itemize}
            \item Example: Ensuring a single user profile is not listed multiple times.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Assessing Data Reliability from Social Media Sources}
    \begin{itemize}
        \item Social Media data presents unique challenges due to its unstructured nature and varying quality.
        \item Assess reliability through:
        \begin{itemize}
            \item \textbf{Source Credibility}: Evaluate authenticity of profiles (check for verified accounts).
            \item \textbf{Engagement Metrics}: High engagement indicates reliability but needs contextual analysis.
            \item \textbf{Sentiment Analysis}: Tools such as VADER or TextBlob can help assess sentiment.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item High data quality is foundational for accurate analysis and decision-making.
            \item Validation techniques should be tailored for different data sources, especially unstructured data.
            \item Regular checks and validations must be integral to any data strategy.
        \end{itemize}
    \end{block}
    
    \begin{block}{Formula Summary}
        \[
        \text{Validation} = \text{Accuracy} + \text{Completeness} + \text{Consistency} + \text{Reliability}
        \]
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Future Trends - Key Takeaways}
    \begin{block}{Key Takeaways on Data Collection Techniques}
        Data collection is essential for analyzing and understanding social phenomena. We’ve explored:
        \begin{itemize}
            \item \textbf{Methods of Data Collection:} 
                \begin{itemize}
                    \item Qualitative and quantitative methods (surveys, focus groups, observational studies).
                    \item Each method has strengths and weaknesses depending on research questions.
                    \item \textit{Example:} Surveys yield quantitative data but may lack depth compared to focus groups.
                \end{itemize}
            \item \textbf{Challenges in Data Collection:}
                \begin{itemize}
                    \item Data privacy, ethical considerations, reliability of open-source data.
                    \item The importance of data validation techniques for accuracy.
                    \item \textit{Example:} Cross-validation methods to compare data across platforms.
                \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Future Trends - Advances in Social Media Data Mining}
    \begin{block}{Advances in Social Media Data Mining}
        As technology evolves, data collection and analysis techniques become more sophisticated:
        \begin{enumerate}
            \item \textbf{Machine Learning Algorithms:}
                \begin{itemize}
                    \item Natural language processing (NLP) for sentiment analysis and trend identification.
                    \item \textit{Code Snippet:}
                    \begin{lstlisting}[language=Python]
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

# Preprocessing text data
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(messages)  
model = MultinomialNB()
model.fit(X, labels)  
                    \end{lstlisting}
                \end{itemize}
            \item \textbf{Real-Time Data Tracking:} 
                \begin{itemize}
                    \item Developing tools for live data streaming from social media.
                    \item \textit{Example:} Enhanced reactions during crises through real-time sentiment analysis.
                \end{itemize}
            \item \textbf{Big Data Technologies:}
                \begin{itemize}
                    \item Using frameworks like Apache Hadoop and Spark for efficient data handling.
                \end{itemize}
            \item \textbf{Ethical AI & Responsible Data Mining:} 
                \begin{itemize}
                    \item Focus on transparency, accountability, and fairness in AI models.
                \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Future Trends - Future Implications and Summary}
    \begin{block}{Future Implications}
        The future of data collection will prioritize user privacy and responsible handling:
        \begin{itemize}
            \item Ethical frameworks will shape research access to social media data.
            \item Researchers must keep pace with evolving legal standards and public expectations regarding consent and data ownership.
        \end{itemize}
    \end{block}
    
    \begin{block}{Summary}
        In conclusion, the landscape of data collection from social media is rapidly changing. 
        \begin{itemize}
            \item New technologies and methodologies necessitate awareness of ethical implications.
            \item Understanding future trends will help in navigating the complex world of data-driven insights effectively.
        \end{itemize}
    \end{block}
\end{frame}


\end{document}