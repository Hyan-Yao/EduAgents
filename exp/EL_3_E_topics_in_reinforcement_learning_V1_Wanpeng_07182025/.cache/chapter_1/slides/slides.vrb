\frametitle{Core Concepts of Reinforcement Learning - Markov Decision Processes (MDPs)}
    \begin{block}{Definition}
        A mathematical framework for modeling decision-making in situations where the outcomes are partly random and partly under the control of a decision-maker.
    \end{block}
    \begin{itemize}
        \item \textbf{Components}:
        \begin{itemize}
            \item \textbf{States (S)}: All possible situations in which an agent can find itself.
            \item \textbf{Actions (A)}: Choices available to the agent in each state.
            \item \textbf{Transition Function (P)}: Probability distribution of reaching the next state given the current state and action, $P(s'|s, a)$.
            \item \textbf{Reward Function (R)}: Immediate return received after transitioning from state $s$ to state $s'$ via action $a$, $R(s, a, s')$.
            \item \textbf{Discount Factor ($\gamma$)}: A factor (0 â‰¤ $\gamma$ < 1) that weighs immediate rewards higher than future rewards.
        \end{itemize}
        \item \textbf{Example}: A simple MDP could be a grid world where an agent must navigate to a goal while avoiding obstacles.
    \end{itemize}
