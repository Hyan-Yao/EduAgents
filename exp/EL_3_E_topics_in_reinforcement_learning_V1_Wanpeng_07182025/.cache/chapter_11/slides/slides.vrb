\frametitle{Strategies for Effective Exploration - Key Strategies}
    \begin{enumerate}
        \item \textbf{Îµ-Greedy Strategy}
        \begin{itemize}
            \item Balances exploration and exploitation with probabilities \( (1 - \epsilon) \) and \( \epsilon \).
            \item Example: If \( \epsilon = 0.1 \), the agent exploits 90\% and explores 10\%.
            \item \begin{equation}
                \text{Action} =
                \begin{cases}
                    \text{Best Action} & \text{with probability } 1 - \epsilon \\
                    \text{Random Action} & \text{with probability } \epsilon
                \end{cases}
            \end{equation}
            \item Benefit: Simple to implement and encourages sufficient exploration.
        \end{itemize}

        \item \textbf{Upper Confidence Bound (UCB)}
        \begin{itemize}
            \item Prioritizes actions based on average rewards and uncertainty.
            \item Formula:
            \begin{equation}
                A_t = \arg\max_{a} \left( Q_t(a) + c \sqrt{\frac{\ln(t)}{N_t(a)}} \right)
            \end{equation}
            \item Where \( Q_t(a) \) is the estimated value and \( N_t(a) \) is the action count.
        \end{itemize}
    \end{enumerate}
