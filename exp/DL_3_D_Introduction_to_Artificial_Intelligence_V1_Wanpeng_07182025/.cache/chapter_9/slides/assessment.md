# Assessment: Slides Generation - Week 9: Ethical Implications of AI

## Section 1: Introduction to Ethical Implications of AI

### Learning Objectives
- Recognize and describe various ethical implications associated with AI technologies.
- Articulate the societal impact of these ethical considerations, including bias, accountability, transparency, and privacy.

### Assessment Questions

**Question 1:** What ethical consideration addresses the issue of biases in AI training data?

  A) Accountability
  B) Transparency
  C) Bias and Fairness
  D) Privacy Concerns

**Correct Answer:** C
**Explanation:** Bias and Fairness refers to the ethical obligation to address and mitigate biases present in training data to ensure that AI systems make fair decisions.

**Question 2:** Why is transparency important in AI decision-making?

  A) It increases sales.
  B) It ensures faster processing times.
  C) It helps build trust and accountability.
  D) It makes coding easier.

**Correct Answer:** C
**Explanation:** Transparency is essential in AI because it allows users to understand how decisions are made, fostering trust and ensuring accountability.

**Question 3:** Which of the following is a potential consequence of AI-based job automation?

  A) Increased job security for all workers.
  B) Redistribution of wealth and opportunities.
  C) Workforce displacement and economic inequality.
  D) Complete elimination of data privacy concerns.

**Correct Answer:** C
**Explanation:** Automating jobs through AI can lead to workforce displacement, resulting in economic disparities and challenges for affected workers.

**Question 4:** What is a key ethical challenge associated with AI-generated deepfakes?

  A) Improved film production.
  B) Misinformation and manipulation of public opinion.
  C) Increased data storage capacities.
  D) Enhanced user experience in gaming.

**Correct Answer:** B
**Explanation:** AI-generated deepfakes pose ethical challenges as they can spread misinformation and manipulate public perceptions, undermining trust in information sources.

### Activities
- Research a recent event related to AI ethics and present your findings, including the ethical implications observed and possible solutions.

### Discussion Questions
- In your opinion, which ethical implication of AI is the most pressing today? Why?
- How can organizations balance the benefits of AI with potential ethical risks?
- Discuss ways to improve transparency in AI algorithms. What specific measures would you suggest?

---

## Section 2: Learning Objectives

### Learning Objectives
- Understand the various ethical concerns surrounding AI technologies.
- Analyze the societal implications of ethical dilemmas in AI.
- Investigate contemporary AI applications that raise ethical questions.
- Engage in ethical decision-making regarding AI technologies.

### Assessment Questions

**Question 1:** What ethical concern is raised by biased algorithms in AI?

  A) Increased computational efficiency
  B) Improved decision-making
  C) Potential racial bias
  D) Enhanced user privacy

**Correct Answer:** C
**Explanation:** Biased algorithms can lead to unfair treatment of individuals, often resulting in racial bias.

**Question 2:** Which of the following is an implication of AI in law enforcement?

  A) Enhanced civilian privacy
  B) Biased policing strategies
  C) Improved transparency
  D) Decreased operational costs

**Correct Answer:** B
**Explanation:** The use of biased algorithms in policing can significantly influence sentencing and policing strategies unjustly.

**Question 3:** What is one of the key skills you will develop regarding AI technologies?

  A) Coding languages proficiency
  B) Ethical decision-making
  C) Hardware understanding
  D) Business management

**Correct Answer:** B
**Explanation:** Developing skills for ethical decision-making will help assess AI impacts effectively.

**Question 4:** What should a code of ethics for an AI start-up prioritize?

  A) Profit maximization
  B) Transparency and accountability
  C) Reducing costs
  D) Speed of development

**Correct Answer:** B
**Explanation:** A sound ethical framework for an AI start-up includes prioritizing transparency and accountability.

### Activities
- Develop a short essay (300-500 words) discussing an ethical concern in AI, such as bias or privacy issues, and propose potential solutions.
- Create a presentation outlining the ethical implications of a specific AI application in your field of interest. Include three ethical guidelines to address these implications.

### Discussion Questions
- How can we ensure diversity in training datasets to avoid bias in AI algorithms?
- What role do you think government regulations should play in AI ethics?
- Can ethical AI exist in a profit-driven environment? Why or why not?

---

## Section 3: Historical Context

### Learning Objectives
- Understand the evolution of AI ethics through significant historical events.
- Analyze and reflect on key case studies that inform current ethical perspectives.

### Assessment Questions

**Question 1:** What significant event is regarded as the birth of AI as a research field?

  A) The Dartmouth Conference
  B) The Turing Test
  C) The Moral Machine Experiment
  D) The Cambridge Analytica scandal

**Correct Answer:** A
**Explanation:** The Dartmouth Conference in 1956 marked the beginning of AI as a research field, sparking discussions about the capabilities and control of intelligent systems.

**Question 2:** What was the main focus of the Moral Machine Experiment conducted by MIT?

  A) Developing self-driving car technology
  B) Analyzing global moral perspectives in AI decision-making
  C) Investigating AI capabilities in gaming
  D) Assessing the efficiency of algorithms

**Correct Answer:** B
**Explanation:** The Moral Machine Experiment aimed to explore how people from different cultures make moral decisions about self-driving cars in accident scenarios.

**Question 3:** Which scandal raised serious ethical questions concerning the use of AI in data analysis?

  A) The Moral Machine Project
  B) Cambridge Analytica
  C) The Turing Test
  D) Asimov's Laws of Robotics

**Correct Answer:** B
**Explanation:** The Cambridge Analytica scandal exposed the misuse of data analytics in political advertising, prompting debates about privacy and accountability.

**Question 4:** What do recent AI ethical guidelines generally emphasize?

  A) Focus on technical prowess
  B) Importing guidelines from unrelated fields
  C) Fairness, accountability, and transparency
  D) Exclusively developing advanced algorithms

**Correct Answer:** C
**Explanation:** Recent ethical guidelines primarily focus on fairness, accountability, and transparency to build trust in AI systems.

### Activities
- Create a timeline that illustrates the key events in the history of AI ethics. Include at least five major milestones and briefly describe their significance.
- Research a contemporary ethical issue related to AI and prepare a short presentation that outlines the problem, its historical context, and potential future implications.

### Discussion Questions
- What lessons can be learned from the historical events in AI ethics, and how can they be applied to current AI technologies?
- In what ways do cultural differences impact ethical decision-making in AI, as illustrated by the Moral Machine Experiment?

---

## Section 4: Key Ethical Concepts

### Learning Objectives
- Define key ethical concepts relevant to AI.
- Assess the importance of these concepts in AI deployment.
- Analyze real-world examples of ethical dilemmas in AI.

### Assessment Questions

**Question 1:** Which of the following is NOT considered a key ethical concept in AI?

  A) Fairness
  B) Accountability
  C) Efficiency
  D) Transparency

**Correct Answer:** C
**Explanation:** Efficiency is not an ethical concept; it relates more to performance.

**Question 2:** What is a core aspect of fairness in AI systems?

  A) Ensuring systems are profitable
  B) Avoiding biases that lead to prejudiced outcomes
  C) Increasing the speed of decision making
  D) Implementing complex algorithms

**Correct Answer:** B
**Explanation:** Fairness involves designing AI systems that avoid biases in order to ensure equitable outcomes.

**Question 3:** Which concept is closely linked to the responsibility for AI system outcomes?

  A) Fairness
  B) Transparency
  C) Accountability
  D) Privacy

**Correct Answer:** C
**Explanation:** Accountability is about having mechanisms to hold responsible parties liable for AI outcomes.

**Question 4:** What does transparency in AI primarily involve?

  A) Keeping algorithms secret
  B) Clarity about how AI systems operate
  C) Reducing the size of datasets
  D) Minimizing the use of computational resources

**Correct Answer:** B
**Explanation:** Transparency refers to the need for clarity regarding the operations and decisions made by AI systems.

**Question 5:** Which of the following practices promotes user privacy in AI?

  A) Data sharing without consent
  B) Data minimization
  C) Collecting as much data as possible
  D) Ignoring privacy regulations

**Correct Answer:** B
**Explanation:** Data minimization ensures that AI programs collect only the necessary data, enhancing user privacy.

### Activities
- Work in small groups to examine a recent case of AI implementation. Identify any ethical concerns related to fairness, accountability, transparency, or privacy, and discuss potential solutions.

### Discussion Questions
- How can organizations balance the need for data in AI systems while maintaining privacy?
- What are some practical steps that can be taken to ensure fairness in AI applications?
- In what ways can transparency in AI enhance user trust?

---

## Section 5: Fairness in AI

### Learning Objectives
- Identify and articulate the challenges related to fairness in AI algorithms.
- Critically evaluate the implications of bias in AI algorithms on diverse groups.
- Develop strategies for assessing and mitigating biases in AI systems.

### Assessment Questions

**Question 1:** What is a major source of bias in AI algorithms?

  A) Data bias
  B) User interface design
  C) Server speed
  D) Programming languages

**Correct Answer:** A
**Explanation:** Data bias occurs when the training data reflects historical inequalities, which can lead to unfair AI outcomes.

**Question 2:** Which of the following best describes equitable outcomes in AI?

  A) Treating all individuals equally regardless of their needs.
  B) Ensuring no group is disproportionately negatively impacted by decisions made by AI.
  C) Prioritizing accuracy over fairness.
  D) Using complex algorithms to enhance performance.

**Correct Answer:** B
**Explanation:** Equitable outcomes focus on ensuring that all individuals are treated fairly and that no group experiences harm due to AI decisions.

**Question 3:** What does demographic parity aim to achieve?

  A) Equal true positive rates across all demographic groups.
  B) Equal outcomes across different demographic groups.
  C) Fairness through algorithmic transparency.
  D) Increased predictive accuracy.

**Correct Answer:** B
**Explanation:** Demographic parity seeks to achieve equal outcomes for different demographic groups to reduce bias.

### Activities
- Conduct a case study analysis where an AI system exhibited bias. Identify the source of the bias and propose potential solutions to mitigate it.
- Develop a plan for auditing an AI system to identify potential biases, including the specific metrics and methods you would use to measure fairness.

### Discussion Questions
- In your opinion, what constitutes 'fairness' in AI, and how may perceptions of fairness differ among various stakeholders?
- Discuss a real-world example where AI bias had significant implications for society. How could this have been prevented?

---

## Section 6: Accountability in AI Systems

### Learning Objectives
- Discuss the concept of accountability within AI systems.
- Analyze the responsibilities of developers in AI design and their implications for ethical practices.
- Evaluate the role of transparency and documentation in establishing accountability.

### Assessment Questions

**Question 1:** Who is typically held accountable for decisions made by AI systems?

  A) The user
  B) The developer
  C) The AI itself
  D) No one

**Correct Answer:** B
**Explanation:** Developers are generally considered responsible for the decisions made by their AI systems.

**Question 2:** What is a key aspect of responsible AI development?

  A) Conducting thorough bias checks
  B) Creating complex algorithms
  C) Maximizing system efficiency only
  D) Avoiding user feedback

**Correct Answer:** A
**Explanation:** Conducting thorough bias checks is essential for responsible AI development to prevent unfair outcomes.

**Question 3:** In the case of an autonomous vehicle accident, who might be held accountable?

  A) The pedestrian
  B) The vehicle itself
  C) The developer and the user
  D) The government

**Correct Answer:** C
**Explanation:** Both the developer of the AI system and the user are typically considered when assessing accountability for accidents involving autonomous vehicles.

**Question 4:** Why is transparent reporting important in AI accountability?

  A) It increases system profits
  B) It clarifies decision-making processes
  C) It reduces legal liability
  D) It democratizes AI access

**Correct Answer:** B
**Explanation:** Transparent reporting is crucial for clarifying decision-making processes and tracing accountability back to developers.

### Activities
- Conduct a case study analysis of a controversial AI decision (e.g., a hiring algorithm or an autonomous vehicle incident) to identify accountability challenges and propose solutions.
- Create a presentation outlining the key moral responsibilities of AI developers in a specific application area.

### Discussion Questions
- How can developers balance innovation with accountability in AI systems?
- In what ways can regulations enhance the accountability of AI technologies?
- What roles do users play in the accountability of AI decision-making?

---

## Section 7: Transparency in AI Technologies

### Learning Objectives
- Examine the role of transparency in user understanding of AI systems.
- Discuss the implications of a lack of transparency in AI technologies.
- Identify challenges related to making AI systems transparent and accountable.

### Assessment Questions

**Question 1:** What is a primary benefit of transparency in AI systems?

  A) It reduces the need for data.
  B) It enhances user trust.
  C) It increases processing time.
  D) It complicates the algorithm.

**Correct Answer:** B
**Explanation:** Transparency enhances user trust in AI technologies by allowing users to understand how decisions are made.

**Question 2:** Why is explainability important in AI?

  A) It guarantees accuracy.
  B) It allows for informed decision-making.
  C) It eliminates all biases.
  D) It speeds up the development process.

**Correct Answer:** B
**Explanation:** Explainability allows users to make informed decisions based on understanding the rationale behind AI recommendations.

**Question 3:** What challenge do complex AI algorithms pose for transparency?

  A) They are always more accurate.
  B) They can be categorized easily.
  C) They often function as black boxes.
  D) They guarantee user satisfaction.

**Correct Answer:** C
**Explanation:** Complex algorithms like deep learning models can act as black boxes, making it difficult for users to understand decision-making processes.

**Question 4:** What is one of the requirements under GDPR related to AI?

  A) AI must be free of data.
  B) AI must provide explanations for automated decisions.
  C) AI must always produce perfect results.
  D) AI should not require any user feedback.

**Correct Answer:** B
**Explanation:** Under GDPR, individuals have the right to receive explanations for decisions made by automated systems that affect them.

### Activities
- Create a case study presentation that explores a real-world AI application. Discuss how transparency and explainability were considered and any improvements that could be made.

### Discussion Questions
- What are some ethical considerations related to the transparency of AI technologies?
- How can organizations effectively communicate the workings of their AI systems to non-technical stakeholders?
- What measures can be taken to enhance the explainability of complex AI algorithms?

---

## Section 8: Privacy Concerns

### Learning Objectives
- Understand concepts from Privacy Concerns

### Activities
- Practice exercise for Privacy Concerns

### Discussion Questions
- Discuss the implications of Privacy Concerns

---

## Section 9: Societal Impacts of AI

### Learning Objectives
- Understand how AI affects employment and requires shifting skill sets.
- Examine the implications of AI on social systems and equity.
- Analyze the economic changes driven by AI adoption and its consequences.

### Assessment Questions

**Question 1:** What is a potential negative impact of AI on employment?

  A) Increase in job satisfaction
  B) Job displacement in certain sectors
  C) Creation of entirely new job sectors
  D) Decrease in worker productivity

**Correct Answer:** B
**Explanation:** AI can lead to job displacement in sectors like manufacturing and customer service, raising concerns about unemployment in those areas.

**Question 2:** How can AI influence social systems?

  A) By making decision-making processes more obscure
  B) By increasing socioeconomic equality
  C) By integrating into government and healthcare decision-making
  D) By eliminating the need for government oversight

**Correct Answer:** C
**Explanation:** AI is increasingly being integrated into decision-making processes across various sectors, which can impact policy and access to services.

**Question 3:** What is a potential positive impact of AI on economic structures?

  A) Reduced productivity
  B) Increased efficiency and economic growth
  C) Increased unemployment rates
  D) Static economic models

**Correct Answer:** B
**Explanation:** AI has the potential to drive economic growth by improving efficiency and productivity in numerous industries.

**Question 4:** Which of the following describes a key point regarding AI and skill requirements?

  A) Skill requirements will remain unchanged
  B) Workers need to upskill or reskill to remain competitive
  C) Only technical jobs will require new skills
  D) Reskilling is unnecessary for most workers

**Correct Answer:** B
**Explanation:** As AI influences job markets, continued learning and adaptation will be essential for workers to compete effectively.

### Activities
- Write a report analyzing the societal impacts of a specific AI technology, focusing on its effects on employment, social equity, and economic structures.
- Conduct a role-play exercise where students simulate the decision-making process in a government agency using AI tools, discussing potential biases and ethical considerations.

### Discussion Questions
- What measures can be implemented to ensure equitable access to AI technologies in underserved communities?
- How can policymakers design regulations that address the potential risks of AI while fostering innovation?

---

## Section 10: Regulatory and Policy Frameworks

### Learning Objectives
- Understand existing regulations related to AI technologies and their implications.
- Evaluate proposed policies for ethical AI governance and the significance of international collaboration.

### Assessment Questions

**Question 1:** What is a key purpose of regulatory frameworks in AI?

  A) To stifle innovation
  B) To provide governance
  C) To increase profits
  D) To limit access to technology

**Correct Answer:** B
**Explanation:** Regulatory frameworks aim to provide governance over AI development and use.

**Question 2:** Which of the following regulations requires transparency in AI decision-making?

  A) The Algorithmic Accountability Act
  B) The AI Act
  C) General Data Protection Regulation (GDPR)
  D) All of the above

**Correct Answer:** D
**Explanation:** Each of these regulations incorporates measures aimed at ensuring transparency in AI systems and their decision-making processes.

**Question 3:** What does the AI Act propose regarding 'high-risk' AI applications?

  A) They require no compliance
  B) They are allowed unlimited access
  C) They must meet strict compliance requirements
  D) They must only be approved by private companies

**Correct Answer:** C
**Explanation:** The AI Act categorizes high-risk AI applications as needing strict compliance to ensure safety and ethical considerations.

**Question 4:** Which of the following reflects the essence of public accountability in AI regulations?

  A) Right to access proprietary algorithms
  B) Right to explanation
  C) Right to free data access
  D) Right to unlimited AI usage

**Correct Answer:** B
**Explanation:** The concept of the 'Right to Explanation' ensures that users can request information on how AI systems make decisions about them.

### Activities
- In small groups, analyze a specific AI technology (e.g., facial recognition, credit scoring) and evaluate its compliance with existing regulatory frameworks. Prepare a brief presentation summarizing your findings and recommendations for improvements.

### Discussion Questions
- What are the potential challenges in enforcing AI regulations across different countries?
- How might ethical standards for AI impact innovation in the field?
- In your opinion, what is the most significant risk associated with AI that regulators should address?

---

## Section 11: Ethical AI Design Principles

### Learning Objectives
- Understand best practices for designing ethically-aligned AI systems.
- Identify the importance of ethical design in technology and its impact on society.
- Analyze real-world AI applications through the ethical principles of transparency, fairness, accountability, privacy, and safety.

### Assessment Questions

**Question 1:** What does the principle of transparency in AI design emphasize?

  A) AI systems should be complex and hidden from users
  B) Users should understand decision-making processes of AI
  C) AI decisions should be inconclusive
  D) AI should prioritize user preferences above all

**Correct Answer:** B
**Explanation:** Transparency emphasizes that users should have a clear understanding of how AI systems make decisions.

**Question 2:** Which of the following best describes the fairness principle in ethical AI design?

  A) AI systems must treat all individuals equally
  B) AI should prioritize performance over bias reduction
  C) AI can reflect historical biases if they are prevalent
  D) Fairness is not a concern in AI design

**Correct Answer:** A
**Explanation:** Fairness in AI design ensures that AI applications treat all individuals equitably, avoiding biases based on race, gender, or other attributes.

**Question 3:** Why is accountability important in AI systems?

  A) To mitigate privacy concerns
  B) To ensure no one takes responsibility for errors
  C) To ensure developers take ownership of AI's impact
  D) To make AI systems less transparent

**Correct Answer:** C
**Explanation:** Accountability is crucial as it requires developers and organizations to take responsibility for the decisions made by AI systems.

### Activities
- Create a checklist of ethical considerations for an AI application that addresses each of the principles discussed in the slide (Transparency, Fairness, Accountability, Privacy, Safety & Security).
- In small groups, select a specific AI technology (like facial recognition or predictive policing) and analyze it through the lens of the ethical principles presented. Prepare a short presentation with your findings.

### Discussion Questions
- How can we ensure that AI systems remain accountable when problems arise?
- What role do stakeholders play in establishing ethical AI systems, and how can their voices be incorporated effectively?
- In your opinion, which ethical principle should be prioritized in AI design, and why?

---

## Section 12: Case Studies

### Learning Objectives
- Analyze prominent AI applications and their associated ethical challenges.
- Propose feasible solutions for identified ethical dilemmas in the discussed case studies.
- Evaluate the effectiveness of implemented solutions in real-world scenarios.

### Assessment Questions

**Question 1:** What ethical challenge is associated with facial recognition technology?

  A) Increased data storage
  B) Invasion of privacy
  C) Improved user experience
  D) Enhanced security measures

**Correct Answer:** B
**Explanation:** Facial recognition technology often captures and analyzes images without users' consent, leading to privacy violations.

**Question 2:** Which solution has been implemented to address bias in AI algorithms?

  A) Increased marketing efforts
  B) Algorithm audits
  C) Enhanced data collection
  D) User feedback options

**Correct Answer:** B
**Explanation:** Algorithm audits involve independent evaluations that aim to identify and rectify biases present in AI algorithms.

**Question 3:** What is a key ethical dilemma faced by autonomous vehicles?

  A) Data storage requirements
  B) Decision-making during accidents
  C) Speed regulation
  D) User interface design

**Correct Answer:** B
**Explanation:** Autonomous vehicles must navigate the ethical challenge of making decisions in life-threatening situations, such as prioritizing safety for passengers vs. pedestrians.

**Question 4:** Which approach can help promote accountability in AI technology?

  A) Focusing solely on profit
  B) Regulatory frameworks
  C) Reducing transparency
  D) Ignoring user consent

**Correct Answer:** B
**Explanation:** Regulatory frameworks help ensure transparency and consent, which are vital in holding AI technologies accountable for their actions.

### Activities
- Review the facial recognition and autonomous vehicle case studies. Prepare a presentation outlining the ethical challenges and the solutions that were implemented in each case.

### Discussion Questions
- How would you approach resolving an ethical dilemma in AI that affects public safety? Provide a specific example.
- Discuss how societal values may influence the development of ethical AI guidelines.

---

## Section 13: Discussion Activity

### Learning Objectives
- Engage in discussions on ethical dilemmas in AI technology.
- Develop critical thinking about the ethical implications of AI.
- Collaborate to explore diverse perspectives on ethical challenges.

### Assessment Questions

**Question 1:** What is a major ethical concern regarding bias in AI algorithms?

  A) They may increase efficiency in decision-making.
  B) They could perpetuate societal biases.
  C) They are more secure than human decision-makers.
  D) They require less data to train.

**Correct Answer:** B
**Explanation:** AI algorithms can reflect and even amplify existing biases in training data, leading to unfair outcomes in sensitive areas such as hiring and law enforcement.

**Question 2:** When discussing data privacy concerns in AI, which factor is most critical?

  A) The AI's ability to learn.
  B) User consent in data collection.
  C) Speed of data processing.
  D) The complexity of algorithms used.

**Correct Answer:** B
**Explanation:** User consent is essential in data privacy discussions to respect individual rights and ensure ethical data handling practices.

**Question 3:** Who should ideally be held accountable for decisions made by autonomous AI systems?

  A) The end user only.
  B) The developers and manufacturers.
  C) The governing bodies of AI technology.
  D) All stakeholders involved.

**Correct Answer:** D
**Explanation:** Accountability for decisions by AI should involve all stakeholders, including users, developers, and policymakers to promote ethical governance.

### Activities
- In small groups, create a hypothetical scenario involving an ethical dilemma related to AI. Present your scenario and propose potential solutions to your classmates.

### Discussion Questions
- How can AI developers ensure that their algorithms do not propagate existing biases?
- In what ways can consumers influence ethical standards in AI technology?
- What are the potential impacts of job displacement due to AI on society as a whole?

---

## Section 14: Reflection on Learning

### Learning Objectives
- Reflect on the key points discussed throughout the course.
- Assess personal understanding and perspectives on AI ethics.
- Apply ethical considerations to real-world AI technologies.

### Assessment Questions

**Question 1:** Which of the following is NOT a core ethical concern related to AI?

  A) Bias
  B) Transparency
  C) Job displacement
  D) Hardware performance

**Correct Answer:** D
**Explanation:** Hardware performance is a technical concern and does not directly relate to the ethical implications of AI.

**Question 2:** What framework emphasizes ethical considerations when developing AI technologies?

  A) IEEE Global Initiative
  B) National AI Agenda
  C) AI Development Partnership
  D) Machine Learning Standards Association

**Correct Answer:** A
**Explanation:** The IEEE Global Initiative provides guidelines for ethical considerations in AI and autonomous systems.

**Question 3:** Which ethical dilemma involves the risk of surveillance overreach?

  A) Bias in AI Models
  B) Autonomous Systems
  C) Surveillance and Privacy
  D) Performance Optimization

**Correct Answer:** C
**Explanation:** Surveillance and privacy concerns are highlighted by the use of AI technologies like facial recognition.

**Question 4:** Reflecting on personal ethics regarding AI responsibility can help you to:

  A) Ignore AI developments
  B) Shape future technology practices
  C) Ensure biased AI development
  D) Prioritize personal success over ethical concerns

**Correct Answer:** B
**Explanation:** Understanding personal ethics in the context of AI can guide responsible future practices in technology.

### Activities
- Write a reflective piece on your lessons learned about AI ethics, including personal insights and real-world implications.
- Create a case study presentation focusing on a specific AI technology, discussing its ethical implications and your proposed guidelines for responsible use.

### Discussion Questions
- How do you believe AI impacts societal norms and individual privacy?
- Are there specific historical instances where AI has led to ethical dilemmas? Discuss and provide examples.
- What roles do you think technology and policy should play in addressing ethical concerns in AI?

---

