\documentclass[aspectratio=169]{beamer}

% Theme and Color Setup
\usetheme{Madrid}
\usecolortheme{whale}
\useinnertheme{rectangles}
\useoutertheme{miniframes}

% Additional Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}
\usepackage{hyperref}

% Custom Colors
\definecolor{myblue}{RGB}{31, 73, 125}
\definecolor{mygray}{RGB}{100, 100, 100}
\definecolor{mygreen}{RGB}{0, 128, 0}
\definecolor{myorange}{RGB}{230, 126, 34}
\definecolor{mycodebackground}{RGB}{245, 245, 245}

% Set Theme Colors
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=white, bg=myblue}
\setbeamercolor{title}{fg=myblue}
\setbeamercolor{section in toc}{fg=myblue}
\setbeamercolor{item projected}{fg=white, bg=myblue}
\setbeamercolor{block title}{bg=myblue!20, fg=myblue}
\setbeamercolor{block body}{bg=myblue!10}
\setbeamercolor{alerted text}{fg=myorange}

% Set Fonts
\setbeamerfont{title}{size=\Large, series=\bfseries}
\setbeamerfont{frametitle}{size=\large, series=\bfseries}
\setbeamerfont{caption}{size=\small}
\setbeamerfont{footnote}{size=\tiny}

% Footer and Navigation Setup
\setbeamertemplate{footline}{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
    \usebeamerfont{author in head/foot}\insertshortauthor
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.5\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
    \usebeamerfont{title in head/foot}\insertshorttitle
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.2\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}%
    \usebeamerfont{date in head/foot}
    \insertframenumber{} / \inserttotalframenumber
  \end{beamercolorbox}}%
  \vskip0pt%
}

% Title Page Information
\title[Week 3: Deep Learning and Neural Networks]{Week 3: Deep Learning and Neural Networks}
\author[J. Smith]{John Smith, Ph.D.}
\institute[University Name]{
  Department of Computer Science\\
  University Name\\
  \vspace{0.3cm}
  Email: email@university.edu\\
  Website: www.university.edu
}
\date{\today}

% Document Start
\begin{document}

\frame{\titlepage}

\begin{frame}[fragile]
    \frametitle{Introduction to Deep Learning - Overview}
    \begin{block}{Definition and Concept}
        Deep Learning is a subset of machine learning, which itself is a subset of artificial intelligence (AI). 
        It involves algorithms inspired by the structure and function of the brain, specifically artificial neural networks. 
        Traditional machine learning relies on feature engineering, while deep learning automates this process by learning 
        hierarchical representations of data through layers of neurons.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Introduction to Deep Learning - Significance in AI}
    Deep Learning has transformed the landscape of AI, enabling machines to perform complex tasks that were previously 
    considered challenging for computers. Its significance is highlighted in areas such as:
    
    \begin{itemize}
        \item \textbf{Computer Vision}: Applications like facial recognition and image classification.
        \item \textbf{Natural Language Processing (NLP)}: Models like ChatGPT and BERT that understand and generate human-like text.
        \item \textbf{Speech Recognition}: Technology behind virtual assistants such as Siri and Alexa.
        \item \textbf{Robotics}: Navigating environments and making decisions based on sensory input.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Introduction to Deep Learning - Key Differentiators and Applications}
    \begin{block}{Key Differentiators}
        \begin{enumerate}
            \item \textbf{Large Datasets}: Deep learning thrives on big data, where traditional algorithms may struggle.
            \item \textbf{Layered Architecture}: Utilizing multiple layers allows for the automatic extraction of features without manual intervention.
            \item \textbf{High Computational Power}: Advances in GPUs and TPUs have made training complex models feasible.
        \end{enumerate}
    \end{block}
    
    \begin{block}{Real-world Applications}
        \begin{itemize}
            \item \textbf{Image Classification}: Convolutional Neural Networks (CNNs) can identify objects in images with accuracy surpassing human performance (e.g., self-driving cars).
            \item \textbf{ChatGPT (GPT-4)}: Processes and generates text, providing context-aware conversations.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Introduction to Deep Learning - Architecture and Conclusion}
    \begin{block}{Fundamental Architecture: Neural Networks}
        \begin{itemize}
            \item \textbf{Neurons}: The basic units of a neural network, mimicking biological neurons.
            \item \textbf{Layers}: Composed of input, hidden, and output layers, each responsible for transforming the input data.
            \item \textbf{Activation Functions}: Functions like ReLU and sigmoid help in decision-making at each neuron.
        \end{itemize}
    \end{block}
    
    \begin{block}{Conclusion}
        Deep learning enhances performance across various domains and pushes the boundaries of what machines can achieve. 
        Understanding its principles and applications is essential for harnessing the power of modern AI.
    \end{block}
    
    \begin{block}{Key Points to Remember}
        \begin{itemize}
            \item Deep Learning is a critical component of modern AI.
            \item It automates feature extraction using layered neural networks.
            \item It excels in tasks requiring large datasets and computational capabilities.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Overview of Neural Networks - Part 1}
    
    \textbf{Introduction to Neural Networks}
    
    \begin{itemize}
        \item Neural networks are a subset of machine learning that mimic human brain operations.
        \item They serve as the backbone of deep learning, effectively recognizing patterns in various data types.
        \item Applications include image and speech recognition, language processing, etc.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Overview of Neural Networks - Part 2}
    
    \textbf{Structure of Neural Networks}
    
    A neural network consists of interconnected layers of nodes, or "neurons". The primary components are:
    
    \begin{enumerate}
        \item \textbf{Input Layer}: Receives initial data; each neuron corresponds to a feature.
        \item \textbf{Hidden Layers}: One or more layers that extract patterns from the input. 
        \item \textbf{Output Layer}: Produces the final output, representing the class label in classification tasks.
    \end{enumerate}
    
    \begin{block}{Diagram of Neural Network Structure}
    \begin{center}
    \small
    \texttt{
       Input Layer      Hidden Layer(s)         Output Layer \\
           [ ]                [ ]                    [ ] \\
           [ ]                [ ]                    [ ] \\
           [ ]                [ ]                    [ ] \\
    }
    \end{center}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Overview of Neural Networks - Part 3}
    
    \textbf{Function of Neural Networks}
    
    \begin{itemize}
        \item \textbf{Feedforward Process}: Data flows from input to output with computations at each neuron.
        \item \textbf{Activation Functions}: Introduce non-linearity.
            \begin{itemize}
                \item \textbf{Sigmoid}: Outputs values between 0 and 1.
                \item \textbf{ReLU (Rectified Linear Unit)}: Outputs zero for negative inputs and inputs for positive values.
            \end{itemize}
    \end{itemize}
    
    \textbf{Mathematical Representation:}
    \begin{equation}
    y = f(w \cdot x + b)
    \end{equation}
    Where:
    \begin{itemize}
        \item $y$: output
        \item $f$: activation function
        \item $w$: weight vector
        \item $x$: input vector
        \item $b$: bias term
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Terminology - Introduction}
    Understanding foundational terminology in deep learning and neural networks is crucial for grasping how these systems operate. This slide will define key terms that we will encounter frequently in our studies.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Terminology - Neurons}
    \begin{itemize}
        \item \textbf{Neurons:} The basic unit of a neural network, inspired by biological neurons in the human brain. 
        \item \textbf{Definition:} Each artificial neuron receives inputs, processes them, and produces an output.
        \item \textbf{Example:} A neuron may take three inputs, each multiplied by a weight, summed, and passed through an activation function.
    \end{itemize}
    \begin{block}{Mathematical Representation}
        \[
        y = f(w_1 x_1 + w_2 x_2 + w_3 x_3 + b)
        \]
        \begin{itemize}
            \item \(y\) = output of the neuron
            \item \(f\) = activation function
            \item \(w_i\) = weight for input \(x_i\)
            \item \(b\) = bias term
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Terminology - Layers and Activation Functions}
    \begin{itemize}
        \item \textbf{Layers:} A collection of neurons working together in a neural network.
        \begin{itemize}
            \item \textbf{Input Layer:} Receives the input data.
            \item \textbf{Hidden Layer:} Processes inputs through neurons.
            \item \textbf{Output Layer:} Produces the final output of the network.
        \end{itemize}
        \item \textbf{Example:} A network might have an Input(3) -> Hidden(4) -> Hidden(4) -> Output(1).
    \end{itemize}
    
    \begin{itemize}
        \item \textbf{Activation Functions:} Determine the output of a neuron and introduce non-linearity.
        \begin{itemize}
            \item \textbf{ReLU:} \(f(x) = \max(0, x)\)
            \item \textbf{Sigmoid:} \(f(x) = \frac{1}{1 + e^{-x}}\)
            \item \textbf{Tanh:} \(f(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}\)
        \end{itemize}
        \item \textbf{Example:} ReLU often used in hidden layers; sigmoid may be used in output layer for binary classification.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Terminology - Backpropagation}
    \begin{itemize}
        \item \textbf{Backpropagation:} A supervised learning algorithm for training neural networks.
        \item \textbf{Process:}
        \begin{enumerate}
            \item Forward pass: Compute the output of the network.
            \item Calculate loss: Compare predicted output with actual output.
            \item Backward pass: Update weights to minimize loss.
        \end{enumerate}
    \end{itemize}
    \begin{block}{Key Formula}
        \[
        w_{\text{new}} = w_{\text{old}} - \eta \frac{\partial L}{\partial w}
        \]
        \begin{itemize}
            \item \(w\) = weight
            \item \(\eta\) = learning rate
            \item \(L\) = loss function
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Summary}
    \begin{itemize}
        \item Neurons are the building blocks of neural networks.
        \item Layers organize multiple neurons and define the flow of data.
        \item Activation functions enable networks to learn complex patterns.
        \item Backpropagation is essential for optimizing weights and minimizing loss during training.
    \end{itemize}
    
    \textbf{Summary:} This foundational terminology sets the stage for diving deeper into neural network architectures and their applications in deep learning, preparing us for more complex concepts in the upcoming slides.
\end{frame}

\begin{frame}[fragile]
  \frametitle{Neural Network Architecture - Overview}
  \begin{block}{Overview}
    Neural networks are at the core of deep learning, representing complex interactions modeled after the human brain. 
    They can be structured in various architectures, each designed for specific tasks. 
    This slide will explore three primary neural network architectures:
    \begin{itemize}
      \item Feedforward Neural Networks (FNNs)
      \item Convolutional Neural Networks (CNNs)
      \item Recurrent Neural Networks (RNNs)
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Neural Network Architecture - Feedforward Neural Networks}
  \begin{block}{1. Feedforward Neural Networks (FNNs)}
    \textbf{Description:}
    \begin{itemize}
      \item \textbf{Structure:} Consists of input, hidden, and output layers.
      \item \textbf{Data Flow:} Information moves in one direction; from input to output with no cycles or loops.
    \end{itemize}
    
    \textbf{Key Features:}
    \begin{itemize}
      \item Simple to construct and understand.
      \item Good for basic classification tasks.
    \end{itemize}

    \textbf{Example:} 
    A network predicting whether an email is spam based on various features, such as the number of links or specific keywords.
    
    \textbf{Illustration:} Input Layer → Hidden Layer(s) → Output Layer
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Neural Network Architecture - Convolutional Neural Networks}
  \begin{block}{2. Convolutional Neural Networks (CNNs)}
    \textbf{Description:}
    \begin{itemize}
      \item \textbf{Structure:} Composed of convolutional layers utilizing filters (kernels) to detect patterns.
      \item \textbf{Data Flow:} Involves both forwards and backpropagation, applying filters to the input.
    \end{itemize}

    \textbf{Key Features:}
    \begin{itemize}
      \item Excellent for image processing, capturing spatial hierarchies.
      \item Reduces manual feature extraction through automatic learning of filters.
    \end{itemize}

    \textbf{Example:} Image recognition tasks, such as classifying images of cats versus dogs.

    \begin{equation}
    S(i,j) = \sum_m \sum_n I(m,n) \cdot K(i-m, j-n)
    \end{equation}
    Where \( S \) is the output feature map, \( I \) is the input image, and \( K \) represents the kernel.

    \textbf{Illustration:} Input Image → Convolution Layer → Activation Function → Pooling Layer → Fully Connected Layer → Output
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Neural Network Architecture - Recurrent Neural Networks}
  \begin{block}{3. Recurrent Neural Networks (RNNs)}
    \textbf{Description:}
    \begin{itemize}
      \item \textbf{Structure:} Allows connections between neurons in a layer to form cycles, maintaining state or memory.
      \item \textbf{Data Flow:} Can process sequences of inputs of arbitrary length.
    \end{itemize}

    \textbf{Key Features:}
    \begin{itemize}
      \item Ideal for sequential data such as time series or natural language.
      \item Utilizes hidden states to carry information across time steps.
    \end{itemize}

    \textbf{Example:} Sentiment analysis on text data, where the understanding of context over words is crucial.

    \textbf{Special Type:} Long Short-Term Memory (LSTM) is a variant designed to learn long-range dependencies, overcoming the vanishing gradient problem.
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Neural Network Architecture - Key Points and Conclusion}
  \begin{block}{Key Points to Emphasize}
    \begin{itemize}
      \item \textbf{Feedforward Networks:} Foundational for static data.
      \item \textbf{Convolutional Networks:} Excel in spatial data handling like images.
      \item \textbf{Recurrent Networks:} Essential for sequence data, commonly used in NLP tasks.
    \end{itemize}
  \end{block}
  
  \begin{block}{Conclusion}
    Understanding these neural network architectures is crucial for applying deep learning effectively across various domains. Their unique structures determine their suitability for different tasks, from simple classification to complex language processing.
  \end{block}
\end{frame}

\begin{frame}
    \frametitle{Learning Objectives for Week 3}
    \begin{itemize}
        \item Understand the fundamentals of neural networks.
        \item Differentiate between various neural network architectures.
        \item Apply key concepts of deep learning.
        \item Recognize recent developments in deep learning.
        \item Explore practical frameworks for model development.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Understanding Neural Networks}
    \begin{enumerate}
        \item \textbf{Understand the Fundamentals of Neural Networks:}
        \begin{itemize}
            \item Explain the basic architecture including input, hidden, and output layers.
            \item Identify the role of activation functions.
        \end{itemize}
        
        \begin{block}{Key Point}
            A neural network mimics the human brain's structure by using interconnected nodes (neurons) to process information.
        \end{block}
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{Neural Network Architectures}
    \begin{enumerate}
        \setcounter{enumi}{1}
        \item \textbf{Differentiate Between Various Neural Network Architectures:}
        \begin{itemize}
            \item \textbf{Feedforward Neural Networks:} Data moves in one direction.
            \item \textbf{Convolutional Neural Networks (CNNs):} Specialized for image processing.
            \item \textbf{Recurrent Neural Networks (RNNs):} Designed for sequential data.
        \end{itemize}

        \begin{block}{Example Illustration}
            \textbf{Feedforward Network Example:} A simple feedforward model predicting binary outcomes.
        \end{block}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts of Deep Learning}
    \begin{enumerate}
        \setcounter{enumi}{2}
        \item \textbf{Apply Key Concepts of Deep Learning:}
        \begin{itemize}
            \item Utilize backpropagation and gradient descent.
            \item Understand loss functions and their role.
        \end{itemize}
        
        \begin{equation}
            L(y, \hat{y}) = -\frac{1}{n} \sum_{i=1}^{n} [y_i \log(\hat{y_i}) + (1-y_i) \log(1-\hat{y_i})]
        \end{equation}
        
        \begin{block}{Formula Highlight}
            Here, \( y \) is the true label, and \( \hat{y} \) is the predicted output.
        \end{block}
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{Recent Developments and Frameworks}
    \begin{enumerate}
        \setcounter{enumi}{3}
        \item \textbf{Recognize Recent Developments in Deep Learning:}
        \begin{itemize}
            \item Discuss advancements like GPT-4 and transformer architecture.
        \end{itemize}

        \begin{block}{Key Point}
            Staying updated with cutting-edge models enriches understanding and prepares for real-world applications.
        \end{block}

        \item \textbf{Explore Practical Frameworks for Model Development:}
        \begin{itemize}
            \item Gain experience with TensorFlow, Keras, and PyTorch.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Code Snippet Example}
    \begin{block}{Example Code Snippet}
    \begin{lstlisting}[language=Python]
    # Example of a simple Keras model
    from keras.models import Sequential
    from keras.layers import Dense

    model = Sequential()
    model.add(Dense(128, activation='relu', input_shape=(input_dim,)))
    model.add(Dense(1, activation='sigmoid'))  # Binary classification
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    \end{lstlisting}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Deep Learning Frameworks - Overview}
    \begin{itemize}
        \item Deep learning frameworks are software libraries that help develop, train, and deploy neural networks.
        \item They abstract complex mathematical computations.
        \item This allows researchers and developers to focus on model architecture and design.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Deep Learning Frameworks - Industry-Standard}
    \begin{enumerate}
        \item \textbf{TensorFlow}
            \begin{itemize}
                \item Developed by Google, open-source library for various ML tasks.
                \item Scalable architecture for CPU and GPU deployment.
                \item \textbf{Key Features:}
                    \begin{itemize}
                        \item Production-scale deployment.
                        \item TensorBoard for visualization.
                        \item Extensive documentation.
                    \end{itemize}
                \item \textbf{Example Usage:}
                \begin{lstlisting}[language=Python]
import tensorflow as tf

model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(10, activation='softmax')
])
                \end{lstlisting}
            \end{itemize}
        
        \item \textbf{Keras}
            \begin{itemize}
                \item High-level API for fast experimentation, user-friendly and modular.
                \item \textbf{Key Features:}
                    \begin{itemize}
                        \item Intuitive API.
                        \item Support for convolutional and recurrent networks.
                        \item Integration with TensorFlow backend.
                    \end{itemize}
                \item \textbf{Example Usage:}
                \begin{lstlisting}[language=Python]
from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
model.add(Dense(64, activation='relu', input_dim=8))
model.add(Dense(1, activation='sigmoid'))
                \end{lstlisting}
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Deep Learning Frameworks - Industry-Standard (cont'd)}
    \begin{enumerate}
        \setcounter{enumi}{2}
        \item \textbf{PyTorch}
            \begin{itemize}
                \item Developed by Facebook’s AI Research lab, popular for dynamic computation and ease of use.
                \item \textbf{Key Features:}
                    \begin{itemize}
                        \item Eager execution for immediate operation evaluation.
                        \item GPU acceleration support.
                        \item Strong community support.
                    \end{itemize}
                \item \textbf{Example Usage:}
                \begin{lstlisting}[language=Python]
import torch
import torch.nn as nn

class SimpleNN(nn.Module):
    def __init__(self):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x
                \end{lstlisting}
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of Deep Learning - Overview}
    \begin{block}{Overview}
        Deep learning, a subset of machine learning, leverages neural networks with many layers to analyze various types of data. 
        Its transformative impact is evident across numerous sectors, enabling innovations that enhance efficiency, accuracy, and decision-making.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of Deep Learning - Healthcare and Finance}
    \begin{itemize}
        \item \textbf{Healthcare}
        \begin{itemize}
            \item Deep learning facilitates diagnosis, treatment planning, and predictive analytics.
            \item Analyzes medical images or patient data to identify patterns and assist in early detection of diseases.
            \item \textbf{Example:} Google's DeepMind detects eye diseases with accuracy comparable to human specialists.
            \item \textbf{Key Points:}
                \begin{itemize}
                    \item Improved diagnostic accuracy
                    \item Reduction in diagnostic time
                    \item Enhanced personalized treatment plans
                \end{itemize}
        \end{itemize}
        
        \item \textbf{Finance}
        \begin{itemize}
            \item Enhances fraud detection, risk management, and algorithmic trading.
            \item Processes vast datasets from transactions or market trends.
            \item \textbf{Example:} PayPal uses deep learning to adaptively learn from new risks in transaction patterns.
            \item \textbf{Key Points:}
                \begin{itemize}
                    \item Real-time detection and response
                    \item Precise credit scoring models
                    \item Automation of trading strategies
                \end{itemize}
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of Deep Learning - Image Recognition and NLP}
    \begin{itemize}
        \item \textbf{Image Recognition}
        \begin{itemize}
            \item Relies on convolutional neural networks (CNNs) to classify images and interpret visual data.
            \item \textbf{Example:} Social media platforms utilize deep learning for facial recognition to tag friends in photos.
            \item \textbf{Key Points:}
                \begin{itemize}
                    \item Applications in security and surveillance
                    \item Enhancements in augmented reality
                    \item Streamlining content moderation
                \end{itemize}
        \end{itemize}

        \item \textbf{Natural Language Processing (NLP)}
        \begin{itemize}
            \item Enables machines to understand and generate human language.
            \item \textbf{Example:} ChatGPT and Amazon's Alexa use transformer models for seamless interactions.
            \item \textbf{Key Points:}
                \begin{itemize}
                    \item Improved sentiment analysis and language translation
                    \item Automation of customer service responses
                    \item Support for content generation applications
                \end{itemize}
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Case Study: Image Recognition - Introduction}
    \begin{block}{Introduction to Image Recognition}
        Image recognition is a task where deep learning models identify and classify objects, scenes, or activities within images. Utilizing Convolutional Neural Networks (CNNs) has greatly improved the accuracy and efficiency of image classification tasks.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Case Study: Image Recognition - Key Concepts}
    \begin{enumerate}
        \item \textbf{Convolutional Neural Networks (CNNs)}:
        \begin{itemize}
            \item \textbf{Architecture}: Layers include convolutional, pooling, and fully connected layers.
            \item \textbf{Functionality}: Automatically detect spatial hierarchies in data, focusing on local patterns.
        \end{itemize}
        
        \item \textbf{Training Process}:
        \begin{itemize}
            \item \textbf{Data Preparation}: Images pre-processed (resizing, normalization).
            \item \textbf{Labeling}: Each image must be accurately labeled for supervised learning.
            \item \textbf{Training}: CNNs adjust weights using datasets (e.g., CIFAR-10, ImageNet).
        \end{itemize}
        
        \item \textbf{Loss Function}: 
        \begin{itemize}
            \item Cross-entropy loss is commonly used to measure the difference between predicted probabilities and actual class labels.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Case Study: Image Recognition - Example Case Study}
    \begin{block}{Example Case Study: CIFAR-10 Dataset}
        \begin{itemize}
            \item \textbf{Dataset Overview}: CIFAR-10 consists of 60,000 32x32 color images across 10 classes (e.g., airplane, automobile, bird).
            \item \textbf{Model Example}:
            \begin{lstlisting}[language=python]
from keras.datasets import cifar10
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Load dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize

# Create model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    MaxPooling2D(),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, epochs=10)
            \end{lstlisting}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Considerations - Overview}
    \begin{block}{Overview}
        The deployment of deep learning technologies presents a myriad of ethical implications that must be carefully considered to ensure responsible usage in society. 
        We will explore the balance between technological advancement and ethical responsibility.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Considerations - Bias and Fairness}
    \begin{enumerate}
        \item \textbf{Bias and Fairness}
        \begin{itemize}
            \item \textbf{Concept:} Deep learning models can inherit biases from training data, leading to unfair outcomes.
            \item \textbf{Example:} Facial recognition systems show higher error rates for certain ethnic backgrounds, perpetuating racial discrimination.
            \item \textbf{Key Point:} Ensure diverse datasets and implement fairness-aware algorithms to mitigate biases.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Considerations - Transparency and Privacy}
    \begin{enumerate}
        \setcounter{enumi}{1}
        \item \textbf{Transparency and Explainability}
        \begin{itemize}
            \item \textbf{Concept:} Many deep learning models operate as "black boxes."
            \item \textbf{Example:} In healthcare, a model might recommend treatments without clear justifications, leading to distrust.
            \item \textbf{Key Point:} Strive for transparency through explainable AI methodologies.
        \end{itemize}

        \item \textbf{Privacy Concerns}
        \begin{itemize}
            \item \textbf{Concept:} Data usage can lead to privacy violations if sensitive information is mishandled.
            \item \textbf{Example:} Social media algorithms analyze user interactions without explicit consent.
            \item \textbf{Key Point:} Adhere to data protection regulations (e.g., GDPR) and utilize anonymization techniques.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Considerations - Security and Societal Impact}
    \begin{enumerate}
        \setcounter{enumi}{3}
        \item \textbf{Security Risks}
        \begin{itemize}
            \item \textbf{Concept:} Deep learning models may be susceptible to adversarial attacks.
            \item \textbf{Example:} An image classifier misclassifying a stop sign if patterns are added.
            \item \textbf{Key Point:} Implement security measures and continuous model evaluation to mitigate threats.
        \end{itemize}

        \item \textbf{Societal Impact and Job Displacement}
        \begin{itemize}
            \item \textbf{Concept:} Automation can lead to job shifts, raising concerns about economic disparities.
            \item \textbf{Example:} While AI improves efficiency in industries, it may displace manual labor jobs.
            \item \textbf{Key Point:} Consider strategies for workforce retraining to promote fair transition.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Considerations - Conclusion}
    \begin{block}{Conclusion}
        Ethical considerations in deep learning require actionable strategies aligning technology with societal values. 
        Addressing these aspects fosters an environment where AI is deployed ethically and responsibly. 
        Recognizing these issues is crucial for successful integration into everyday applications.
    \end{block}
    
    \begin{block}{Reminder}
        As future practitioners, it's your responsibility to advocate for ethical practices in your work with AI technologies.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Hands-on Project Overview}
    \begin{block}{Introduction to the Project}
        This hands-on project will guide you through utilizing a deep learning framework to create a simple neural network. The objective is to provide practical experience with the concepts we’ve covered in Week 3, focusing on how neural networks function, their architecture, and their applications.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Learning Objectives}
    By the end of this project, you will be able to:
    \begin{itemize}
        \item Understand the basic components of a neural network.
        \item Implement a simple neural network using a popular deep learning framework (e.g., TensorFlow or PyTorch).
        \item Train the model on a dataset, evaluate its performance, and make predictions.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts}
    \begin{enumerate}
        \item \textbf{Neural Network}: A computational model inspired by the human brain, consisting of interconnected nodes (neurons) with weighted connections.
        
        \item \textbf{Activation Function}: Determines if a neuron should be activated, introducing non-linearity in the model. Common examples include:
        \begin{itemize}
            \item ReLU: $f(x) = \max(0, x)$
            \item Sigmoid: $f(x) = \frac{1}{1 + e^{-x}}$
        \end{itemize}
        
        \item \textbf{Loss Function}: Evaluates the network's performance. Common functions include:
        \begin{itemize}
            \item Mean Squared Error (MSE) for regression.
            \item Cross-Entropy Loss for classification tasks.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Project Outline}
    \begin{enumerate}
        \item \textbf{Choose the Framework}:
        \begin{itemize}
            \item Select either TensorFlow or PyTorch.
        \end{itemize}

        \item \textbf{Dataset Selection}:
        \begin{itemize}
            \item Use datasets like MNIST or Iris.
        \end{itemize}
        
        \item \textbf{Model Architecture}:
        \begin{itemize}
            \item Input Layer: Number of features.
            \item Hidden Layer(s): 1 or 2 layers, e.g., 64 neurons.
            \item Output Layer: Number of classes (e.g., 10 for digit classification).
        \end{itemize}
        
        \item \textbf{Training the Model}:
        \begin{itemize}
            \item Split dataset into training and testing sets.
            \item Compile model and fit it on training data.
        \end{itemize}
        
        \item \textbf{Evaluation}:
        \begin{itemize}
            \item Analyze model performance through metrics like accuracy.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Example Code Snippet}
    Here is a code snippet using TensorFlow to build and train a simple neural network:
    
    \begin{lstlisting}[language=Python]
import tensorflow as tf
from tensorflow import keras

# Load dataset
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Preprocess data
x_train = x_train.reshape((-1, 28 * 28)).astype('float32') / 255
x_test = x_test.reshape((-1, 28 * 28)).astype('float32') / 255

# Build model
model = keras.models.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(28 * 28,)),
    keras.layers.Dense(10, activation='softmax')
])

# Compile model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train model
model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))

# Evaluate model
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(f'\nTest accuracy: {test_acc}')
    \end{lstlisting}

\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points to Emphasize}
    \begin{itemize}
        \item A clear understanding of neural network architecture is vital.
        \item Practical application reinforces theoretical knowledge.
        \item Evaluating model performance helps in learning optimization techniques.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Next Steps}
    \begin{block}{Conclusion}
        This project will solidify your understanding of deep learning concepts and enhance your skills in using frameworks to tackle real-world problems. Document your process, as reflection is key to your learning journey!
    \end{block}
    
    \begin{block}{Next Steps}
        We will discuss collaborative learning strategies in the upcoming slide to enhance your teamwork during this project.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Collaborative Learning - Overview}
    \begin{block}{Overview}
        Collaborative learning is a powerful approach that fosters teamwork and enhances the overall learning experience, especially in complex projects like developing a deep learning model. 
    \end{block}
    This slide focuses on strategies for effective teamwork, including role assignments and communication tips that can facilitate collaboration.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Collaborative Learning - Key Concepts}
    \begin{enumerate}
        \item \textbf{Role Assignments}
        \begin{itemize}
            \item Clearly defining roles helps distribute tasks based on individual strengths and expertise, minimizing overlap and confusion.
            \item Common roles include:
            \begin{itemize}
                \item \textbf{Project Manager}: Oversees project timeline and coordinates tasks.
                \item \textbf{Data Engineer}: Handles data preprocessing and organization.
                \item \textbf{Model Developer}: Designs and implements neural network architecture.
                \item \textbf{Research Analyst}: Conducts literature reviews.
                \item \textbf{Quality Assurance Tester}: Validates model outputs and checks accuracy.
            \end{itemize}
        \end{itemize}
        \item \textbf{Effective Communication}
        \begin{itemize}
            \item Establishing open lines of communication is crucial for project success:
            \begin{itemize}
                \item Hold regular meetings to discuss progress.
                \item Utilize project management tools.
                \item Use instant messaging for quick communications.
            \end{itemize}
            \item \textbf{Tip}: Encourage all team members to express their ideas using "I" statements.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Collaborative Learning - Additional Concepts}
    \begin{enumerate}[resume]
        \item \textbf{Collaboration Tools}
        \begin{itemize}
            \item Utilize collaborative platforms for code sharing and documentation:
            \begin{itemize}
                \item \textbf{GitHub}: For version control and collaborative coding.
                \item \textbf{Google Drive}: For shared documents and data storage.
                \item \textbf{Jupyter Notebooks}: For collaborative code exploration.
            \end{itemize}
        \end{itemize}
        \item \textbf{Feedback Mechanisms}
        \begin{itemize}
            \item Incorporate regular feedback loops within the team:
            \begin{itemize}
                \item Assess what went well after major milestones.
                \item Foster a culture of constructive criticism.
            \end{itemize}
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Collaborative Learning - Conclusion}
    \begin{block}{Conclusion}
        Effective collaborative learning hinges on strategic role assignments, open communication, and the use of collaborative tools. By fostering an environment that promotes teamwork and continuous feedback, teams can navigate the complexities of deep learning projects more effectively.
    \end{block}
    \textbf{Key Takeaway}: Establish clear roles, maintain open communication, and regularly evaluate team dynamics to maximize project success.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Future Directions - Overview}
    \begin{block}{Key Takeaways from the Week}
        This week we explored foundational concepts in Deep Learning and Neural Networks:
    \end{block}
    \begin{itemize}
        \item Understanding the structure and function of Neural Networks
        \item Types of Neural Networks:
          \begin{itemize}
              \item Feedforward Neural Networks
              \item Convolutional Neural Networks (CNNs)
              \item Recurrent Neural Networks (RNNs)
          \end{itemize}
        \item The training process and its importance
        \item Challenges of Overfitting and Regularization techniques
        \item Application areas transforming various fields
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Future Directions - Deep Learning Concepts}
    \begin{block}{Training Neural Networks}
        The training process adjusts weight values using...
        \begin{equation}
            w = w - \eta \nabla L(w)
        \end{equation}
        where:
        \begin{itemize}
            \item \( w \) = weights
            \item \( \eta \) = learning rate
            \item \( L \) = loss function
        \end{itemize}
    \end{block}
    
    \begin{block}{Future Directions in Deep Learning}
        Advanced topics to consider:
    \end{block}
    \begin{itemize}
        \item Transformers and Attention Mechanisms
        \item Generative Models (GANs and VAEs)
        \item Ethics and Fairness in AI
        \item Neurosymbolic AI
        \item Continual Learning methods
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion and Future Directions - Final Thoughts}
    As we conclude, review these aspects:
    \begin{itemize}
        \item The basics of deep learning provide a solid foundation for advanced topics
        \item Rapid evolution of the field necessitates ongoing learning
        \item Ethical considerations and applications are crucial for responsible development
    \end{itemize}
    \begin{block}{Reminder}
        Always link your learning to ethical practices and real-world applications as you explore deeper concepts!
    \end{block}
\end{frame}


\end{document}