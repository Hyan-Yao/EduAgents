\documentclass[aspectratio=169]{beamer}

% Theme and Color Setup
\usetheme{Madrid}
\usecolortheme{whale}
\useinnertheme{rectangles}
\useoutertheme{miniframes}

% Additional Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}
\usepackage{hyperref}

% Custom Colors
\definecolor{myblue}{RGB}{31, 73, 125}
\definecolor{mygray}{RGB}{100, 100, 100}
\definecolor{mygreen}{RGB}{0, 128, 0}
\definecolor{myorange}{RGB}{230, 126, 34}
\definecolor{mycodebackground}{RGB}{245, 245, 245}

% Set Theme Colors
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=white, bg=myblue}
\setbeamercolor{title}{fg=myblue}
\setbeamercolor{section in toc}{fg=myblue}
\setbeamercolor{item projected}{fg=white, bg=myblue}
\setbeamercolor{block title}{bg=myblue!20, fg=myblue}
\setbeamercolor{block body}{bg=myblue!10}
\setbeamercolor{alerted text}{fg=myorange}

% Set Fonts
\setbeamerfont{title}{size=\Large, series=\bfseries}
\setbeamerfont{frametitle}{size=\large, series=\bfseries}
\setbeamerfont{caption}{size=\small}
\setbeamerfont{footnote}{size=\tiny}

% Code Listing Style
\lstdefinestyle{customcode}{
  backgroundcolor=\color{mycodebackground},
  basicstyle=\footnotesize\ttfamily,
  breakatwhitespace=false,
  breaklines=true,
  commentstyle=\color{mygreen}\itshape,
  keywordstyle=\color{blue}\bfseries,
  stringstyle=\color{myorange},
  numbers=left,
  numbersep=8pt,
  numberstyle=\tiny\color{mygray},
  frame=single,
  framesep=5pt,
  rulecolor=\color{mygray},
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=2,
  captionpos=b
}
\lstset{style=customcode}

% Custom Commands
\newcommand{\hilight}[1]{\colorbox{myorange!30}{#1}}
\newcommand{\source}[1]{\vspace{0.2cm}\hfill{\tiny\textcolor{mygray}{Source: #1}}}
\newcommand{\concept}[1]{\textcolor{myblue}{\textbf{#1}}}
\newcommand{\separator}{\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}}

% Footer and Navigation Setup
\setbeamertemplate{footline}{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
    \usebeamerfont{author in head/foot}\insertshortauthor
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.5\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
    \usebeamerfont{title in head/foot}\insertshorttitle
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.2\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}%
    \usebeamerfont{date in head/foot}
    \insertframenumber{} / \inserttotalframenumber
  \end{beamercolorbox}}%
  \vskip0pt%
}

% Turn off navigation symbols
\setbeamertemplate{navigation symbols}{}

% Title Page Information
\title[Week 12: Neural Networks and Deep Learning]{Week 12: Neural Networks and Deep Learning}
\author[J. Smith]{John Smith, Ph.D.}
\institute[University Name]{
  Department of Computer Science\\
  University Name\\
  \vspace{0.3cm}
  Email: email@university.edu\\
  Website: www.university.edu
}
\date{\today}

% Document Start
\begin{document}

\frame{\titlepage}

\begin{frame}[fragile]
    \titlepage
\end{frame}

\begin{frame}[fragile]
    \frametitle{Introduction to Neural Networks and Deep Learning}
    \begin{block}{Overview}
        In this chapter, we will explore foundational concepts of Neural Networks (NNs) and delve into the advanced realm of Deep Learning (DL). This overview serves as a stepping stone into understanding how these technologies transform data into intelligent systems.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{1. What are Neural Networks?}
    \begin{itemize}
        \item \textbf{Definition:} Neural Networks are computational models inspired by the human brain's network of neurons, consisting of interconnected layers of nodes (neurons).
        \item \textbf{Structure:}
        \begin{itemize}
            \item \textbf{Input Layer:} Receives initial data.
            \item \textbf{Hidden Layers:} Intermediate layers where computations occur.
            \item \textbf{Output Layer:} Produces final output or prediction.
        \end{itemize}
    \end{itemize}
    \textbf{Example:} A simple neural network for classifying images:
    \begin{itemize}
        \item \textbf{Input Layer:} Pixels of the image.
        \item \textbf{Hidden Layer:} Detects features like edges or shapes.
        \item \textbf{Output Layer:} Classifies the image as "cat," "dog," etc.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{2. Deep Learning - An Evolution of Neural Networks}
    \begin{itemize}
        \item \textbf{Definition:} Deep Learning is a subset of machine learning that uses multi-layered neural networks, enabling the processing of vast amounts of data.
        \item \textbf{Difference from Traditional NNs:}
        \begin{itemize}
            \item \textbf{Depth:} Deep Learning models can have hundreds or thousands of layers for complex feature extraction.
            \item \textbf{Training Data:} They excel with large datasets, learning directly from data without the need for feature engineering.
        \end{itemize}
    \end{itemize}
    \textbf{Illustration:}
    \begin{itemize}
        \item \textbf{Shallow Network:} 1 hidden layer for simple tasks.
        \item \textbf{Deep Network:} 5+ hidden layers for complex tasks like language translation or facial recognition.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{3. Key Applications of Neural Networks and Deep Learning}
    \begin{itemize}
        \item \textbf{Computer Vision:} Image classification, object detection, image generation.
        \item \textbf{Natural Language Processing:} Sentiment analysis, language translation, chatbots.
        \item \textbf{Healthcare:} Disease diagnosis from medical images, predictive analytics.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{4. Emphasizing Key Concepts}
    \begin{itemize}
        \item \textbf{Learning Process:} Neural networks learn through backpropagation, minimizing error by adjusting weights based on the loss function.
        \item \textbf{Activation Functions:} Functions like ReLU (Rectified Linear Unit) and Sigmoid introduce non-linearity, enabling the network to learn complex patterns.
    \end{itemize}
    \textbf{Formula for Loss Calculation:}
    \begin{equation}
        L(y, \hat{y}) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i)]
    \end{equation}
\end{frame}

\begin{frame}[fragile]
    \frametitle{5. Closing Thoughts}
    As we navigate this chapter, we will review essential techniques, architectures, and challenges in training deep learning models. 
    By the end, you will grasp the significance of deep learning in modern AI applications, preparing you for advanced studies in neural networks.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Engagement Prompt}
    Reflect on how neural network architectures can be adapted for different applications. Consider: 
    \begin{itemize}
        \item What features might you prioritize in a network designed for healthcare versus one for image classification?
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{History of Neural Networks - Introduction}
    \begin{block}{Overview}
        Neural networks have a rich history that traces back to the early days of artificial intelligence. Over the decades, significant milestones have contributed to the sophisticated deep learning techniques we utilize today. This timeline outlines key developments in the history of neural networks.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{History of Neural Networks - Key Milestones}
    \begin{enumerate}
        \item \textbf{1943: The Perceptron Model}
            \begin{itemize}
                \item \textbf{Concept:} Warren McCulloch and Walter Pitts introduced a computational model that mimicked neural activity.
                \item \textbf{Significance:} First mathematical representation of a neuron.
            \end{itemize}
        
        \item \textbf{1950s: The First Neural Networks}
            \begin{itemize}
                \item \textbf{Key Figure:} Frank Rosenblatt's Perceptron (1958).
                \item \textbf{Example:} A single-layer neural network for binary classification.
                \item \textbf{Limitation:} Could not solve non-linearly separable problems (e.g., XOR).
            \end{itemize}

        \item \textbf{1969: The Limitations of Perceptrons}
            \begin{itemize}
                \item \textbf{Key Publication:} "Perception: A Psychological Approach" by Marvin Minsky and Seymour Papert.
                \item \textbf{Impact:} Highlighted limitations of single-layer networks.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{History of Neural Networks - Continued}
    \begin{enumerate}
        \setcounter{enumi}{3}
        \item \textbf{1980s: Revival with Backpropagation}
            \begin{itemize}
                \item \textbf{Breakthrough:} Development of backpropagation by Geoffrey Hinton.
                \item \textbf{Importance:} Enabled training of multi-layer networks.
            \end{itemize}

        \item \textbf{1990s: Emergence of Various Architectures}
            \begin{itemize}
                \item \textbf{Advancements:} Introduction of RNNs and CNNs.
                \item \textbf{Example:} CNNs revolutionized image processing (Yann LeCun).
            \end{itemize}

        \item \textbf{2006: The Deep Learning Revolution}
            \begin{itemize}
                \item \textbf{Key Event:} Geoffrey Hinton's auto-encoder paper.
                \item \textbf{Significance:} Renewed interest in deep architectures for feature learning.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{History of Neural Networks - Recent Developments}
    \begin{enumerate}
        \setcounter{enumi}{6}
        \item \textbf{2010s: Breakthroughs in Performance}
            \begin{itemize}
                \item \textbf{Key Achievements:} AlexNet (2012) and the ImageNet challenge.
                \item \textbf{Further Developments:} Techniques like dropout and transfer learning.
            \end{itemize}

        \item \textbf{Present Day: Advanced Applications}
            \begin{itemize}
                \item \textbf{Current Trends:} Use of neural networks in NLP, autonomous systems, GANs, transformers (e.g., BERT, GPT).
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Takeaways and Additional Notes}
    \begin{itemize}
        \item Neural networks evolved from simple perceptrons to complex architectures.
        \item Understanding the historical context enhances appreciation of modern deep learning technologies.
    \end{itemize}
    
    \begin{block}{Additional Notes}
        \begin{itemize}
            \item Consider including a timeline diagram for visual context.
            \item Basic perceptron model output:
            \begin{equation}
            y = f\left(\sum_{i=1}^{n} w_i x_i + b\right)
            \end{equation}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{What are Neural Networks? - Definition}
    \begin{block}{Definition of Neural Networks}
        Neural networks are computational models inspired by the human brain, designed to recognize patterns in data. 
        They consist of interconnected groups of artificial neurons (also called nodes) and are used in various applications, such as:
        \begin{itemize}
            \item Image recognition
            \item Speech processing
            \item Natural language understanding
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{What are Neural Networks? - Structure}
    \begin{block}{Structure of Neural Networks}
        A neural network typically incorporates layers of neurons:
        \begin{enumerate}
            \item \textbf{Input Layer:}
                \begin{itemize}
                    \item Receives the initial data inputs.
                    \item Each neuron corresponds to a feature of the input data.
                    \item \textit{Example:} In an image classification task, individual pixels serve as inputs.
                \end{itemize}
                
            \item \textbf{Hidden Layers:}
                \begin{itemize}
                    \item Perform computations through various transformations, can be one or more layers.
                    \item Introduce non-linearities through activation functions.
                \end{itemize}
                
            \item \textbf{Output Layer:}
                \begin{itemize}
                    \item Produces the network's output, representing predictions or classifications.
                    \item \textit{Example:} For a binary classification task (e.g., spam detection), may consist of a single neuron generating a probability.
                \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{What are Neural Networks? - Neurons and Activation Functions}
    \begin{block}{Neurons and Activation Function}
        Each neuron has a simple structure with:
        \begin{itemize}
            \item \textbf{Weights and Biases:} Parameters adjusted during training to minimize prediction errors.
            \item \textbf{Activation Function:} A mathematical function that determines the neuron output, introducing non-linearity.
                \begin{itemize}
                    \item Common activation functions include:
                        \begin{itemize}
                            \item Sigmoid: $f(x) = \frac{1}{1 + e^{-x}}$
                            \item ReLU (Rectified Linear Unit): $f(x) = \max(0, x)$
                        \end{itemize}
                \end{itemize}
        \end{itemize}
        
        \begin{block}{Formula for Neuron Output}
            For a single neuron, the output \( y \) is expressed as:
            \[
            y = f\left(\sum_{i=1}^{n} w_i \cdot x_i + b\right)
            \]
            Where:
            \begin{itemize}
                \item \( w_i \) = weight of the \( i^{th} \) input
                \item \( x_i \) = \( i^{th} \) input
                \item \( b \) = bias
                \item \( f \) = activation function
            \end{itemize}
        \end{block}
    \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Understanding Deep Learning - Overview}
  \begin{block}{What is Deep Learning?}
    Deep learning is a subset of machine learning, inspired by the structure and function of the human brain. It employs artificial neural networks with many layers—hence "deep"—to learn complex representations of data.
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Understanding Deep Learning - Key Differences}
  \begin{itemize}
    \item \textbf{Neural Networks}: 
    \begin{itemize}
      \item Typically consist of an input layer, one or two hidden layers, and an output layer.
      \item Effective for simpler tasks but can struggle with complex patterns.
    \end{itemize}
    
    \item \textbf{Deep Learning}:
    \begin{itemize}
      \item Uses deep neural networks (DNNs) with multiple hidden layers (often dozens or hundreds).
      \item These layers automatically learn hierarchical features, extracting intricate patterns from raw data like images, sound, and text.
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Understanding Deep Learning - Applications and Key Points}
  \begin{block}{Why Use Deep Learning?}
    \begin{enumerate}
      \item \textbf{Feature Learning}: Automates feature discovery, unlike traditional machine learning where features must be manually engineered.
      \item \textbf{Handling Unstructured Data}: Excels at processing unstructured data such as images, audio, and text.
    \end{enumerate}
  \end{block}

  \begin{block}{Examples of Deep Learning Applications}
    \begin{itemize}
      \item \textbf{Image Recognition}: Convolutional Neural Networks (CNNs) accurately identify objects.
      \item \textbf{Natural Language Processing (NLP)}: RNNs and Transformers understand and generate human language.
      \item \textbf{Speech Recognition}: Used in systems like Siri or Google Assistant to process spoken language.
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Deep Learning Architectures - Overview}
    Deep learning architectures are structured designs of neural networks that enable computers to recognize patterns and learn from large amounts of data.
    
    \begin{itemize}
        \item Three primary types of architectures:
        \item Feedforward Networks
        \item Convolutional Networks
        \item Recurrent Networks
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Deep Learning Architectures - Feedforward Neural Networks}
    
    \begin{block}{Description}
        • The simplest type of artificial neural network. \\
        • Information moves in one direction: 
        from input nodes, through hidden nodes (if any), to output nodes. \\
        • No cycles or loops; data flows straight from input to output.
    \end{block}
    
    \begin{block}{Key Features}
        \begin{itemize}
            \item Composed of layers: Input Layer, Hidden Layer(s), Output Layer.
            \item Each neuron in one layer connects to every neuron in the next layer.
        \end{itemize}
    \end{block}
    
    \begin{block}{Example}
        Used for basic classification tasks, like recognizing handwritten digits.
    \end{block}
    
    \begin{equation}
        y = f(wx + b)
    \end{equation}
    where: \\
    \( y \) = output, \( f \) = activation function (e.g., sigmoid, ReLU), \\ 
    \( w \) = weights, \( x \) = input, \( b \) = bias term.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Deep Learning Architectures - Convolutional Neural Networks}
    
    \begin{block}{Description}
        • Designed to process data with grid-like topology, particularly images. \\
        • Utilizes convolutional layers that apply filters (kernels) to input data.
    \end{block}
    
    \begin{block}{Key Features}
        \begin{itemize}
            \item \textbf{Convolutional Layer:} Extracts features from the input using filters.
            \item \textbf{Pooling Layer:} Reduces the dimensionality of feature maps.
            \item Typically used in image and video recognition tasks.
        \end{itemize}
    \end{block}
    
    \begin{block}{Example}
        Identifying objects in images (e.g., detecting faces in photos).
    \end{block}
    
    \begin{block}{Diagram Overview}
        Input Image $\rightarrow$ Convolutional Layer $\rightarrow$ Activation Function $\rightarrow$ Pooling Layer $\rightarrow$ Fully Connected Layer $\rightarrow$ Output Class
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Deep Learning Architectures - Recurrent Neural Networks}
    
    \begin{block}{Description}
        • Specialized for sequential data where the order is important (e.g., time series, natural language). \\
        • Allows information to persist, using feedback loops.
    \end{block}
    
    \begin{block}{Key Features}
        \begin{itemize}
            \item Each neuron can take inputs from the previous layer and its own output from the previous time step.
            \item Capable of learning temporal dependencies (e.g., predicting the next word in a sentence).
        \end{itemize}
    \end{block}
    
    \begin{block}{Example}
        Used in language modeling and text generation.
    \end{block}
    
    \begin{equation}
        h_t = f(W_h h_{t-1} + W_x x_t + b)
    \end{equation}
    where: \\
    \( h_t \) = hidden state at time \( t \), \( x_t \) = input at time \( t \), \\ 
    \( W_h, W_x \) = weight matrices, \( b \) = bias.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Deep Learning Architectures - Key Points and Conclusion}
    
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item \textbf{Feedforward Networks:} Great for static data and classification tasks.
            \item \textbf{Convolutional Networks:} Essential for image and spatial data processing.
            \item \textbf{Recurrent Networks:} Ideal for sequential data, capturing dependencies over time.
        \end{itemize}
    \end{block}
    
    \begin{block}{Conclusion}
        Understanding these architectures equips you to choose the right model for specific tasks in deep learning. 
        In the next slide, we will delve deeper into Convolutional Neural Networks and their applications in image processing.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Convolutional Neural Networks (CNNs) - Overview}
    \begin{block}{Definition}
        Convolutional Neural Networks (CNNs) are a specialized type of deep learning model primarily used for analyzing visual data. They mimic the human brain's ability to recognize patterns, making them ideal for tasks such as:
    \end{block}
    \begin{itemize}
        \item Image recognition
        \item Classification
        \item Video analysis
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{CNN Architecture}
    \begin{enumerate}
        \item \textbf{Input Layer}:
        \begin{itemize}
            \item Represents the input image (e.g., RGB channels)
        \end{itemize}
        
        \item \textbf{Convolutional Layers}:
        \begin{itemize}
            \item Apply filters to learn spatial hierarchies
            \item Formula:
            \begin{equation}
                S(i, j) = (I * K)(i, j) = \sum_m \sum_n I(m, n) \cdot K(i-m, j-n)
            \end{equation}
            \item Stride and Padding ensure output dimensions
        \end{itemize}
        
        \item \textbf{Activation Function}:
        \begin{itemize}
            \item Typically uses ReLU: 
            \begin{equation}
                f(x) = \max(0, x)
            \end{equation}
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{CNN Architecture (Continued)}
    \begin{enumerate}[resume]
        \item \textbf{Pooling Layers}:
        \begin{itemize}
            \item Max Pooling: Retains crucial features
            \item Average Pooling: Computes average in the pooling window
        \end{itemize}
        
        \item \textbf{Fully Connected Layers}:
        \begin{itemize}
            \item Perform high-level reasoning based on extracted features
        \end{itemize}
        
        \item \textbf{Output Layer}:
        \begin{itemize}
            \item Provides final classification or prediction
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Characteristics of CNNs}
    \begin{itemize}
        \item \textbf{Local Connectivity}: Each neuron connects only to a local region
        \item \textbf{Parameter Sharing}: Features are invariant to spatial translation
        \item \textbf{Hierarchical Feature Learning}: Layers capture simple to complex features
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Example: Image Classification}
    \begin{itemize}
        \item Classifying images of cats and dogs:
        \begin{enumerate}
            \item First layers learn edges
            \item Intermediate layers detect shapes (e.g., ears, paws)
            \item Higher layers differentiate between classes
        \end{enumerate}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Summary of Key Points}
    \begin{itemize}
        \item CNNs are critical for image processing due to automatic learning of spatial hierarchies
        \item Architecture consists of convolutional, pooling, and fully connected layers
        \item Excellent at recognizing patterns in visual inputs, with wide applications in various fields
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Real-World Relevance}
    As we transition to applications of CNNs, think about how these capabilities apply in:
    \begin{itemize}
        \item Medical imaging
        \item Autonomous vehicles
        \item Cloud-based image recognition services
    \end{itemize}
    CNNs have revolutionized the interpretation of visual data, establishing them as a cornerstone of modern AI applications.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of CNNs - Introduction}
    \begin{block}{Overview}
        Convolutional Neural Networks (CNNs) have revolutionized various fields by enabling machines to process visual data with remarkable accuracy. 
    \end{block}
    \begin{itemize}
        \item Key applications include:
            \begin{itemize}
                \item Computer Vision
                \item Medical Imaging
                \item Autonomous Vehicles
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of CNNs - Computer Vision}
    \begin{block}{Description}
        CNNs are essential for analyzing visual data, proficient in tasks such as:
    \end{block}
    \begin{itemize}
        \item **Image Classification**: Categorizing images (e.g., distinguishing between cats and dogs).
        \item **Object Detection**: Tools like YOLO detect objects in real-time, identifying and localizing them.
        \item **Image Segmentation**: Techniques like U-Net help to identify relevant structures in medical images.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of CNNs - Medical Imaging and Autonomous Vehicles}
    \begin{block}{Medical Imaging}
        CNNs assist in diagnosing and analyzing medical images, improving accuracy and reducing manual workload.
    \end{block}
    \begin{itemize}
        \item **Tumor Detection**: Identifying cancerous cells in radiology images.
        \item **Disease Classification**: Classifying stages of diseases like diabetic retinopathy.
        \item **3D Reconstruction**: Facilitating reconstruction of 3D models from 2D slices.
    \end{itemize}
    
    \begin{block}{Autonomous Vehicles}
        CNNs are crucial for enabling vehicles to perceive their surroundings and make real-time decisions.
    \end{block}
    \begin{itemize}
        \item **Obstacle Detection**: Processing camera feeds to detect pedestrians and road signs.
        \item **Lane Detection**: Analyzing road images to recognize lane markings.
        \item **Traffic Sign Recognition**: Identifying traffic signs for safe driving.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Code Snippet}
    \begin{block}{Key Points}
        \begin{itemize}
            \item **Robustness**: CNNs handle variations in images effectively.
            \item **Real-time Processing**: Optimized for time-sensitive applications like autonomous driving.
            \item **Transfer Learning**: Pre-trained models can be fine-tuned to save time and resources.
        \end{itemize}
    \end{block}
    
    \begin{block}{Code Snippet}
        \begin{lstlisting}[language=Python]
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))  # Convolutional Layer
model.add(MaxPooling2D(pool_size=(2, 2)))  # Pooling Layer
model.add(Flatten())  # Flattening
model.add(Dense(units=128, activation='relu'))  # Fully Connected Layer
model.add(Dense(units=10, activation='softmax'))  # Output Layer for 10 classes

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
        \end{lstlisting}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of CNNs - Conclusion}
    \begin{block}{Conclusion}
        CNNs continuously reshape the landscape of technology across diverse sectors. 
        Their capability to learn hierarchical features from raw visual data enables breakthroughs in areas impacting both everyday lives and industries.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Training Neural Networks - Overview}
    \begin{block}{Overview of Neural Network Training}
        Training a neural network involves adjusting its parameters (weights and biases) to minimize the difference between the predicted outputs and the actual target values. This process ensures that the network learns to recognize patterns in data.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Training Neural Networks - Key Concepts}
    \begin{enumerate}
        \item \textbf{Backpropagation}
            \begin{itemize}
                \item \textbf{Definition}: Supervised learning algorithm for training neural networks, calculating error and feeding it back to adjust weights.
                \item \textbf{How it Works}:
                    \begin{itemize}
                        \item \textit{Forward Pass}: Input data produces an output.
                        \item \textit{Error Calculation}: Loss is calculated using a loss function:
                          \[
                          \text{Loss} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2
                          \]
                        \item \textit{Backward Pass}: Gradient of the loss function is computed to adjust weights.
                    \end{itemize}
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Training Neural Networks - Optimization and Loss Functions}
    \begin{enumerate}
        \setcounter{enumi}{1}
        \item \textbf{Optimization Techniques}
            \begin{itemize}
                \item \textbf{Purpose}: Update model parameters to minimize the loss function.
                \item \textbf{Common Methods}:
                    \begin{itemize}
                        \item \textit{Gradient Descent}:
                          \[
                          w := w - \eta \nabla L
                          \]
                        \item \textit{Stochastic Gradient Descent (SGD)}: Updates with randomly selected subsets of data.
                        \item \textit{Momentum}: Improves convergence by incorporating past updates.
                    \end{itemize}
            \end{itemize}
        \item \textbf{Loss Functions}
            \begin{itemize}
                \item \textbf{Importance}: Quantifies how well predictions match actual labels.
                \item \textbf{Common Loss Functions}:
                    \begin{itemize}
                        \item \textit{Mean Squared Error (MSE)}: For regression tasks.
                        \item \textit{Cross-Entropy Loss}:
                          \[
                          L = -\sum_{i=1}^{C} y_i \log(\hat{y_i})
                          \]
                    \end{itemize}
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Example Code}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item Training is iterative, involving multiple passes through data (epochs).
            \item Proper learning rate selection is crucial for convergence.
            \item Selecting the appropriate loss function is critical based on the task.
        \end{itemize}
    \end{block}
    
    \begin{block}{Example Code Snippet (Python with TensorFlow)}
    \begin{lstlisting}[language=Python]
import tensorflow as tf

# Define model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile model with the optimizer and loss function
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Fit model to the training data
model.fit(X_train, y_train, epochs=10, batch_size=32)
    \end{lstlisting}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Common Optimization Algorithms}
    \begin{block}{Overview of Optimization Algorithms}
        Optimization algorithms are essential for training neural networks as they determine how the weights of the model are updated to minimize the loss function. This update is crucial in making the model learn from the training data. Below, we discuss three popular optimization algorithms: 
        \begin{itemize}
            \item Stochastic Gradient Descent (SGD)
            \item Adam
            \item RMSprop
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{1. Stochastic Gradient Descent (SGD)}
    \begin{block}{Concept}
        SGD is a variation of gradient descent that updates the model's weights using only a single (or a few) training example(s) at a time, rather than the entire dataset. This leads to faster updates and can help escape local minima.
    \end{block}
    
    \begin{block}{Formula}
        \begin{equation}
            w_{t+1} = w_t - \eta \nabla L(w_t)
        \end{equation}
        Where:
        \begin{itemize}
            \item \(w_t\) = current weights
            \item \(\eta\) = learning rate
            \item \(\nabla L(w_t)\) = gradient of the loss function
        \end{itemize}
    \end{block}
    
    \begin{block}{Key Points}
        \begin{itemize}
            \item \textbf{Pros:} Faster convergence on large datasets, helps navigate challenging loss landscapes.
            \item \textbf{Cons:} High variance in updates can lead to oscillations; may require tuning.
        \end{itemize}
    \end{block}
    
    \begin{block}{Example}
        If you have a dataset with 10,000 examples, use one example at a time for gradient computation instead of the whole dataset.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{2. Adam (Adaptive Moment Estimation)}
    \begin{block}{Concept}
        Adam combines the advantages of AdaGrad and RMSprop, computing adaptive learning rates from estimates of first and second moments of the gradients.
    \end{block}
    
    \begin{block}{Formulas}
        \begin{equation}
            m_t = \beta_1 m_{t-1} + (1 - \beta_1)\nabla L(w_t)
        \end{equation}
        \begin{equation}
            v_t = \beta_2 v_{t-1} + (1 - \beta_2)(\nabla L(w_t))^2
        \end{equation}
        \begin{equation}
            \hat{m}_t = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1 - \beta_2^t}
        \end{equation}
        \begin{equation}
            w_{t+1} = w_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t
        \end{equation}
        Where:
        \begin{itemize}
            \item \(\beta_1, \beta_2\) = decay rates (commonly 0.9 and 0.999)
            \item \(\epsilon\) = small constant to prevent division by zero.
        \end{itemize}
    \end{block}
    
    \begin{block}{Key Points}
        \begin{itemize}
            \item \textbf{Pros:} Efficient for large datasets; adapts learning rates for parameters.
            \item \textbf{Cons:} Can lead to overfitting due to high performance with noisy data.
        \end{itemize}
    \end{block}
    
    \begin{block}{Example}
        Adam dynamically adjusts the learning rate based on past gradients for each weight, enabling fine-tuned updates during training.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{3. RMSprop (Root Mean Square Propagation)}
    \begin{block}{Concept}
        RMSprop addresses AdaGrad's diminishing learning rates by introducing a decay term to the average of squared gradients, allowing for more stable updates.
    \end{block}

    \begin{block}{Formulas}
        \begin{equation}
            v_t = \beta v_{t-1} + (1 - \beta)(\nabla L(w_t))^2
        \end{equation}
        \begin{equation}
            w_{t+1} = w_t - \frac{\eta}{\sqrt{v_t} + \epsilon} \nabla L(w_t)
        \end{equation}
        Where:
        \begin{itemize}
            \item \(v_t\) = average of squared gradients
            \item \(\beta\) = decay rate (typically around 0.9)
        \end{itemize}
    \end{block}

    \begin{block}{Key Points}
        \begin{itemize}
            \item \textbf{Pros:} Handles non-stationary objectives; allows adaptive learning rates per parameter.
            \item \textbf{Cons:} Requires hyperparameter tuning for optimal performance.
        \end{itemize}
    \end{block}

    \begin{block}{Example}
        RMSprop adjusts the step size dynamically in minimizing the cost function based on the history of squared gradients.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion}
    Choosing the right optimization algorithm can significantly impact the efficiency and success of training neural networks. Understanding their strengths and weaknesses allows for better tuning of deep learning models. Experimentation and experience with datasets will help determine which algorithm works best in specific scenarios.

    This overview provides foundational knowledge about popular optimization algorithms that enhance the learning process of neural networks.
\end{frame}

\begin{frame}[fragile]
  \frametitle{Challenges in Deep Learning - Introduction}
  Deep learning has revolutionized fields such as computer vision and natural language processing. However, training deep neural networks effectively presents several challenges:
  \begin{itemize}
      \item Understanding challenges is crucial for building robust models.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Challenges in Deep Learning - Overfitting and Underfitting}
  \begin{block}{1. Overfitting}
      \begin{itemize}
          \item \textbf{Definition}: Learning noise instead of patterns; leads to high training accuracy but poor generalization.
          \item \textbf{Causes}: 
          \begin{itemize}
              \item Complex models with too many parameters
              \item Insufficient training data
          \end{itemize}
          \item \textbf{Mitigation Strategies}:
          \begin{itemize}
              \item Regularization Techniques: Dropout, L1/L2 regularization
              \item More Data: Data augmentation or acquiring more labeled data
          \end{itemize}
      \end{itemize}
  \end{block}

  \begin{block}{2. Underfitting}
      \begin{itemize}
          \item \textbf{Definition}: Model too simple to capture trends; poor performance on both training and test datasets.
          \item \textbf{Causes}: 
          \begin{itemize}
              \item Inadequate model capacity
              \item Too strong regularization
          \end{itemize}
          \item \textbf{Mitigation Strategies}:
          \begin{itemize}
              \item Increasing model complexity
              \item Reducing the amount of regularization
          \end{itemize}
      \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Challenges in Deep Learning - Vanishing Gradients}
  \begin{block}{3. Vanishing Gradients}
      \begin{itemize}
          \item \textbf{Definition}: Gradients become exceedingly small during backpropagation; earlier layers learn slowly.
          \item \textbf{Causes}: Activation functions like Sigmoid or Tanh can squash inputs, causing gradients to vanish.
          \item \textbf{Mitigation Strategies}:
          \begin{itemize}
              \item Use alternative activation functions: ReLU, Leaky ReLU
              \item Implement normalization techniques: Batch normalization
          \end{itemize}
      \end{itemize}
  \end{block}

  \begin{block}{Key Points to Emphasize}
      \begin{itemize}
          \item Understand the trade-off: Balancing model complexity is essential.
          \item Monitor performance metrics: Validate using rigorous methods.
          \item Experimentation is key: Resolving challenges requires iterative experimentation.
      \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Regularization Techniques}
    \begin{block}{Understanding Overfitting}
        \begin{itemize}
            \item **Overfitting** happens when a model learns noise in the training data instead of the underlying patterns.
            \item Results in high performance on training data but poor generalization to new, unseen data.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Regularization Techniques}
    Regularization techniques are essential tools to combat overfitting. Here are two prominent methods:
    \begin{itemize}
        \item **Dropout**
        \item **Weight Regularization**
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{1. Dropout}
    \begin{block}{Concept}
        Dropout is a method that randomly sets a fraction of neurons to zero during training, preventing reliance on any single node.
    \end{block}
    
    \begin{block}{How it Works}
        During training, a percentage (e.g., 20\% for a dropout rate of 0.2) of neurons are randomly selected to be ignored.
    \end{block}

    \begin{block}{Benefits}
        \begin{itemize}
            \item Reduces overfitting by ensuring neurons cannot co-adapt too much.
        \end{itemize}
    \end{block}
    
    \begin{lstlisting}[language=Python]
from keras.models import Sequential
from keras.layers import Dense, Dropout

model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(input_dim,)))
model.add(Dropout(0.5))  # 50% dropout
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))  # 50% dropout
model.add(Dense(output_dim, activation='softmax'))
    \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
    \frametitle{2. Weight Regularization}
    \begin{block}{Concept}
        Weight regularization adds a penalty to the loss function based on weight magnitudes to discourage complex models.
    \end{block}
    
    \begin{block}{Types}
        \begin{itemize}
            \item **L1 Regularization (Lasso):** 
                \[
                L = L_{data} + \lambda \sum |w_i|
                \]
            \item **L2 Regularization (Ridge):**
                \[
                L = L_{data} + \lambda \sum w_i^2
                \]
        \end{itemize}
    \end{block}

    \begin{block}{Benefits}
        \begin{itemize}
            \item Prevents large weights, reducing overfitting.
            \item Encourages simpler models (especially L1).
        \end{itemize}
    \end{block}
    
    \begin{lstlisting}[language=Python]
from keras.regularizers import l2

model = Sequential()
model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01), input_shape=(input_dim,)))
model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))
model.add(Dense(output_dim, activation='softmax'))
    \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points to Emphasize}
    \begin{itemize}
        \item Regularization improves generalization in neural networks.
        \item Dropout aids in reducing reliance on specific nodes.
        \item L1 and L2 regularization penalize large weights for model simplicity.
        \item Choose techniques based on specific use cases and model requirements.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future of Neural Networks - Introduction}
    \begin{block}{Overview}
        Neural networks have transformed the landscape of machine learning and AI. As technology evolves, so do the methodologies and applications of neural networks.
    \end{block}
    \begin{block}{Objective}
        This talk explores emerging trends and future directions in neural network research and applications.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Directions - Key Trends}
    \begin{enumerate}
        \item \textbf{Explainable AI (XAI)}
        \begin{itemize}
            \item \textit{Demand for transparency} in AI decisions.
            \item Enhances trust in systems like healthcare and finance.
            \item \textit{Example}: LIME (Local Interpretable Model-agnostic Explanations).
        \end{itemize}

        \item \textbf{Neural Architecture Search (NAS)}
        \begin{itemize}
            \item \textit{Automated model optimization} methods.
            \item Uses reinforcement learning and evolutionary algorithms.
            \item \textit{Example}: Google’s AutoML.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Directions - More Key Trends}
    \begin{enumerate}
        \setcounter{enumi}{2}
        \item \textbf{Federated Learning}
        \begin{itemize}
            \item \textit{Decentralized training} of models.
            \item Addresses privacy by keeping data local.
            \item \textit{Example}: Predictive text in mobile applications.
        \end{itemize}

        \item \textbf{Integration with Quantum Computing}
        \begin{itemize}
            \item Leverages quantum mechanics for faster processing.
            \item Potential for exponential increases in training speed.
            \item Research ongoing in quantum properties like superposition.
        \end{itemize}

        \item \textbf{Continual and Lifelong Learning}
        \begin{itemize}
            \item Models adapt continuously without forgetting.
            \item Important for evolving AI systems with real-time learning.
            \item \textit{Example}: Real-time learning from medical cases.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Summary and Conclusion}
    \begin{block}{Key Points}
        \begin{itemize}
            \item Shift towards understanding AI decisions (XAI).
            \item Automation in model architecture (NAS).
            \item Enhanced data security through federated learning.
            \item Novel approaches with quantum computing.
            \item Ability to learn continuously (Lifelong Learning).
        \end{itemize}
    \end{block}
    \begin{block}{Conclusion}
        The future of neural networks is promising with ongoing research aimed at overcoming limitations and enabling innovative applications. These trends will significantly impact our interaction with technology and AI.
    \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Ethical Considerations - Overview}
  As deep learning technologies become increasingly integrated into various applications, such as facial recognition and financial assessments, it is essential to consider their ethical implications. Two major concerns arise: 
  \begin{itemize}
      \item \textbf{Bias}
      \item \textbf{Data Privacy}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Ethical Considerations - Bias in Deep Learning Models}
  \begin{block}{Definition}
      Bias in machine learning refers to outcomes produced by models that are systematically prejudiced due to improper data representation or algorithm assumptions.
  \end{block}

  \begin{itemize}
      \item \textbf{Examples of Bias:}
      \begin{itemize}
          \item \textbf{Facial Recognition:} Higher error rates for underrepresented groups.
          \item \textbf{Hiring Algorithms:} AI tools favoring candidates from specific demographics, leading to discrimination.
      \end{itemize}
      
      \item \textbf{Key Points:}
      \begin{itemize}
          \item Source of Bias: Often rooted in biased training data.
          \item Consequences: Perpetuation of inequality and unjust treatment of marginalized groups.
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Ethical Considerations - Data Privacy Concerns}
  \begin{block}{Definition}
      Data privacy refers to the ethical and legal obligations to maintain the confidentiality of personal information used in training AI systems.
  \end{block}

  \begin{itemize}
      \item \textbf{Examples of Data Privacy Issues:}
      \begin{itemize}
          \item \textbf{User Consent:} Collection of personal data without explicit user consent.
          \item \textbf{Data Breaches:} High-profile incidents exposing sensitive information.
      \end{itemize}
      
      \item \textbf{Key Points:}
      \begin{itemize}
          \item Regulatory Standards: Compliance with regulations like GDPR is essential.
          \item Transparency and Accountability: Organizations must disclose how data is collected and used.
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Ethical Considerations - Navigating Challenges}
  To address ethical concerns in deep learning, developers and organizations should:
  \begin{itemize}
      \item Conduct Bias Audits: Regularly assess models for bias and take corrective actions.
      \item Enhance Transparency: Provide clear documentation on data usage and model decision-making processes.
      \item Implement Privacy-First Practices: Use data anonymization, secure storage, and obtain informed consent.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Ethical Considerations - Conclusion}
  Integrating ethical considerations into the development and application of deep learning technologies is crucial for:
  \begin{itemize}
      \item Fostering fairness and protecting individual rights.
      \item Addressing bias and ensuring data privacy as key steps in building trustworthy AI systems.
  \end{itemize}
  \textbf{Remember:} Ethical AI improves model performance and enhances public trust and social responsibility.
\end{frame}

\begin{frame}[fragile]
  \frametitle{Ethical Considerations - Additional Resources}
  \begin{itemize}
      \item Articles on ethical AI practices.
      \item Case studies on bias and privacy issues in AI.
      \item Regulatory frameworks like GDPR for data privacy laws.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Capstone Project Overview - Introduction}
    \begin{block}{Introduction to the Capstone Project}
        The capstone project serves as the culmination of your learning journey in neural networks and deep learning. 
        It provides you hands-on experience in applying theoretical concepts to solve real-world problems through advanced machine learning techniques.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Capstone Project Overview - Objectives}
    \begin{block}{Objectives}
        \begin{enumerate}
            \item \textbf{Application of Neural Networks}
            \begin{itemize}
                \item Utilize different types of neural network architectures (e.g., CNNs, RNNs).
                \item Implement and train models using a chosen dataset to evaluate performance.
            \end{itemize}

            \item \textbf{Exploration of Deep Learning Techniques}
            \begin{itemize}
                \item Experiment with techniques like transfer learning and data augmentation.
                \item Analyze optimization algorithms and loss functions for best results.
            \end{itemize}

            \item \textbf{Data Processing and Ethical Considerations}
            \begin{itemize}
                \item Engage in data preprocessing steps and involve ethical reflections.
            \end{itemize}

            \item \textbf{Presentation of Findings}
            \begin{itemize}
                \item Prepare a comprehensive report and presentation to communicate findings.
            \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Capstone Project Overview - Key Points}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item \textbf{Hands-On Learning}: Emphasizes practical skills through real-world datasets.
            \item \textbf{Diverse Approaches}: Encourages exploration of model architectures and modifications.
            \item \textbf{Interdisciplinary Application}: Demonstrates the application of neural networks in fields like healthcare and finance.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Capstone Project Overview - Potential Project Ideas}
    \begin{block}{Potential Project Ideas}
        \begin{itemize}
            \item \textbf{Image Classification}: Model to classify images (e.g., cats vs. dogs) using CNNs.
            \item \textbf{Sentiment Analysis}: Develop an LSTM model to analyze review sentiments.
            \item \textbf{Time Series Forecasting}: Utilize RNNs to predict future values in datasets.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Capstone Project Overview - Code Snippet}
    \begin{block}{Code Snippet Example}
        Here’s a sample code snippet for setting up a simple neural network using Keras:
        \begin{lstlisting}[language=Python]
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout

# Initialize the model
model = Sequential()

# Add input layer
model.add(Dense(128, activation='relu', input_shape=(input_dim,)))
model.add(Dropout(0.5))

# Add hidden layers
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))

# Add output layer
model.add(Dense(num_classes, activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
        \end{lstlisting}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Capstone Project Overview - Conclusion}
    \begin{block}{Conclusion}
        The capstone project is an opportunity to apply learned skills and explore innovative solutions 
        while reflecting on ethical considerations and the societal impact of your work. 
        Through this project, you will refine your skills and potentially contribute valuable insights 
        to the field of artificial intelligence.
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{Practical Implementation of CNNs}
    \begin{block}{Summary}
        This presentation covers practical implementations of Convolutional Neural Networks (CNNs) using TensorFlow and PyTorch, including key case studies in image classification and object detection.
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{Introduction to Convolutional Neural Networks (CNNs)}
    \begin{itemize}
        \item CNNs are specialized neural networks designed for structured grid data such as images.
        \item They automatically learn spatial hierarchies of features.
        \item Applications include:
        \begin{itemize}
            \item Image classification
            \item Object detection
            \item Others
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Popular Frameworks for Implementing CNNs}
    \begin{enumerate}
        \item \textbf{TensorFlow}: 
        \begin{itemize}
            \item Open-source framework for building and deploying ML models.
        \end{itemize}
        \item \textbf{PyTorch}:
        \begin{itemize}
            \item Known for its ease of use and dynamic computation graph.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Case Study 1: Image Classification Using CNNs in TensorFlow}
    \begin{block}{Objective}
        Classify images from the CIFAR-10 dataset into 10 categories.
    \end{block}
    
    \textbf{Implementation Steps:}
    \begin{enumerate}
        \item \textbf{Load the Dataset}:
        \begin{lstlisting}[language=Python]
        from tensorflow.keras.datasets import cifar10
        (x_train, y_train), (x_test, y_test) = cifar10.load_data()
        \end{lstlisting}
        
        \item \textbf{Preprocessing}:
        \begin{lstlisting}[language=Python]
        x_train = x_train.astype('float32') / 255.0
        x_test = x_test.astype('float32') / 255.0
        from tensorflow.keras.utils import to_categorical
        y_train = to_categorical(y_train, num_classes=10)
        y_test = to_categorical(y_test, num_classes=10)
        \end{lstlisting}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Case Study 1: Continued}
    \textbf{Implementation Steps (Continued):}
    \begin{enumerate}[resume]
        \item \textbf{Build the CNN Model}:
        \begin{lstlisting}[language=Python]
        from tensorflow.keras import Sequential
        from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

        model = Sequential([
            Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
            MaxPooling2D(pool_size=(2, 2)),
            Conv2D(64, (3, 3), activation='relu'),
            MaxPooling2D(pool_size=(2, 2)),
            Flatten(),
            Dense(128, activation='relu'),
            Dense(10, activation='softmax')
        ])
        \end{lstlisting}
        
        \item \textbf{Compile and Train the Model}:
        \begin{lstlisting}[language=Python]
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
        model.fit(x_train, y_train, epochs=10, validation_split=0.2)
        \end{lstlisting}
        
        \item \textbf{Evaluate the Model}:
        \begin{lstlisting}[language=Python]
        test_loss, test_acc = model.evaluate(x_test, y_test)
        print(f'Test accuracy: {test_acc:.4f}')
        \end{lstlisting}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Case Study 2: Object Detection Using CNNs in PyTorch}
    \begin{block}{Objective}
        Detect objects from a given image using a pre-trained YOLO model.
    \end{block}
    
    \textbf{Implementation Steps:}
    \begin{enumerate}
        \item \textbf{Install Required Libraries}:
        \begin{lstlisting}[language=sh]
        pip install torch torchvision
        \end{lstlisting}
        
        \item \textbf{Load Pre-trained Model}:
        \begin{lstlisting}[language=Python]
        import torch
        model = torch.hub.load('ultralytics/yolov5:v6.0', 'yolov5s', pretrained=True)
        \end{lstlisting}
        
        \item \textbf{Inference on a Custom Image}:
        \begin{lstlisting}[language=Python]
        img = 'path/to/your/image.jpg'
        results = model(img)
        results.show()  # Visualize the detection
        \end{lstlisting}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Case Study 2: Continued}
    \textbf{Implementation Steps (Continued):}
    \begin{enumerate}[resume]
        \item \textbf{Extract Bounding Boxes}:
        \begin{lstlisting}[language=Python]
        detections = results.xyxy[0]  # Bounding boxes
        \end{lstlisting}
        
        \item \textbf{Post-processing}:
        \begin{itemize}
            \item Filter out low-confidence detections.
            \item Visualize results.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{Key Points to Emphasize}
    \begin{itemize}
        \item \textbf{Flexibility}: Both frameworks allow easy experimentation and iterative improvement of CNN architectures.
        \item \textbf{Community Support}: Large communities provide extensive documentation and resources for learning and troubleshooting.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Conclusion}
    \begin{block}{Summary}
        Implementing CNNs with frameworks like TensorFlow and PyTorch showcases their power and versatility. 
        Case studies highlight practical approaches to solve real-world problems using images, making CNNs essential in the machine learning toolbox.
    \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Conclusion and Key Takeaways - Overview of Key Concepts}
  \begin{enumerate}
    \item \textbf{Neural Networks}:
      \begin{itemize}
        \item Mimics the human brain's architecture with layers of nodes (neurons).
        \item Key types: Feedforward Neural Networks, Convolutional Neural Networks (CNNs), and Recurrent Neural Networks (RNNs).
      \end{itemize}
    
    \item \textbf{Deep Learning}:
      \begin{itemize}
        \item Focuses on neural networks with many layers (deep architectures).
        \item Enables automatic feature extraction from raw data, reducing manual work.
      \end{itemize}
    
    \item \textbf{Convolutional Neural Networks (CNNs)}:
      \begin{itemize}
        \item Crucial for visual data processing; used in image recognition and classification.
        \item Implemented using frameworks like TensorFlow and PyTorch for real-world tasks.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Conclusion and Key Takeaways - Importance in Machine Learning}
  \begin{itemize}
    \item \textbf{State-of-the-Art Performance}:
      \begin{itemize}
        \item Deep learning, especially CNNs, excels in complex domains like image analysis and natural language processing.
      \end{itemize}
    
    \item \textbf{Automation and Efficiency}:
      \begin{itemize}
        \item Automates feature extraction, reducing time and effort for model training and development.
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Conclusion and Key Takeaways - Key Points and Final Thoughts}
  \begin{block}{Key Takeaways}
    \begin{itemize}
      \item \textbf{Scalability}: Neural networks can efficiently capture complex patterns in large datasets.
      \item \textbf{Transfer Learning}: Pretrained models can be fine-tuned, saving time and boosting performance.
      \item \textbf{Hyperparameter Tuning}: Success relies on tuning elements like learning rate, batch size, and layers.
    \end{itemize}
  \end{block}
  
  \begin{block}{Final Thoughts}
    \begin{itemize}
      \item Advancements in neural networks and deep learning are pivotal for the future of AI.
      \item Continuous learning and adaptation to new methodologies are paramount for success.
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Call to Action}
  \begin{itemize}
    \item \textbf{Explore Further}: Engage in hands-on projects with TensorFlow or PyTorch to solidify understanding.
    \item \textbf{Join the Community}: Participate in forums and study groups to share insights and stay updated on advancements.
  \end{itemize}
\end{frame}


\end{document}