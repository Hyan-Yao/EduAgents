\frametitle{Common Model Evaluation Metrics (cont.)}

    \begin{enumerate}[resume]
        \item \textbf{Recall}
        \begin{itemize}
            \item \textbf{Definition:} Ratio of correctly predicted positives to all actual positives.
            \item \textbf{Formula:}
            \[
            \text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
            \]
            \item \textbf{Example:} Correctly identifying 60 out of 100 sick patients with 40 missed cases gives:
            \[
            \text{Recall} = \frac{60}{60 + 40} = 0.6 \text{ (or 60\%)}
            \]

        \item \textbf{F1-Score}
        \begin{itemize}
            \item \textbf{Definition:} Weighted average of precision and recall.
            \item \textbf{Formula:}
            \[
            F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
            \]
            \item \textbf{Utility:} Best for uneven class distributions.
        \end{itemize}
    \end{enumerate}

    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item Model evaluation helps choose the best model based on evidence.
            \item Different metrics serve varying purposes.
            \item Metric choice depends on business contexts and domains.
        \end{itemize}
    \end{block}

    \begin{block}{Conclusion}
        Model evaluation is essential in data mining for ensuring predictionsâ€™ reliability and guiding enhancements. The choice of evaluation metrics impacts the effectiveness of machine learning applications significantly.
    \end{block}
