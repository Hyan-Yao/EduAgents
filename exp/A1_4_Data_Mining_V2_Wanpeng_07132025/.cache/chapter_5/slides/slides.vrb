\frametitle{Training Neural Networks - Backpropagation}
    \begin{block}{Definition}
        Updating the network's weights to minimize prediction errors.
    \end{block}

    \begin{enumerate}
        \item \textbf{Calculate Loss:} Compute error using a loss function (e.g., Mean Squared Error).
        \item \textbf{Gradient Descent:} Compute the gradient:
        \begin{equation}
            \frac{\partial \text{Loss}}{\partial w} = \frac{\partial \text{Loss}}{\partial a} \cdot \frac{\partial a}{\partial z} \cdot \frac{\partial z}{\partial w}
        \end{equation}
        \item \textbf{Update Weights:} Adjust weights:
        \begin{equation}
            w = w - \alpha \cdot \frac{\partial \text{Loss}}{\partial w}
        \end{equation}
    \end{enumerate}

    \begin{block}{Example}
        For a prediction error of $100,000, backpropagation updates weights accordingly.
    \end{block}
