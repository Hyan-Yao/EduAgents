\documentclass[aspectratio=169]{beamer}

% Theme and Color Setup
\usetheme{Madrid}
\usecolortheme{whale}
\useinnertheme{rectangles}
\useoutertheme{miniframes}

% Additional Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}
\usepackage{hyperref}

% Custom Colors
\definecolor{myblue}{RGB}{31, 73, 125}
\definecolor{mygray}{RGB}{100, 100, 100}
\definecolor{mygreen}{RGB}{0, 128, 0}
\definecolor{myorange}{RGB}{230, 126, 34}
\definecolor{mycodebackground}{RGB}{245, 245, 245}

% Set Theme Colors
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=white, bg=myblue}
\setbeamercolor{title}{fg=myblue}
\setbeamercolor{section in toc}{fg=myblue}
\setbeamercolor{item projected}{fg=white, bg=myblue}
\setbeamercolor{block title}{bg=myblue!20, fg=myblue}
\setbeamercolor{block body}{bg=myblue!10}
\setbeamercolor{alerted text}{fg=myorange}

% Set Fonts
\setbeamerfont{title}{size=\Large, series=\bfseries}
\setbeamerfont{frametitle}{size=\large, series=\bfseries}
\setbeamerfont{caption}{size=\small}
\setbeamerfont{footnote}{size=\tiny}

% Custom Commands
\newcommand{\concept}[1]{\textcolor{myblue}{\textbf{#1}}}
\newcommand{\separator}{\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}}

% Title Page Information
\title[Week 13: Advanced Topics]{Week 13: Advanced Topics – Text Mining \& Representation Learning}
\author[J. Smith]{John Smith, Ph.D.}
\institute[University Name]{
  Department of Computer Science\\
  University Name\\
  \vspace{0.3cm}
  Email: email@university.edu\\
  Website: www.university.edu
}
\date{\today}

% Document Start
\begin{document}

\frame{\titlepage}

\begin{frame}[fragile]
    \frametitle{Introduction to Text Mining}
    \begin{block}{Overview of Text Mining}
        Text mining is the process of deriving high-quality information from text. It involves transforming unstructured text into structured data to extract patterns, insights, and useful knowledge. With the exponential growth of textual data from sources like social media and documents, the relevance of text mining is paramount.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Purpose of Text Mining}
    \begin{enumerate}
        \item \textbf{Uncovering Insights:} Identifying trends and sentiment in customer feedback, reviews, or surveys.
        \item \textbf{Automating Data Processing:} Automating extraction and analysis of unstructured data for efficiency.
        \item \textbf{Supporting Decision-Making:} Driving strategic decisions based on insights from text mining.
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Relevance in Handling Unstructured Data}
    \begin{itemize}
        \item \textbf{Nature of Unstructured Data:} Text data is messy and diverse, making it a prime candidate for text mining.
        \item \textbf{Techniques Used:}
        \begin{itemize}
            \item \textbf{Natural Language Processing (NLP):} Understanding and generating human language.
            \item \textbf{Sentiment Analysis:} Determining the sentiment of the text.
            \item \textbf{Topic Modeling:} Identifying topics in a document set.
            \item \textbf{Information Retrieval:} Extracting relevant information from large texts.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Examples of Real-World Applications}
    \begin{itemize}
        \item \textbf{Customer Insights:} Analyzing customer reviews on platforms like Amazon or Yelp.
        \item \textbf{Healthcare:} Using NLP to extract data from medical literature or patient records.
        \item \textbf{AI Models:} Applications like ChatGPT benefit from vast datasets mined from the web.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Conclusion}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item Text mining is essential for harnessing unstructured data.
            \item It automates the extraction of valuable insights.
            \item Techniques such as NLP and sentiment analysis broaden our interaction with data.
        \end{itemize}
    \end{block}
    \begin{block}{Conclusion}
        Understanding text mining is vital in a data-driven world. Consider how these techniques can apply to your field of study or interest.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance of Text Mining - Introduction}
    Text mining is a crucial technique in data science that transforms unstructured text data into meaningful insights. Understanding its significance is essential in today’s data-rich environment. Key motivations for using text mining include:

    \begin{itemize}
        \item Handling unstructured data
        \item Automating information extraction
        \item Enhancing decision-making
        \item Improving customer experience
        \item Supporting AI and machine learning developments
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance of Text Mining - Key Motivations}
    
    \begin{enumerate}
        \item **Handling Unstructured Data:**
            \begin{itemize}
                \item Approximately 80\% of global data is unstructured (emails, social media, documents).
                \item **Example:** Analyzing customer reviews on platforms like Amazon to gain insights.
            \end{itemize}
    
        \item **Automating Information Extraction:**
            \begin{itemize}
                \item Automates the extraction of valuable insights from large datasets.
                \item **Example:** NLP algorithms summarizing research papers, saving time.
            \end{itemize}
        
        \item **Enhancing Decision-Making:**
            \begin{itemize}
                \item Unveils patterns in textual data for informed choices.
                \item **Example:** Healthcare providers improving services based on patient feedback.
            \end{itemize}
    
        \item **Improving Customer Experience:**
            \begin{itemize}
                \item Understanding customer sentiments through text mining.
                \item **Example:** Companies like Netflix refining recommendations through reviews.
            \end{itemize}
    
        \item **Support for AI and Machine Learning:**
            \begin{itemize}
                \item Text mining provides structured information for machine learning accuracy.
                \item **Example:** ChatGPT using diverse datasets for context understanding.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance of Text Mining - Real-World Applications}
    
    Real-world applications vividly illustrate the importance of text mining:

    \begin{itemize}
        \item **Sentiment Analysis:**
            \begin{itemize}
                \item Monitoring social media to assess public opinion concerning brands.
                \item **Example:** Tracking tweets during a product launch to gauge reactions.
            \end{itemize}
        
        \item **Healthcare Monitoring:**
            \begin{itemize}
                \item Analyzing patient notes to improve care outcomes.
            \end{itemize}
        
        \item **Fraud Detection:**
            \begin{itemize}
                \item Financial institutions using text mining to find anomalies in transaction reports.
            \end{itemize}
    \end{itemize}
    
    \begin{block}{Summary of Key Points}
        Text mining reveals insights from unstructured data, automates manual processes, and supports AI technologies like ChatGPT, proving indispensable in various sectors.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Text Mining Techniques}
    \begin{block}{Overview of Core Text Mining Methodologies}
        Text mining is the process of deriving meaningful information from text. 
        It encompasses several methodologies, categorized mainly into three techniques:
        \begin{itemize}
            \item Information Retrieval
            \item Text Classification
            \item Sentiment Analysis
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{1. Information Retrieval}
    \begin{block}{Definition}
        Information Retrieval (IR) is the technique used to find relevant documents from a large corpus based on a user's query.
    \end{block}
    \begin{itemize}
        \item \textbf{How It Works:}
        \begin{enumerate}
            \item The user submits a query (keywords/questions).
            \item The system searches databases and retrieves matching documents.
        \end{enumerate}
        \item \textbf{Example:} 
        \begin{itemize}
            \item Search engines like Google utilize IR techniques to rank web pages based on relevance.
        \end{itemize}
        \item \textbf{Key Points:}
        \begin{itemize}
            \item Utilizes indexing for faster searches.
            \item Effectiveness measured by precision and recall.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{2. Text Classification}
    \begin{block}{Definition}
        Text Classification involves assigning predefined categories to documents based on their content.
    \end{block}
    \begin{itemize}
        \item \textbf{How It Works:}
        \begin{itemize}
            \item Algorithms learn from labeled training data to classify new text.
            \item Common algorithms: Naïve Bayes, Support Vector Machines, Neural Networks.
        \end{itemize}
        \item \textbf{Example:} 
        \begin{itemize}
            \item Email filtering uses classification to distinguish between spam and legitimate emails.
        \end{itemize}
        \item \textbf{Key Points:}
        \begin{itemize}
            \item Types: Binary Classification (e.g., spam vs. non-spam) and Multi-class Classification (e.g., news article categories).
            \item Performance metrics include accuracy, precision, and F1-score.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{3. Sentiment Analysis}
    \begin{block}{Definition}
        Sentiment Analysis determines the emotional tone behind a body of text, classifying it as positive, negative, or neutral.
    \end{block}
    \begin{itemize}
        \item \textbf{How It Works:}
        \begin{itemize}
            \item Utilizes NLP techniques to interpret sentiments.
            \item Can be performed at document, sentence, or aspect levels.
        \end{itemize}
        \item \textbf{Example:} 
        \begin{itemize}
            \item Businesses analyze customer reactions from social media or reviews.
        \end{itemize}
        \item \textbf{Key Points:}
        \begin{itemize}
            \item Methods include lexical analysis, machine learning, and deep learning.
            \item Provides insights into customer satisfaction and brand perception.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Summary of Key Techniques}
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Technique} & \textbf{Definition} & \textbf{Example} \\
        \hline
        Information Retrieval & Finding documents relevant to user queries & Search engines like Google \\
        \hline
        Text Classification & Assigning categories to text based on content & Email spam filtering \\
        \hline
        Sentiment Analysis & Assessing emotional tone from text & Analyzing customer feedback \\
        \hline
    \end{tabular}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Motivation for Text Mining}
    Understanding these techniques is essential as they form the backbone of modern applications in artificial intelligence and machine learning. Some applications, such as ChatGPT, rely heavily on data mining to learn from vast datasets and generate human-like responses. 

    By grasping these foundational techniques, students can appreciate the significance of text mining in decision-making and strategic planning within organizations, emphasizing its real-world importance.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Topics}
    \begin{block}{Next Steps}
        Next, we will delve into Data Preprocessing in Text Mining, which is crucial for preparing text data to improve analysis accuracy.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data Preprocessing in Text Mining - Introduction}
    \begin{block}{Introduction}
        Data preprocessing is a critical step in text mining that prepares raw text for analysis. It transforms raw text into a format that can be efficiently processed by machine learning algorithms.
    \end{block}
    
    \begin{itemize}
        \item Improves data quality
        \item Enhances analysis effectiveness
        \item Reduces computational resources
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data Preprocessing in Text Mining - Key Steps}

    \begin{enumerate}
        \item \textbf{Tokenization}
        \item \textbf{Stop Word Removal}
        \item \textbf{Stemming}
        \item \textbf{Lemmatization}
    \end{enumerate}
    
    \begin{block}{Conclusion}
        Data preprocessing lays the groundwork for effective text mining and improves model precision.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data Preprocessing in Text Mining - Detailed Steps}

    \begin{enumerate}
        \item \textbf{Tokenization}  
        \begin{itemize}
            \item \textbf{Definition:} Breaks down text into individual units (tokens).
            \item \textbf{Example:} 
            \begin{lstlisting}
            Input: "The cat sat on the mat."
            Output: ["The", "cat", "sat", "on", "the", "mat"]
            \end{lstlisting}
            \item \textbf{Key Point:} Allows granular text analysis.
        \end{itemize}

        \item \textbf{Stop Word Removal}  
        \begin{itemize}
            \item \textbf{Definition:} Removes common words that add little meaning.
            \item \textbf{Example:} 
            \begin{lstlisting}
            Input: ["The", "cat", "sat", "on", "the", "mat"]
            Output: ["cat", "sat", "mat"]
            \end{lstlisting}
            \item \textbf{Key Point:} Reduces noise and improves focus.
        \end{itemize}

        \item \textbf{Stemming}  
        \begin{itemize}
            \item \textbf{Definition:} Reduces words to their base form.
            \item \textbf{Example:} 
            \begin{lstlisting}
            Input: "running", "runner", "ran"
            Output: "run"
            \end{lstlisting}
            \item \textbf{Key Point:} Enhances matching across word forms.
            \item \textbf{Algorithm:} Porter Stemmer.
        \end{itemize}

        \item \textbf{Lemmatization}  
        \begin{itemize}
            \item \textbf{Definition:} Returns the dictionary form of a word considering context.
            \item \textbf{Example:} 
            \begin{lstlisting}
            Input: "better"
            Output: "good"
            \end{lstlisting}
            \item \textbf{Key Point:} More accurate than stemming but computationally intensive.
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data Preprocessing in Text Mining - Summary}

    \begin{itemize}
        \item Data preprocessing enhances the quality of data for text mining tasks.
        \item Understanding these techniques is essential for:
        \begin{itemize}
            \item Information retrieval
            \item Sentiment analysis
            \item Text classification
        \end{itemize}
        \item Recent AI applications, like ChatGPT, rely on robust text preprocessing techniques for text understanding and generation.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Feature Extraction}
    Feature extraction is a crucial step in text mining that converts textual data into a numerical format suitable for machine learning algorithms. This facilitates learning and prediction tasks.
    
    \begin{block}{Why Do We Need Feature Extraction?}
        \begin{itemize}
            \item \textbf{Numerical Representation:} Machine learning algorithms primarily require numbers, making text conversion essential.
            \item \textbf{Dimensionality Reduction:} Extracting features can reduce text data complexity while retaining meaningful information.
            \item \textbf{Noise Reduction:} Filtering out irrelevant information enhances model performance.
        \end{itemize}
    \end{block}
    
    \pause
    
    \begin{block}{Common Techniques for Feature Extraction}
        \begin{itemize}
            \item Bag of Words (BoW)
            \item Term Frequency-Inverse Document Frequency (TF-IDF)
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Bag of Words (BoW)}
    \begin{block}{Overview}
        BoW is a simple and widely used technique that represents text as a collection of words, disregarding grammar and word order.
    \end{block}
    
    \begin{block}{How It Works}
        \begin{enumerate}
            \item Create a vocabulary of unique words from the dataset.
            \item Represent each document as a vector of word frequencies.
        \end{enumerate}
    \end{block}
    
    \begin{example}
    Consider the following documents:
    \begin{itemize}
        \item Document 1: "I love machine learning."
        \item Document 2: "Machine learning is fascinating."
    \end{itemize}
    
    Vocabulary: $\{I, love, machine, learning, is, fascinating\}$
    
    Document 1 Vector: $[1, 1, 1, 1, 0, 0]$ \\
    Document 2 Vector: $[0, 0, 1, 1, 1, 1]$
    
    \textbf{Key Points:}
    \begin{itemize}
        \item Quick to implement and understand.
        \item Ignores context and semantics of language.
    \end{itemize}
    \end{example}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Term Frequency-Inverse Document Frequency (TF-IDF)}
    \begin{block}{Overview}
        TF-IDF enhances BoW by considering the importance of words across documents.
    \end{block}
    
    \begin{block}{Formulas}
        \begin{equation}
            \text{IDF}(t) = \log\left(\frac{N}{df(t)}\right)
        \end{equation}
        where $N$ is the total number of documents, and $df(t)$ is the number of documents containing the term $t$.
        
        \begin{equation}
            \text{TF-IDF}(t, d) = \text{TF}(t, d) \times \text{IDF}(t)
        \end{equation}
    \end{block}
    
    \pause
    
    \begin{block}{Example}
    Using the previous documents, TF-IDF vectors will highlight terms more unique to each document, enhancing context.
    
    \textbf{Key Points:}
    \begin{itemize}
        \item Considers term significance across documents.
        \item Minimizes the impact of frequently occurring but less informative words.
    \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Introduction to Representation Learning}
    
    \begin{block}{What is Representation Learning?}
        Representation Learning is a subset of machine learning techniques focused on automatically discovering the representations or features needed for a given task from raw data. 
    \end{block}
    
    \begin{itemize}
        \item Enables models to learn and extract meaningful patterns directly from the data.
        \item Reduces the reliance on manual feature engineering.
    \end{itemize}

\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Characteristics and Significance}

    \begin{block}{Key Characteristics}
        \begin{itemize}
            \item \textbf{Automatic Feature Extraction}: Processes data without extensive preprocessing.
            \item \textbf{High-Dimensional Data Handling}: Effective for data types like images, text, and sound. 
        \end{itemize}
    \end{block}
    
    \begin{block}{Significance of Representation Learning}
        \begin{enumerate}
            \item \textbf{Enhances Model Performance}
            \item \textbf{Reduces Dimensionality}
            \item \textbf{Facilitates Transfer Learning}
            \item \textbf{Sparsity \& Interpretability}
        \end{enumerate}
    \end{block}
    
\end{frame}

\begin{frame}[fragile]
    \frametitle{Examples and Key Takeaways}

    \begin{block}{Example of Representation Learning in AI Applications}
        \begin{itemize}
            \item \textbf{ChatGPT \& NLP Models}: Utilizes representation learning to understand context and generate human-like text.
            \item \textit{Word embeddings} capture semantic meanings effectively.
        \end{itemize}
    \end{block}
    
    \begin{block}{Conclusion \& Key Takeaways}
        \begin{itemize}
            \item Pivotal in extracting meaningful insights from raw data.
            \item Leads to smarter implementations of AI applications.
        \end{itemize}
    \end{block}

\end{frame}

\begin{frame}[fragile]
    \frametitle{Representation Techniques - Overview}
    \begin{block}{Introduction}
        Representation learning is vital in text mining, transforming words into numerical vectors for better semantic understanding. This slide covers three key techniques: Word2Vec, GloVe, and FastText.
    \end{block}
    \begin{itemize}
        \item **Word2Vec**: Neural network-based word representation.
        \item **GloVe**: Global statistical co-occurrence modeling.
        \item **FastText**: Character n-gram based representation.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Representation Techniques - Word2Vec}
    \begin{block}{Overview}
        Developed by Google, Word2Vec generates vector representations using neural networks.
    \end{block}
    \begin{itemize}
        \item **Techniques**:
            \begin{itemize}
                \item CBOW: Predicts the target word from context words.
                \item Skip-Gram: Predicts context words from a target word.
            \end{itemize}
        \item **Benefits**: Captures semantic relationships, e.g., king - man + woman = queen.
        \item **Applications**: Sentiment analysis, similar word search, feature representation in neural networks.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Representation Techniques - GloVe and FastText}
    \begin{block}{GloVe}
        GloVe employs global statistics through a co-occurrence matrix for word vectors.
    \end{block}
    \begin{itemize}
        \item **Mathematical formula**:
        \begin{equation}
            J = \sum_{i,j=1}^{V} f(X_{ij}) \left( \mathbf{w_i}^T \mathbf{w_j} + b_i + b_j - \log(X_{ij}) \right)^2
        \end{equation}
        \item **Applications**: Effective in text classification, named entity recognition, machine translation.
    \end{itemize}

    \begin{block}{FastText}
        FastText enhances Word2Vec by incorporating subword information for better representations.
    \end{block}
    \begin{itemize}
        \item **Benefits**: Handles out-of-vocabulary words and captures fine-grained semantic nuances.
        \item **Applications**: Document classification, sentiment analysis, chatbots.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Concluding Thoughts}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item Essential role of representation techniques in transforming text for machine understanding.
            \item Each method has unique strengths suited for different applications.
            \item Combining methods enhances performance in NLP tasks.
        \end{itemize}
    \end{block}
    \begin{block}{Concluding Thoughts}
        Understanding these techniques is crucial for leveraging AI advances. For instance, models like ChatGPT rely on such embeddings for generating coherent responses.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Deep Learning in Text Mining - Introduction}
    \begin{block}{Overview}
        Deep learning has revolutionized text mining by enabling machines to understand, interpret, and generate human language with unprecedented accuracy.
    \end{block}
    \begin{itemize}
        \item Neural networks transform raw text into meaningful representations.
        \item This advancement opens doors to various natural language processing (NLP) applications.
    \end{itemize}
    \begin{block}{Motivation for Using Deep Learning}
        \begin{itemize}
            \item **Complex Patterns**: Identifies intricate patterns for better performance on tasks like sentiment analysis and topic modeling.
            \item **Unstructured Data**: Automatically derives features, reducing the need for manual extraction.
            \item **State-of-the-Art Performance**: Models like BERT and GPT set new benchmarks in NLP.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Deep Learning Concepts}
    \begin{block}{Key Concepts in Deep Learning for Text Mining}
        \begin{enumerate}
            \item **Neural Networks**
                \begin{itemize}
                    \item Interconnected nodes (neurons) that process and learn.
                    \item **Feedforward Neural Networks**: Data flows in one direction.
                    \item **Activation Functions**: Functions like ReLU that introduce non-linearity.
                \end{itemize}
            \item **Representation Learning**
                \begin{itemize}
                    \item Automatically learns high-level representations.
                    \item **Embedding Layer**: Maps words to dense vectors.
                \end{itemize}
            \item **Advanced Architectures**
                \begin{itemize}
                    \item **CNNs**: Capture local features for text classification.
                    \item **RNNs**: Suitable for sequential data.
                    \item **Transformers**: Utilize self-attention for contextual understanding.
                \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Recent Applications and Example}
    \begin{block}{Recent Applications of Deep Learning}
        \begin{itemize}
            \item **ChatGPT**: A conversational agent generating coherent responses.
            \item **Sentiment Analysis**: Classifying opinions using LSTM networks.
            \item **Document Classification**: Automating categorization with BERT.
        \end{itemize}
    \end{block}
    \begin{block}{Example: Using a Transformer Model}
        \begin{lstlisting}[language=Python]
from transformers import BertTokenizer, BertModel
import torch

# Load pre-trained model and tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased')

# Tokenize and encode sentence
input_ids = tokenizer("Text mining with deep learning is powerful.", return_tensors='pt')
outputs = model(**input_ids)

# Get the embeddings
embeddings = outputs.last_hidden_state
        \end{lstlisting}
    \end{block}
    \begin{block}{Key Takeaways}
        Deep learning significantly enhances text mining capabilities, allowing for intricate comprehension of human language.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Neural Networks for Text Representation - Overview}
    \begin{block}{Overview}
        Neural networks are powerful tools for learning representations of text data. 
        They automate feature extraction, enabling advanced processing essential for various natural language processing (NLP) tasks.
    \end{block}
    \begin{itemize}
        \item Sentiment Analysis
        \item Machine Translation
        \item Information Retrieval
    \end{itemize}
    \begin{block}{Motivation}
        Why do we need data mining?
        \begin{itemize}
            \item To manage large amounts of unstructured text data.
            \item To improve understanding of user interactions in AI applications like ChatGPT.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Neural Networks - Learning Representations}
    \begin{block}{How They Work}
        Neural networks transform input data into meaningful representations through feature extraction, optimizing weights to minimize prediction error.
    \end{block}
    \begin{enumerate}
        \item \textbf{Input Layer:} 
          Raw text data transformed into numerical vectors (e.g., Word2Vec, GloVe).
        \item \textbf{Hidden Layers:} 
          Capture complexity via multiple transformations.
        \item \textbf{Output Layer:} 
          Produces predictions (e.g., sentiment scores, classifications).
    \end{enumerate}

    \begin{block}{Training}
        Weights are adjusted using algorithms such as backpropagation and optimizers (e.g., Adam, SGD).
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Neural Networks for Text}
    \begin{block}{Convolutional Neural Networks (CNNs)}
        \begin{itemize}
            \item \textbf{Structure:} 
              Efficient extraction of local features with convolutional layers.
            \item \textbf{Usage:} 
              Text classification, spam detection.
            \item \textbf{Example:} 
              Identifies n-grams by scanning text (e.g., "ChatGPT is amazing!").
        \end{itemize}
        \begin{figure}
            \centering
            \includegraphics[width=0.6\linewidth]{cnn_example.png}
            \caption{CNN sliding window illustration.}
        \end{figure}
    \end{block}

    \begin{block}{Recurrent Neural Networks (RNNs)}
        \begin{itemize}
            \item \textbf{Structure:} 
              Designed for sequential data with hidden states.
            \item \textbf{Usage:} 
              Language modeling, machine translation.
            \item \textbf{Example:} 
              Predicts next words in sequences based on previous context.
        \end{itemize}
        \begin{figure}
            \centering
            \includegraphics[width=0.6\linewidth]{rnn_example.png}
            \caption{RNN hidden state updates.}
        \end{figure}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Advantages of Neural Networks}
    \begin{itemize}
        \item \textbf{Scalability:} 
            Efficient handling of vast unstructured text data.
        \item \textbf{Generalization:} 
            Ability to learn from training data and apply knowledge to unseen data.
        \item \textbf{Feature Learning:} 
            Automatically extract relevant features, reducing manual effort.
    \end{itemize}
    \begin{block}{Conclusion}
        Neural networks, through architectures like CNNs and RNNs, offer effective frameworks for text representation learning.
        Applications such as AI chatbots reflect their transformative role in technology.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Considerations in Text Mining \& Representation Learning}
    \begin{block}{Introduction to Ethical Implications}
        Understanding the ethical considerations surrounding text mining and representation learning is crucial. Key areas of concern include data privacy and algorithmic bias.
    \end{block}
    \begin{itemize}
        \item Data Privacy
        \item Bias in Algorithms
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data Privacy}
    \begin{block}{Definition}
        Data privacy refers to the proper handling, processing, and storing of sensitive data.
    \end{block}
    \begin{itemize}
        \item **Concerns**:
            \begin{itemize}
                \item Personal Data: Text mining processes large datasets, which can include personal information (e.g., social media posts).
                \item Consent: There may be a lack of awareness among users regarding how their data is utilized.
            \end{itemize}
        \item **Example**: Training models like ChatGPT often involves scraping vast amounts of data, sometimes without user consent.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points on Data Privacy}
    \begin{itemize}
        \item **Legal Regulations**: 
            \begin{itemize}
                \item GDPR in Europe enforces strict rules on data collection.
            \end{itemize}
        \item **Best Practices**:
            \begin{itemize}
                \item Anonymization: Remove identifiable information from datasets.
                \item Transparency: Clearly communicate data usage to users.
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Bias in Algorithms}
    \begin{block}{Definition}
        Bias in algorithms refers to systemic favoritism or prejudice in decision-making processes of machine learning systems.
    \end{block}
    \begin{itemize}
        \item **Concerns**:
            \begin{itemize}
                \item Training Data Bias: If training data contains biases (e.g., gender stereotypes), the model may perpetuate these biases.
            \end{itemize}
        \item **Example**: Language models predominantly trained on texts from specific demographics may poorly represent marginalized groups.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points on Bias}
    \begin{itemize}
        \item **Impact of Bias**: 
            \begin{itemize}
                \item Can lead to unfair outcomes in hiring, loan approvals, and legal judgments.
            \end{itemize}
        \item **Mitigation Strategies**: 
            \begin{itemize}
                \item Diverse Training Sets: Incorporate varied datasets to reduce bias.
                \item Ongoing Evaluation: Regularly test models for bias.
            \end{itemize}
    \end{itemize}
    \begin{block}{Conclusion}
        Ethical implications in text mining and representation learning must prioritize data privacy and address algorithmic biases.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Real-World Applications - Overview}
    \begin{block}{Introduction}
        Text mining and representation learning transform unstructured data into valuable insights. They are widely applied across various industries, enhancing processes, decision-making, and customer experiences.
    \end{block}
    
    \begin{block}{Key Concepts}
        \begin{itemize}
            \item \textbf{Text Mining}: Extracting meaningful information from textual data using Natural Language Processing (NLP).
            \item \textbf{Representation Learning}: Learning useful data representations such as word embeddings that allow algorithms to understand data structures.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Real-World Applications - Case Studies}
    \begin{itemize}
        \item \textbf{Healthcare}
            \begin{itemize}
                \item \textbf{Application}: Analyzing clinical notes and patient records.
                \item \textbf{Benefits}: Improved patient outcomes, predictive modeling.
                \item \textbf{Example}: IBM Watson Health suggests tailored treatments.
            \end{itemize}
        
        \item \textbf{Finance}
            \begin{itemize}
                \item \textbf{Application}: Sentiment analysis of news and social media.
                \item \textbf{Benefits}: Enhanced market predictions and strategies.
                \item \textbf{Example}: Bloomberg analyzes market sentiment for investment insight.
            \end{itemize}
        
        \item \textbf{Retail}
            \begin{itemize}
                \item \textbf{Application}: Analyzing customer feedback.
                \item \textbf{Benefits}: Improved offerings and satisfaction.
                \item \textbf{Example}: Amazon uses sentiment analysis for product reviews.
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Real-World Applications - Continued Case Studies}
    \begin{itemize}
        \item \textbf{Legal}
            \begin{itemize}
                \item \textbf{Application}: Document review and e-discovery.
                \item \textbf{Benefits}: Cost reductions and time savings.
                \item \textbf{Example}: ROSS Intelligence aids lawyers in finding pertinent cases.
            \end{itemize}
        
        \item \textbf{Chatbots and Virtual Assistants}
            \begin{itemize}
                \item \textbf{Application}: Customer service and tailored assistance.
                \item \textbf{Benefits}: Higher engagement and efficiency.
                \item \textbf{Example}: ChatGPT offers human-like responses using representation learning.
            \end{itemize}
    \end{itemize}

    \begin{block}{Conclusion}
        Applying text mining and representation learning can significantly drive innovation and efficiency across sectors, emphasizing their critical role in the data-driven world.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges in Text Mining - Overview}
    Text mining involves extracting valuable information from unstructured textual data. 
    While the potential is vast, several challenges must be addressed for effective analysis. 
    Here are the key challenges:
    \begin{itemize}
        \item Language Diversity
        \item Context Understanding
        \item Ambiguity in Text
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges in Text Mining - Language Diversity}
    \begin{block}{Language Diversity}
        \begin{itemize}
            \item \textbf{Explanation:} Text data appears in multiple languages, dialects, and variations (slang/regional phrases).
            \item \textbf{Example:} A sentiment analysis model trained on English texts may struggle with Spanish due to linguistic structures.
            \item \textbf{Key Point:} Text mining systems must adapt to various languages or provide translations.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges in Text Mining - Context Understanding}
    \begin{block}{Context Understanding}
        \begin{itemize}
            \item \textbf{Explanation:} Context is crucial for interpreting meanings accurately; the same word may have different meanings based on context.
            \item \textbf{Example:} The term “bank” can refer to a financial institution or the side of a river.
            \item \textbf{Key Point:} Advanced techniques like named entity recognition and contextual embeddings (e.g., BERT) are essential.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges in Text Mining - Ambiguity in Text}
    \begin{block}{Ambiguity in Text}
        \begin{itemize}
            \item \textbf{Explanation:} Text often contains idioms and metaphors which confuse algorithms, leading to errors.
            \item \textbf{Example:} “Kick the bucket” means to die but can be misinterpreted literally.
            \item \textbf{Key Point:} Handling ambiguity requires sophisticated NLP strategies, including disambiguation algorithms.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges in Text Mining - Conclusion}
    Overcoming the challenges of language diversity, context understanding, and ambiguity is essential for effective text mining. 
    As NLP tools evolve, innovative approaches will emerge to enhance the accuracy of text mining in real-world applications.
    
    \begin{itemize}
        \item Language Diversity: Adaptability is critical.
        \item Context Understanding: Essential for meaning interpretation.
        \item Ambiguity: Require advanced NLP techniques.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Trends in Text Mining - Overview}
    \begin{block}{Introduction}
        As technology advances, text mining is evolving through integration with artificial intelligence (AI) and advanced analytics.
    \end{block}
    \begin{itemize}
        \item Importance of understanding emerging trends.
        \item Preparing for real-world applications of text mining.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Trends in Text Mining - Integration of AI}
    \begin{block}{Integration of AI}
        AI enhances the accuracy and efficiency of natural language processing (NLP) tasks.
    \end{block}
    \begin{itemize}
        \item Key Advances:
        \begin{itemize}
            \item \textbf{Transfer Learning:} Models like BERT and GPT understand context and semantics.
            \item \textbf{Automated Insights:} Tools generate summaries, perform sentiment analysis, and create human-like text.
        \end{itemize}
        \item \textbf{Example:} ChatGPT showcases the synergy between text mining and AI.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Trends in Text Mining - NLU and NLG}
    \begin{block}{Natural Language Understanding (NLU) and Generation (NLG)}
        NLU and NLG enable machines to comprehend and generate text similarly to humans.
    \end{block}
    \begin{itemize}
        \item Key Techniques:
        \begin{itemize}
            \item \textbf{Reinforcement Learning:} Improves model accuracy based on feedback.
            \item \textbf{Deep Learning Architectures:} Transformers enhance sequence-to-sequence tasks.
        \end{itemize}
        \item \textbf{Example:} NLG systems automate report writing in finance and journalism.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Trends in Text Mining - Advanced Analytics}
    \begin{block}{Advanced Analytics Integration}
        Combining text mining with advanced analytics uncovers hidden insights from unstructured data.
    \end{block}
    \begin{itemize}
        \item Key Features:
        \begin{itemize}
            \item \textbf{Predictive Analytics:} Leveraging historical data for future predictions.
            \item \textbf{Sentiment Analysis:} Gauging public opinion via mining text from social media and surveys.
        \end{itemize}
        \item \textbf{Example:} Analyzing tweets during elections reveals public opinion trends.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Trends in Text Mining - Multilingual and Ethical Considerations}
    \begin{block}{Contextual and Multilingual Capabilities}
        Tools must process multiple languages and understand context due to globalization.
    \end{block}
    \begin{itemize}
        \item Developments:
        \begin{itemize}
            \item \textbf{Multilingual Modeling:} Supports various languages accounting for cultural nuances.
            \item \textbf{Contextualized Word Embeddings:} Differentiates meanings based on context.
        \end{itemize}
        \item \textbf{Example:} Google Translate's improvement through contextualization.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Trends in Text Mining - Ethical Considerations}
    \begin{block}{Ethical Considerations and Bias Management}
        Addressing ethical issues and managing bias is critical as AI technologies advance.
    \end{block}
    \begin{itemize}
        \item Key Points:
        \begin{itemize}
            \item \textbf{Bias Detection:} New tools identify and mitigate biases in datasets.
            \item \textbf{Transparency Initiatives:} Promoting transparency in models builds trust.
        \end{itemize}
        \item \textbf{Example:} Best practices ensuring models do not perpetuate stereotypes.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Future Trends in Text Mining - Conclusion}
    \begin{block}{Conclusion}
        The intersection of AI and advanced analytics will shape future text mining trends.
    \end{block}
    \begin{itemize}
        \item Understanding context and ethical implications is essential.
        \item Organizations can maximize unstructured data potential by embracing these trends.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Interactive Q\&A Session - Overview}
    \begin{block}{Engagement Set-Up}
        Welcome to the Interactive Q\&A Session! Here, we encourage active participation to consolidate your understanding of text mining and representation learning concepts discussed earlier. This is your opportunity to reflect on key ideas, clarify doubts, and share insights.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Interactive Q\&A Session - Key Questions}
    \begin{enumerate}
        \item \textbf{Why is Text Mining Important?}
            \begin{itemize}
                \item Motivation: Extracts meaningful information from unstructured data.
                \item Examples: Influences product reviews analysis and marketing strategies.
            \end{itemize}
        
        \item \textbf{What are the Key Techniques in Text Mining?}
            \begin{itemize}
                \item Common Techniques:
                    \begin{itemize}
                        \item \textbf{Tokenization}: Breaking text into words or phrases.
                        \item \textbf{Stemming and Lemmatization}: Reducing words to their base form.
                        \item \textbf{Named Entity Recognition (NER)}: Identifying and categorizing entities.
                    \end{itemize}
                \item Example Discussion: Techniques for specific applications like chatbots.
            \end{itemize}
        
        \item \textbf{How Does Representation Learning Enhance Text Mining?}
            \begin{itemize}
                \item Definition: Automating feature extraction to enhance understanding.
                \item Example: Word embeddings (e.g., Word2Vec, GloVe) represent meanings and relationships.
                \item Discussion Point: Transformer models vs traditional methods in text understanding.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Interactive Q\&A Session - Recent Applications and Wrap-Up}
    \begin{enumerate}
        \setcounter{enumi}{3}
        \item \textbf{Recent Applications of AI in Text Mining:}
            \begin{itemize}
                \item Integration with AI models like ChatGPT for generating human-like responses.
                \item Discussion Question: Transformations in text mining practices through AI.
            \end{itemize}
    \end{enumerate}
    
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item Growing relevance of text mining in an era of big data.
            \item Importance of advanced techniques like representation learning.
            \item Impact of AI applications in enhancing empathy and context in text mining.
        \end{itemize}
    \end{block}
    
    \begin{block}{Wrap-Up}
        \begin{itemize}
            \item Synthesize what you have learned today.
            \item Consider areas that could benefit from advances in these fields.
            \item Open the floor for questions and discussions!
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Summary and Conclusions - Part 1}
    \begin{block}{Recap of Key Concepts in Text Mining}
        \begin{enumerate}
            \item \textbf{What is Text Mining?}
            \begin{itemize}
                \item Extracts meaningful information from unstructured text data.
                \item Combines Natural Language Processing (NLP), machine learning, and data mining.
                \item \textbf{Example:} Analyzing customer reviews to determine sentiment trends.
            \end{itemize}

            \item \textbf{Significance of Text Mining}
            \begin{itemize}
                \item Transforms raw text into insights that drive decision-making in various industries.
                \item \textbf{Motivation:} Enables organizations to distill vast amounts of text data into actionable intelligence.
            \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Summary and Conclusions - Part 2}
    \begin{block}{Methodologies Covered}
        \begin{enumerate}
            \item \textbf{Text Representation Techniques:}
            \begin{itemize}
                \item \textbf{Bag of Words (BoW):} 
                \begin{itemize}
                    \item Counts word occurrences, disregarding grammar and order.
                    \item \textbf{Example:} "I love snacks" $\rightarrow$ \{‘I’: 1, ‘love’: 1, ‘snacks’: 1\}
                \end{itemize}

                \item \textbf{TF-IDF (Term Frequency-Inverse Document Frequency):}
                \begin{itemize}
                    \item Highlights important words relative to document collections.
                    \item \textbf{Illustration:} TF-IDF emphasizes ‘data’ in critical reviews despite its commonality.
                \end{itemize}

                \item \textbf{Word Embeddings:}
                \begin{itemize}
                    \item Techniques like Word2Vec represent words in multi-dimensional spaces.
                    \item \textbf{Example:} "king" is similar to "queen" in context, reflecting their relationship.
                \end{itemize}
            \end{itemize}

            \item \textbf{Advanced Topics:}
            \begin{itemize}
                \item Representation learning for automatic feature discovery.
                \item Applications of AI in text mining, including ChatGPT.
            \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Summary and Conclusions - Part 3}
    \begin{block}{Conclusion Points}
        \begin{itemize}
            \item \textbf{Impact on Business and Society:}
            Text mining enhances decision-making, personalization, and insights across various domains.
            
            \item \textbf{Continuous Evolution:}
            Methodologies are rapidly advancing, fostering new applications.
            
            \item \textbf{Call to Action:}
            Stay informed on emerging techniques and tools in text mining for full leverage of its potential.
        \end{itemize}
    \end{block}

    \begin{block}{Final Thoughts}
        By understanding the correlations between text mining methodologies and practical applications, we can appreciate their relevance in today’s data-driven environment. Let's move on to explore further reading opportunities for deeper engagement with these concepts.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Resources and Further Reading - Introduction}
    \begin{block}{Introduction}
        As text mining becomes increasingly important in various domains, having access to reliable resources for further learning can significantly enhance your understanding and skill set. Below, we provide a curated selection of books, online courses, and articles to deepen your knowledge of text mining and representation learning.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Resources and Further Reading - Recommended Books}
    \begin{block}{Recommended Books}
        \begin{enumerate}
            \item \textbf{"Foundations of Statistical Natural Language Processing" by Christopher D. Manning and Hinrich Schütze}
            \begin{itemize}
                \item \textbf{Overview}: Covers statistical methods used in natural language processing (NLP).
                \item \textbf{Key Points}: Algorithms, probabilistic models, and evaluation metrics.
            \end{itemize}
            
            \item \textbf{"Text Mining: Concepts, Methodologies, Tools, and Applications" edited by Information Resources Management Association}
            \begin{itemize}
                \item \textbf{Overview}: Discusses various text mining applications and methodologies.
                \item \textbf{Key Points}: Real-world applications, case studies, and tool evaluations.
            \end{itemize}
            
            \item \textbf{"Python Text Processing with NLTK 2.0 Cookbook" by Jacob Perkins}
            \begin{itemize}
                \item \textbf{Overview}: A practical guide for Python users exploring text mining techniques.
                \item \textbf{Key Points}: Hands-on code snippets, practical exercises, and real-life examples.
            \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Resources and Further Reading - Online Courses}
    \begin{block}{Online Courses}
        \begin{enumerate}
            \item \textbf{Coursera: Natural Language Processing Specialization}
            \begin{itemize}
                \item \textbf{Provider}: DeepLearning.AI
                \item \textbf{Description}: Covers a wide range of NLP techniques, including text mining.
                \item \textbf{Key Topics}: RNNs, NLP techniques, Sentiment Analysis.
            \end{itemize}
            
            \item \textbf{edX: Text Mining and Analytics}
            \begin{itemize}
                \item \textbf{Provider}: University of California, Berkeley
                \item \textbf{Description}: Focuses on extracting insights and patterns from textual data.
                \item \textbf{Key Topics}: Text analysis, visualization techniques, and hands-on projects.
            \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Resources and Further Reading - Online Resources}
    \begin{block}{Online Resources}
        \begin{enumerate}
            \item \textbf{Kaggle Notebooks}
            \begin{itemize}
                \item \textbf{Link}: \href{https://www.kaggle.com/notebooks}{Kaggle Notebooks}
                \item \textbf{Description}: Offers real-world datasets and community-driven notebooks for practice.
            \end{itemize}
            
            \item \textbf{Towards Data Science (Medium)}
            \begin{itemize}
                \item \textbf{Link}: \href{https://towardsdatascience.com/tagged/text-mining}{Towards Data Science}
                \item \textbf{Description}: A collection of articles and tutorials on the latest trends in text mining.
            \end{itemize}
            
            \item \textbf{ArXiv.org}
            \begin{itemize}
                \item \textbf{Link}: \href{https://arxiv.org/}{arXiv}
                \item \textbf{Description}: Repository for the latest research papers, including cutting-edge text mining research.
            \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Resources and Further Reading - Conclusion}
    \begin{block}{Conclusion}
        Exploring these resources can provide you with deeper insights into text mining methodologies, tools, and applications. Engaging with both theoretical texts and practical materials will enhance your understanding and application of text mining techniques.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Resources and Further Reading - Key Takeaways}
    \begin{block}{Key Takeaways}
        \begin{itemize}
            \item \textbf{Diverse Learning Materials}: Use books, courses, and online platforms to grasp various aspects of text mining.
            \item \textbf{Hands-On Practice}: Engage with practical tools and datasets to solidify your understanding.
            \item \textbf{Stay Updated}: Follow research papers for the latest advancements in the field.
        \end{itemize}
    \end{block}
\end{frame}


\end{document}