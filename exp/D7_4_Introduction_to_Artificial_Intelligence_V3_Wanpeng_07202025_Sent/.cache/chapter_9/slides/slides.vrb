\frametitle{Key Algorithms in Reinforcement Learning - Value-Based Methods}
  \begin{block}{Value-Based Methods}
    Value-based methods focus on estimating the value of actions taken in specific states, deriving policies indirectly from these estimates.
  \end{block}

  \begin{block}{Q-Learning}
    \begin{itemize}
      \item \textbf{Definition}: An off-policy algorithm learning the value of actions with Q-values.
      \item \textbf{Formula}:
      \[
      Q(s, a) \leftarrow Q(s, a) + \alpha \left( r + \gamma \max_{a'} Q(s', a') - Q(s, a) \right)
      \]
      \begin{itemize}
        \item \( Q(s, a) \): Current estimated Q-value of action \( a \) in state \( s \)
        \item \( \alpha \): Learning rate (0 < \( \alpha \) ≤ 1)
        \item \( r \): Reward received
        \item \( \gamma \): Discount factor (0 ≤ \( \gamma \) < 1)
        \item \( s' \): Next state
      \end{itemize}
      \item \textbf{Example}: Chess board configurations to estimate optimal moves based on past experiences.
    \end{itemize}
  \end{block}
