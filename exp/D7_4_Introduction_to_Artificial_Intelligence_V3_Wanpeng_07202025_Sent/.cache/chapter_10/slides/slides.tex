\documentclass[aspectratio=169]{beamer}

% Theme and Color Setup
\usetheme{Madrid}
\usecolortheme{whale}
\useinnertheme{rectangles}
\useoutertheme{miniframes}

% Additional Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{positioning}
\usepackage{hyperref}

% Custom Colors
\definecolor{myblue}{RGB}{31, 73, 125}
\definecolor{mygray}{RGB}{100, 100, 100}
\definecolor{mygreen}{RGB}{0, 128, 0}
\definecolor{myorange}{RGB}{230, 126, 34}
\definecolor{mycodebackground}{RGB}{245, 245, 245}

% Set Theme Colors
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=white, bg=myblue}
\setbeamercolor{title}{fg=myblue}
\setbeamercolor{section in toc}{fg=myblue}
\setbeamercolor{item projected}{fg=white, bg=myblue}
\setbeamercolor{block title}{bg=myblue!20, fg=myblue}
\setbeamercolor{block body}{bg=myblue!10}
\setbeamercolor{alerted text}{fg=myorange}

% Set Fonts
\setbeamerfont{title}{size=\Large, series=\bfseries}
\setbeamerfont{frametitle}{size=\large, series=\bfseries}
\setbeamerfont{caption}{size=\small}
\setbeamerfont{footnote}{size=\tiny}

% Footer and Navigation Setup
\setbeamertemplate{footline}{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
    \usebeamerfont{author in head/foot}\insertshortauthor
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.5\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
    \usebeamerfont{title in head/foot}\insertshorttitle
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.2\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}%
    \usebeamerfont{date in head/foot}
    \insertframenumber{} / \inserttotalframenumber
  \end{beamercolorbox}}%
  \vskip0pt%
}

% Turn off navigation symbols
\setbeamertemplate{navigation symbols}{}

% Title Page Information
\title[Probabilistic Reasoning]{Week 10: Probabilistic Reasoning}
\author[J. Smith]{John Smith, Ph.D.}
\institute[University Name]{
  Department of Computer Science\\
  University Name\\
  \vspace{0.3cm}
  Email: email@university.edu\\
  Website: www.university.edu
}
\date{\today}

% Document Start
\begin{document}

\frame{\titlepage}

\begin{frame}[fragile]
    \frametitle{Introduction to Probabilistic Reasoning}
    \begin{block}{What is Probabilistic Reasoning?}
        Probabilistic reasoning is a method used to draw conclusions from uncertain information. It is foundational in various fields, most notably artificial intelligence (AI), where uncertainty is inherent and decisions must still be made.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Importance in AI}
    \begin{itemize}
        \item \textbf{Handling Uncertainty:} 
            In real-world scenarios, data is often incomplete or noisy. Probabilistic reasoning allows AI systems to make informed predictions based on available information.
        
        \item \textbf{Decision Making:} 
            AI systems use probabilistic models to evaluate different outcomes and make decisions based on probabilities rather than deterministic approaches.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Real-World Applications}
    \begin{enumerate}
        \item \textbf{Medical Diagnosis:} 
            Doctors leverage probabilistic models to assess the likelihood of diseases based on symptoms and diagnostic tests. 
            \begin{itemize}
                \item Example: If a patient presents fever and cough, and the model predicts a 70\% probability of flu versus a 30\% probability of a cold, the doctor can prioritize treatment accordingly.
            \end{itemize}
        
        \item \textbf{Weather Forecasting:} 
            Meteorologists use probabilistic reasoning to predict weather patterns, often providing a probability of specific conditions (e.g., "30\% chance of rain").
            \begin{itemize}
                \item Illustration: The likelihood of rain can be modeled by analyzing historical data and current atmospheric conditions.
            \end{itemize}
        
        \item \textbf{Recommendation Systems:}
            Platforms like Netflix and Amazon use probabilistic reasoning to suggest movies or products based on user preferences and past behavior.
            \begin{itemize}
                \item Example: If a user liked three sci-fi movies, the system may predict with a 90\% probability that they will enjoy a new sci-fi release.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Concepts to Remember}
    \begin{itemize}
        \item \textbf{Probability Basics:} Understanding events, outcomes, and likelihoods is essential for grasping more complex probabilistic methods.
        \item \textbf{Bayes' Theorem:} A fundamental principle for updating the probability of a hypothesis based on new evidence.
    \end{itemize}
    \begin{equation}
        P(H|E) = \frac{P(E|H) \cdot P(H)}{P(E)}
    \end{equation}
    \begin{itemize}
        \item \(P(H|E)\) = probability of hypothesis \(H\) given evidence \(E\).
        \item \(P(E|H)\) = probability of evidence \(E\) given hypothesis \(H\).
        \item \(P(H)\) = prior probability of hypothesis \(H\).
        \item \(P(E)\) = total probability of evidence \(E\).
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{What is Probability?}
    \begin{block}{Understanding Probability}
        Probability is a branch of mathematics that deals with quantifying uncertainty. It helps us predict the likelihood of events occurring based on known or observed data.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Definitions}
    \begin{itemize}
        \item \textbf{Probability (P)}: A measure of the likelihood that an event will occur, expressed as a number between 0 and 1.
        \begin{itemize}
            \item \( P(\text{Event}) = \frac{\text{Number of favorable outcomes}}{\text{Total number of possible outcomes}} \)
            \item If \( P = 0 \), the event will not happen; if \( P = 1 \), it will certainly happen.
        \end{itemize}
        
        \item \textbf{Sample Space (S)}: The set of all possible outcomes of a random experiment. 
        \begin{itemize}
            \item *Example*: For a coin toss, the sample space is \( S = \{\text{Heads}, \text{Tails}\} \).
        \end{itemize}
        
        \item \textbf{Event (E)}: A subset of the sample space representing one or more outcomes.
        \begin{itemize}
            \item *Example*: Getting Heads in a coin toss can be defined as \( E = \{\text{Heads}\} \).
        \end{itemize}
        
        \item \textbf{Random Variable (X)}: A variable that takes on numerical values based on the outcome of a random phenomenon.
        \begin{itemize}
            \item Discrete Random Variable: Takes on a countable number of values. (*Example*: Number of heads in three tosses of a coin).
            \item Continuous Random Variable: Takes on an infinite number of values within a given range. (*Example*: Height of students).
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Formulas}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item Probability quantifies uncertainty and is pivotal in fields such as statistics, finance, science, and artificial intelligence.
            \item Understanding the sample space allows for accurate calculations of probabilities related to events.
            \item Random variables provide a way to attach numbers to outcomes, facilitating mathematical operations on probabilistic models.
        \end{itemize}
    \end{block}

    \begin{block}{Formulas}
        \begin{enumerate}
            \item \textbf{Basic Probability Formula:}
            \begin{equation}
                P(E) = \frac{\text{Number of favorable outcomes}}{\text{Total number of outcomes}}
            \end{equation}
            \item \textbf{For Discrete Random Variables:}
            \begin{equation}
                E(X) = \sum [x_i \cdot P(x_i)]
            \end{equation}
            Where \( E(X) \) is the expected value, \( x_i \) are the possible values of the random variable, and \( P(x_i) \) is the probability of each value.
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Probability - Introduction}
    \begin{block}{Introduction}
        Probability is the measure of the likelihood that an event will occur. There are three main types of probability:
        \begin{itemize}
            \item Classical Probability
            \item Empirical Probability
            \item Subjective Probability
        \end{itemize}
        Each type has its unique characteristics and applications.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Probability - Classical Probability}
    \begin{block}{Classical Probability}
        \textbf{Definition:} Classical probability is based on the assumption that all outcomes in a sample space are equally likely. 

        \textbf{Formula:}
        \begin{equation}
            P(A) = \frac{n(A)}{n(S)}
        \end{equation}
        Where:
        \begin{itemize}
            \item \( P(A) \) = probability of event \( A \) occurring
            \item \( n(A) \) = number of favorable outcomes for event \( A \)
            \item \( n(S) \) = total number of outcomes in the sample space
        \end{itemize}
        
        \textbf{Example:} For a fair six-sided die:
        \begin{itemize}
            \item Favorable outcomes \( n(A) = 1 \)
            \item Total outcomes \( n(S) = 6 \)
        \end{itemize}
        Thus, 
        \begin{equation}
            P(rolling\ a\ 3) = \frac{1}{6}
        \end{equation}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Probability - Empirical and Subjective Probability}
    \begin{block}{Empirical Probability}
        \textbf{Definition:} Empirical probability is based on observed data. It is calculated by performing an experiment and recording the frequency of events.

        \textbf{Formula:}
        \begin{equation}
            P(A) = \frac{f}{n}
        \end{equation}
        Where:
        \begin{itemize}
            \item \( f \) = number of times event \( A \) occurs
            \item \( n \) = total number of trials
        \end{itemize}
        
        \textbf{Example:} If you flip a coin 100 times and get heads 56 times:
        \begin{itemize}
            \item Favorable outcomes \( f = 56 \)
            \item Total flips \( n = 100 \)
        \end{itemize}
        Then,
        \[
        P(Heads) = \frac{56}{100} = 0.56
        \]
    \end{block}


    \begin{block}{Subjective Probability}
        \textbf{Definition:} Subjective probability is based on personal judgment or opinion rather than on exact calculations. 

        \textbf{Example:} A weather forecaster might estimate a 70% chance of rain based on experience and conditions.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Types of Probability - Key Points}
    \begin{block}{Key Points}
        \begin{itemize}
            \item \textbf{Classical Probability:} Theoretical outcomes useful in well-defined scenarios.
            \item \textbf{Empirical Probability:} Based on actual experiments, insightful but variable based on data quality.
            \item \textbf{Subjective Probability:} Personal beliefs affecting estimates; can be flexible but less reliable.
        \end{itemize}
    \end{block}
    
    \begin{block}{Next Steps}
        In the following slide, we will delve into \textbf{Conditional Probability}, exploring how the probability of one event can affect the probability of another event.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conditional Probability - Definition}
    \begin{block}{Definition of Conditional Probability}
        Conditional probability is the probability of an event occurring given that another event has already occurred. 
        It is denoted as \( P(A|B) \), which reads "the probability of A given B." 
        This concept is vital in scenarios where the occurrence of one event affects the likelihood of another.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conditional Probability - Mathematical Representation}
    \begin{block}{Mathematical Representation}
        The formula for calculating conditional probability is expressed as:
        \begin{equation}
            P(A|B) = \frac{P(A \cap B)}{P(B)} 
        \end{equation}
        where:
        \begin{itemize}
            \item \( P(A|B) \) = Probability of event A occurring given that event B has occurred.
            \item \( P(A \cap B) \) = Probability of both events A and B occurring.
            \item \( P(B) \) = Probability of event B occurring.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conditional Probability - Significance}
    \begin{block}{Significance of Conditional Probability}
        \begin{enumerate}
            \item \textbf{Real-World Applications:} Useful in fields like medicine, finance, and machine learning where certain factors influence outcomes.
            \item \textbf{Decision Making:} Understanding how probabilities are modified by conditions can lead to better decision-making and predictions.
            \item \textbf{Foundation for Advanced Concepts:} A core component of Bayes’ Theorem and crucial for statistics and machine learning.
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conditional Probability - Examples}
    \begin{block}{Weather Example}
        \begin{itemize}
            \item Let A = "It will rain tomorrow."
            \item Let B = "The weather forecast predicts rain."
            \item With \( P(A) = 0.3 \), \( P(B) = 0.6 \), and \( P(A \cap B) = 0.2 \):
        \end{itemize}
        \begin{equation}
            P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{0.2}{0.6} \approx 0.33 
        \end{equation}
        This means there is approximately a 33% chance it will rain tomorrow given that the forecast predicts rain.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conditional Probability - Medical Diagnosis Example}
    \begin{block}{Medical Diagnosis Example}
        \begin{itemize}
            \item Let A = "Patient has a disease."
            \item Let B = "Test result is positive."
            \item If \( P(A) = 0.01 \), \( P(B|A) = 0.95 \), and \( P(B|\neg A) = 0.05 \):
        \end{itemize}
        We can find \( P(A|B) \) using Bayes' Theorem that we will discuss in the next slide.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conditional Probability - Key Points}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item Conditional probability helps in understanding the dependency of events.
            \item It is foundational for grasping complex probability concepts such as Bayes' Theorem.
            \item Always ensure the basic rules of probability apply (e.g., \( P(A|B) \) is valid only if \( P(B) > 0 \)).
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Bayes' Theorem - Introduction}
    \begin{block}{Introduction to Bayes' Theorem}
        Bayes' Theorem is a fundamental concept in probability theory that describes how to update the probability of a hypothesis based on new evidence. It allows us to revise our beliefs in the light of new data.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Bayes' Theorem - Formula}
    \begin{block}{Bayes' Theorem Formula}
        The theorem is formally expressed as:
        \begin{equation}
            P(H|E) = \frac{P(E|H) \cdot P(H)}{P(E)}
        \end{equation}
        Where:
        \begin{itemize}
            \item $P(H|E)$ = Posterior Probability: the probability of hypothesis $H$ given evidence $E$.
            \item $P(E|H)$ = Likelihood: the probability of observing evidence $E$ given that $H$ is true.
            \item $P(H)$ = Prior Probability: the initial probability of hypothesis $H$ before observing evidence.
            \item $P(E)$ = Marginal Probability: the total probability of observing evidence $E$ under all hypotheses.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Bayes' Theorem - Derivation}
    \begin{block}{Derivation Steps}
        1. **Conditional Probability Review**:
           \[
           P(A|B) = \frac{P(A \cap B)}{P(B)}
           \]
           Rearranging gives:
           \[
           P(A \cap B) = P(A|B) \cdot P(B)
           \]

        2. **Applying Conditional Probability**:
           \[
           P(E) = P(E|H) \cdot P(H) + P(E|\neg H) \cdot P(\neg H)
           \]

        3. **Combining Equations**: 
           Substituting these values leads us to Bayes' Theorem.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Bayes' Theorem - Example}
    \begin{block}{Example: Medical Diagnosis}
        \begin{itemize}
            \item **Context**: Determining if a patient has a disease (H) based on a positive test result (E).
            \item **Prior Probability ($P(H)$)**: Prevalence of the disease is 1\% $(0.01)$.
            \item **Likelihood ($P(E|H)$)**: Probability of a positive result if the patient has the disease is 90\% $(0.90)$.
            \item **False Positive Rate ($P(E|\neg H)$)**: Probability of a positive result if the patient does not have the disease is 5\% $(0.05)$.
        \end{itemize}

        **Calculating Posterior Probability**: 
        \[
        P(E) = (0.90 \cdot 0.01) + (0.05 \cdot 0.99) = 0.0585
        \]
        \[
        P(H|E) = \frac{0.90 \cdot 0.01}{0.0585} \approx 0.1538 
        \]
        Thus, the updated probability that the patient has the disease given a positive test result is approximately 15.38\%.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Bayes' Theorem - Key Points}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item **Updating Knowledge**: Bayes' Theorem quantifies how evidence influences decision-making under uncertainty.
            \item **Real-World Applications**: Commonly used in medical diagnosis, spam filtering, and machine learning.
            \item **Practical Tool**: Helps improve predictions and insights by iteratively refining probabilities as more data becomes available.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of Bayes' Theorem - Introduction}
    \begin{block}{What is Bayes' Theorem?}
        Bayes' Theorem is a powerful mathematical formula used to update the probability of a hypothesis as more evidence or information becomes available. It emphasizes how to revise our beliefs in light of new data.
    \end{block}
    \begin{equation}
        P(H|E) = \frac{P(E|H) \cdot P(H)}{P(E)}
    \end{equation}
    \begin{itemize}
        \item \(P(H|E)\): Probability of hypothesis \(H\) given evidence \(E\)
        \item \(P(E|H)\): Probability of evidence \(E\) given \(H\)
        \item \(P(H)\): Probability of hypothesis \(H\) before evidence
        \item \(P(E)\): Total probability of evidence \(E\)
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of Bayes' Theorem - Medical Diagnosis}
    \begin{block}{Bayesian Applications in Medicine}
        In medical diagnosis, Bayes' Theorem allows healthcare professionals to assess the likelihood of a disease based on test results.
    \end{block}
    \begin{itemize}
        \item **Example Scenario**: A doctor evaluates the probability of a patient having a disease \(D\) after testing positive.
        \item **Key Components**:
            \begin{itemize}
                \item **Prior Probability** (\(P(D)\)): The prevalence of the disease in the population.
                \item **Likelihood** (\(P(\text{Positive Test} | D)\)): Probability of a positive test if the disease is present.
                \item **Evidence Probability** (\(P(\text{Positive Test})\)): Overall probability of a positive test occurring.
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of Bayes' Theorem - Spam Detection}
    \begin{block}{Bayesian Filtering for Spam Detection}
        Bayes' Theorem is extensively used in spam filtering to classify emails based on observed features.
    \end{block}
    \begin{itemize}
        \item **Example Scenario**: Determining if an email is spam based on the presence of the word "free".
        \item **Key Components**:
            \begin{itemize}
                \item Let \(S\) represent spam and \(W\) represent the presence of "free".
                \item **Prior Probability** (\(P(S)\)): The probability of any email being spam.
                \item **Likelihood** (\(P(W|S)\)): Probability that "free" appears in spam emails.
                \item **Evidence Probability** (\(P(W)\)): Overall probability of "free" appearing in any email.
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of Bayes' Theorem - Key Points}
    \begin{itemize}
        \item Bayes' Theorem updates beliefs based on new evidence.
        \item It is critical for informed decision-making in medical diagnostics.
        \item Enhances email sorting in spam detection by leveraging past data.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Applications of Bayes' Theorem - Conclusion}
    \begin{block}{Summary}
        Bayes' Theorem serves as both a theoretical tool and a practical framework with significant implications in critical areas like healthcare and information technology. Understanding its applications enhances decision-making based on probabilistic reasoning.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Introduction to Bayesian Networks}
    \begin{block}{Definition of Bayesian Networks}
        A Bayesian Network (BN) is a graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG).
        It visualizes and computes probabilistic relationships, aiding in inferring outcomes based on inputs.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Components of Bayesian Networks}
    \begin{itemize}
        \item \textbf{Nodes}:
            \begin{itemize}
                \item Represent random variables, either discrete (e.g., weather) or continuous (e.g., temperature).
                \item \textbf{Example}: In a medical BN, nodes represent symptoms (e.g., cough, fever) and diseases (e.g., flu, cold).
            \end{itemize}
        \item \textbf{Directed Edges}:
            \begin{itemize}
                \item Indicate influence or dependency; an edge from A to B means A influences B.
                \item \textbf{Example}: An edge from "Disease" to "Symptom" suggests disease presence increases symptom likelihood.
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points and Illustration}
    \begin{itemize}
        \item \textbf{Directionality}: Directed edges denote causation; not just correlation.
        \item \textbf{Acyclic Property}: No feedback loops are allowed.
        \item \textbf{Probabilistic Inference}: BNs aid in probability calculations of unknowns given evidence.
    \end{itemize}

    \begin{block}{Illustration: Simple Bayesian Network Example}
        \begin{center}
            \includegraphics[width=0.5\textwidth]{bayesian_network.png} % Placeholder for the actual illustration
        \end{center}
    \end{block}

    \begin{equation}
        P(X_1, X_2, \ldots, X_n) = \prod_{i=1}^{n} P(X_i \mid \text{Parents}(X_i))
    \end{equation}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Structure of Bayesian Networks - Overview}
    \begin{block}{Key Concepts}
        \begin{enumerate}
            \item \textbf{Bayesian Network Definition}: A graphical model representing variables and their conditional dependencies via a directed acyclic graph (DAG).
            \item \textbf{Graph Structure and Conditional Independence}:
                \begin{itemize}
                    \item Directed edges indicate direct influence.
                    \item Conditional independence is established by parent-child relationships in the graph.
                \end{itemize}
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Structure of Bayesian Networks - Influence}
    \begin{block}{Influence of Structure}
        \begin{itemize}
            \item \textbf{Representation of Relationships}:
                \begin{itemize}
                    \item Presence of edges signifies direct probabilistic influence, e.g., Rain $\rightarrow$ Traffic.
                \end{itemize}
            \item \textbf{Node Conditional Probability Tables (CPTs)}:
                \begin{itemize}
                    \item Each node has a CPT quantifying the effect of parent nodes on its probability, as illustrated:
                \end{itemize}
                \begin{center}
                    \begin{tabular}{|c|c|c|}
                        \hline
                        Rain & Rush Hour & P(Traffic) \\
                        \hline
                        Yes  & Yes       & 0.9 \\
                        Yes  & No        & 0.7 \\
                        No   & Yes       & 0.3 \\
                        No   & No        & 0.1 \\
                        \hline
                    \end{tabular}
                \end{center}
            \item \textbf{Impact of Removing/Adding Edges}:
                \begin{itemize}
                    \item Removing an edge indicates no direct influence.
                    \item Adding an edge establishes new dependence.
                \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Structure of Bayesian Networks - Examples and Conclusion}
    \begin{block}{Examples for Clarity}
        \begin{enumerate}
            \item \textbf{Example 1}:
                \begin{itemize}
                    \item In a health-related network: Smoking increases Cancer, which in turn increases Coughing.
                \end{itemize}
            \item \textbf{Example 2}:
                \begin{itemize}
                    \item Absence of an edge implies independence, e.g., Coughing and Smoking are independent given Cancer.
                \end{itemize}
        \end{enumerate}
    \end{block}
    \begin{block}{Conclusion}
        The structure of nodes and edges in a Bayesian network is crucial for understanding the probabilistic relationships and enables effective probabilistic reasoning and inference.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Inference in Bayesian Networks - Introduction}
    \begin{block}{Introduction to Inference}
        Bayesian networks (BNs) are graphical models that represent variables and their conditional dependencies via directed acyclic graphs (DAGs).
        Inference involves computing posterior probabilities of certain variables based on observed data.
    \end{block}
    \begin{itemize}
        \item Exact Inference
        \item Approximate Inference
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Inference in Bayesian Networks - Exact Inference}
    \begin{block}{Exact Inference}
        Exact inference methods compute precise probabilities, working well for simpler networks but becoming computationally expensive with complexity.
    \end{block}
    \begin{itemize}
        \item \textbf{Key Methods:}
        \begin{itemize}
            \item \textbf{Variable Elimination}
            \item \textbf{Junction Tree Algorithm}
        \end{itemize}
    \end{itemize}
    \begin{block}{Variable Elimination}
        To calculate posterior probabilities efficiently by eliminating variables systematically:
        \begin{equation}
            P(A | E) = \frac{\sum_{X \in \text{Rest}} P(A, X | E)}{P(E)}
        \end{equation}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Inference in Bayesian Networks - Approximate Inference}
    \begin{block}{Approximate Inference}
        Necessary for large or complex networks where exact methods are impractical, providing estimates of probabilities.
    \end{block}
    \begin{itemize}
        \item \textbf{Key Methods:}
        \begin{itemize}
            \item \textbf{Monte Carlo Simulation}
            \item \textbf{Variational Inference}
        \end{itemize}
    \end{itemize}
    \begin{itemize}
        \item \textbf{Trade-offs:}
        \begin{itemize}
            \item Exact methods: Precise but computationally intensive.
            \item Approximate methods: Scalable and faster, but come with simulation error.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Inference in Bayesian Networks - Applications and Summary}
    \begin{block}{Applications}
        Used in areas such as:
        \begin{itemize}
            \item Medical Diagnosis
            \item Risk Assessment
            \item Decision-Making Under Uncertainty
        \end{itemize}
    \end{block}
    \begin{block}{Summary}
        Understanding both exact and approximate methods is crucial for practical applications of probabilistic reasoning in Bayesian networks.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Markov Decision Processes (MDPs) - Introduction}
    \begin{block}{Introduction to MDPs}
        Markov Decision Processes (MDPs) provide a mathematical framework for modeling decision-making situations where outcomes are partly random and partly under the control of an agent. They are instrumental in areas like robotics, automated control, and reinforcement learning.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{MDPs - Key Concepts}
    \begin{enumerate}
        \item \textbf{Markov Property}: Future states depend only on the current state and action taken:
        \begin{equation}
            P(S_{t+1} | S_t, A_t) = P(S_{t+1} | S_t)
        \end{equation}
        \item \textbf{Decision-Making Environment}: MDPs model environments requiring a sequence of decisions to maximize cumulative rewards over time.
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{MDPs - Components and Example}
    \begin{block}{Components of MDPs}
        \begin{itemize}
            \item \textbf{States (S)}: The possible situations for the agent.
            \item \textbf{Actions (A)}: Choices available to the agent at each state.
            \item \textbf{Transition Probabilities (P)}: Likelihood of moving between states after an action.
            \item \textbf{Rewards (R)}: Feedback for actions taken in various states.
            \item \textbf{Policies (π)}: Strategies to choose actions in each state.
        \end{itemize}
    \end{block}

    \begin{block}{Example Scenario}
        Consider a simple grid world:
        \begin{itemize}
            \item \textbf{States}: Each cell in the grid.
            \item \textbf{Actions}: Move up, down, left, or right.
            \item \textbf{Transition}: Movement may be blocked by obstacles.
            \item \textbf{Rewards}: Points for reaching the goal and penalties for hitting obstacles.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{MDPs - Key Points and Conclusion}
    \begin{itemize}
        \item MDPs encapsulate the essence of sequential decision-making under uncertainty.
        \item The Markov property simplifies environment modeling, allowing informed decisions based on current states.
        \item Understanding MDPs is crucial for reinforcement learning algorithms.
    \end{itemize}
    
    \begin{block}{Conclusion}
        MDPs are foundational for various algorithms in artificial intelligence, essential for optimal long-term strategies and more complex decision-making frameworks.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Components of MDPs}
    \begin{block}{Key Concepts}
        Markov Decision Processes (MDPs) are fundamental in probabilistic reasoning and decision-making under uncertainty. An MDP is defined by five key components:
        \begin{itemize}
            \item States
            \item Actions
            \item Transition Probabilities
            \item Rewards
            \item Policies
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{States (S)}
    \begin{block}{Definition}
        A state represents the current configuration or situation of the environment. It encapsulates all relevant information needed for making a decision.
    \end{block}
    \begin{block}{Example}
        In a chess game, each unique arrangement of pieces on the board represents a different state.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Actions (A)}
    \begin{block}{Definition}
        Actions are the choices available to the agent in each state. The action taken influences the next state and determines the outcome of the decision-making process.
    \end{block}
    \begin{block}{Example}
        In a driving scenario, possible actions could include "turn left", "turn right", "accelerate", or "brake".
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Transition Probabilities (P)}
    \begin{block}{Definition}
        Transition probabilities define the likelihood of moving from one state to another after taking a specific action. They are often denoted as \( P(s' | s, a) \).
    \end{block}
    \begin{block}{Example}
        If an action 'shoot' in a basketball game results in a point with a probability of 0.7 and missing the shot with a probability of 0.3, these values represent the transition probabilities associated with that action in a given state.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Rewards (R)}
    \begin{block}{Definition}
        A reward is a numerical value received after transitioning to a new state. It quantifies the immediate benefit of an action taken in a given state, often denoted as \( R(s, a, s') \).
    \end{block}
    \begin{block}{Example}
        In a robotic pathway scenario, reaching a target could yield a reward of +10, while bumping into an obstacle might yield a penalty of -5.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Policies (π)}
    \begin{block}{Definition}
        A policy is a strategy that defines the agent's way of behaving at any given time. It is a mapping from states to actions.
    \end{block}
    \begin{block}{Example}
        In a game, a policy could dictate that, if the current state is a losing position, the action taken should aim for the most conservative strategy to prolong the game.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Summary of Key Points}
    \begin{itemize}
        \item \textbf{States}: Define the environment’s current status.
        \item \textbf{Actions}: Are the choices available to influence future states.
        \item \textbf{Transition probabilities}: Indicate the likelihood of state changes due to actions.
        \item \textbf{Rewards}: Provide feedback on the success of actions.
        \item \textbf{Policies}: Are strategies that guide decision-making.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Formula for Transition Probability}
    Transition probabilities can often be represented in a matrix form for easier computational handling:
    
    \begin{equation}
        P_{ij} = P(s_j | s_i, a)
    \end{equation}
    
    Where \( P_{ij} \) is the probability of transitioning from state \( s_i \) to state \( s_j \) after taking action \( a \).
\end{frame}

\begin{frame}[fragile]
    \frametitle{Conclusion}
    MDPs form the backbone for making optimal decisions in uncertain environments. By mastering the components—
    states, actions, transition probabilities, rewards, and policies—students can learn to devise effective strategies and solve complex decision-making problems.
\end{frame}

\begin{frame}[fragile]
    \frametitle{Overview of Methods for Solving MDPs}
    \begin{itemize}
        \item Markov Decision Processes (MDPs) model decision-making under uncertainty.
        \item Key methodologies for solving MDPs:
        \begin{itemize}
            \item Dynamic Programming (DP)
            \item Reinforcement Learning (RL)
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Dynamic Programming (DP)}
    \begin{block}{Description}
        Dynamic Programming is an algorithmic technique that breaks complex problems into simpler subproblems for efficient solving.
    \end{block}
    
    \begin{itemize}
        \item **Key DP Algorithms**:
        \begin{itemize}
            \item **Value Iteration**
            \item **Policy Iteration**
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Dynamic Programming - Value Iteration}
    \begin{itemize}
        \item Value Iteration updates state values based on expected future rewards.
        \item Formula:
        \begin{equation}
        V(s) \gets R(s) + \gamma \sum_{s'} P(s'|s,a)V(s')
        \end{equation}
        \begin{itemize}
            \item \( V(s) \): Value of state \( s \)
            \item \( R(s) \): Immediate reward for state \( s \)
            \item \( \gamma \): Discount factor (0 ≤ \( \gamma \) < 1)
            \item \( P(s'|s,a) \): Probability of transitioning to state \( s' \)
        \end{itemize}
    \end{itemize}
    
    \begin{block}{Example}
        A robot navigating a grid can use DP to determine the best actions for maximizing rewards.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Reinforcement Learning (RL)}
    \begin{block}{Description}
        Reinforcement Learning involves agents learning to make decisions through interaction with their environment, without needing a model.
    \end{block}
    
    \begin{itemize}
        \item **Key RL Techniques**:
        \begin{itemize}
            \item **Q-Learning**
            \item **Deep Q-Networks (DQN)**
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Q-Learning}
    \begin{itemize}
        \item Q-Learning updates the Q-value based on the current state, action, and reward:
        \begin{equation}
        Q(s,a) \gets Q(s,a) + \alpha \left( r + \gamma \max_{a'} Q(s',a') - Q(s,a) \right)
        \end{equation}
        \begin{itemize}
            \item \( Q(s,a) \): Q-value for state \( s \), action \( a \)
            \item \( \alpha \): Learning rate
            \item \( r \): Immediate reward
        \end{itemize}
    \end{itemize}

    \begin{block}{Example}
        An agent playing a video game learns to optimize its score by tweaking its strategies from past experiences.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Key Points to Emphasize}
    \begin{itemize}
        \item MDPs model decision-making under uncertainty.
        \item Dynamic Programming excels with known models.
        \item Reinforcement Learning is ideal for model-free environments.
        \item Mastering both methods prepares students for diverse applications.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Comparing Bayesian Networks and MDPs - Concepts}
    \begin{block}{Bayesian Networks (BNs)}
        \begin{itemize}
            \item \textbf{Definition}: A graphical model representing variables and their conditional dependencies using a directed acyclic graph (DAG).
            \item \textbf{Purpose}: Primarily used for probabilistic inference—reasoning about uncertain events based on known relationships.
        \end{itemize}
    \end{block}
    
    \begin{block}{Markov Decision Processes (MDPs)}
        \begin{itemize}
            \item \textbf{Definition}: A framework for modeling decision-making where outcomes are partly random and partly under the control of a decision maker.
            \item \textbf{Purpose}: Focus on finding optimal policies to maximize expected rewards over time, accommodating uncertainty in states and rewards.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Comparing Bayesian Networks and MDPs - Key Differences}
    \begin{enumerate}
        \item \textbf{Nature of Problems Addressed}:
            \begin{itemize}
                \item BNs: Suitable for uncertainty in knowledge and inference about variable relationships (e.g., medical diagnosis).
                \item MDPs: Applicable when decisions are made sequentially, considering states, actions, and rewards (e.g., robotic navigation).
            \end{itemize}
        
        \item \textbf{Graphical Representation}:
            \begin{itemize}
                \item BNs: Use directed edges for conditional dependencies.
                \item MDPs: Represented as state transition diagrams, not relying on a DAG structure.
            \end{itemize}
        
        \item \textbf{Temporal Aspect}:
            \begin{itemize}
                \item BNs: Typically static snapshots of dependencies.
                \item MDPs: Dynamic, modeling a sequence of decisions across time.
            \end{itemize}
        
        \item \textbf{Decision-Making}:
            \begin{itemize}
                \item BNs: Inference to deduce probabilities given evidence.
                \item MDPs: Policy selection to maximize cumulative reward.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Comparing Bayesian Networks and MDPs - Use Cases}
    \begin{block}{Bayesian Networks}
        \begin{itemize}
            \item \textbf{Example}: Medical diagnosis system using symptoms to infer the likelihood of diseases.
            \item \textbf{Illustration}: A simplified disease model with nodes for symptoms/diseases and edges for conditional probabilities.
        \end{itemize}
    \end{block}
    
    \begin{block}{Markov Decision Processes}
        \begin{itemize}
            \item \textbf{Example}: Robot navigating a maze, deciding direction based on rewards.
            \item \textbf{Illustration}: Grid layout of a maze with states colored by reward values, arrows indicating actions.
        \end{itemize}
    \end{block}
    
    \begin{block}{Key Points}
        \begin{itemize}
            \item BNs excel in uncertainty visualization and probability inference.
            \item MDPs are suited for dynamic sequential decision-making.
            \item Choose between BNs and MDPs based on context and problem-solving needs.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Challenges in Probabilistic Reasoning}
    \begin{block}{Overview}
        Probabilistic reasoning is used to manage uncertainty in applications like machine learning, artificial intelligence, and data analysis. However, it faces several challenges:
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Computational Complexity}
    \begin{itemize}
        \item \textbf{Definition:} Complexity of algorithms can grow exponentially with problem size.
        \item \textbf{Explanation:} As the number of variables increases, calculations required for inference expand dramatically, especially in Bayesian networks and Markov Decision Processes (MDPs).
        \item \textbf{Example:} In a Bayesian network with $n$ variables, inference time complexity can be $O(2^n)$. For instance, with 10 variables, a naive approach evaluates $2^{10} = 1024$ states.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Data Requirements and Modeling Challenges}
    \begin{itemize}
        \item \textbf{Data Requirements:}
        \begin{itemize}
            \item Models need large amounts of high-quality data for accurate probability estimation.
            \item Limited or biased data can result in erroneous inferences.
            \item \textbf{Example:} Training on a non-representative population dataset can lead to misleading outcomes.
        \end{itemize}
        \item \textbf{Modeling Difficulties:}
        \begin{itemize}
            \item \textbf{Incompleteness:} Hidden or latent variables complicate the model structure.
            \item \textbf{Overfitting:} Complex models may capture noise rather than the underlying processes.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Implications - Introduction}
    \begin{block}{Introduction}
        Probabilistic reasoning plays a crucial role in AI and decision-making processes, but it raises important ethical considerations. This slide explores key ethical issues that arise from using probabilistic models.
    \end{block}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Implications - Key Considerations}
    \begin{enumerate}
        \item \textbf{Bias and Fairness}
            \begin{itemize}
                \item Definition: Models can perpetuate biases in training data.
                \item Example: Credit scoring model may discriminate based on biased historical data.
                \item Implication: Implement fairness metrics to evaluate equitable treatment.
            \end{itemize}
        
        \item \textbf{Transparency and Explainability}
            \begin{itemize}
                \item Definition: Complex models can be hard to interpret.
                \item Example: Patient risk prediction model clarity may hinder trust.
                \item Implication: Aim for transparency using interpretability techniques.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Implications - Continued}
    \begin{enumerate}
        \setcounter{enumi}{2}
        \item \textbf{Accountability}
            \begin{itemize}
                \item Definition: Responsible parties for model-based decisions must be clear.
                \item Example: Liability in autonomous vehicle driving errors.
                \item Implication: Establish guidelines for responsibility allocation.
            \end{itemize}

        \item \textbf{Informed Consent}
            \begin{itemize}
                \item Definition: Users should know how their data is utilized.
                \item Example: Health data usage requires informed user consent.
                \item Implication: Ethical data collection practices are essential.
            \end{itemize}

        \item \textbf{Impacts on Society}
            \begin{itemize}
                \item Definition: AI can influence societal norms and behaviors.
                \item Example: Predictive policing may erode community trust.
                \item Implication: Consider broader societal effects of AI interventions.
            \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Ethical Implications - Conclusion}
    \begin{block}{Key Points to Emphasize}
        \begin{itemize}
            \item Bias and fairness are paramount in equitable AI systems.
            \item Transparency and explainability are essential for user trust.
            \item Clear accountability mechanisms are necessary for AI decisions.
            \item Informed consent is crucial for ethical data usage.
            \item Consider the wider societal implications of probabilistic reasoning in AI.
        \end{itemize}
    \end{block}
    
    \begin{block}{Conclusion}
        Recognizing and addressing these ethical implications is essential to ensure responsible use of probabilistic reasoning in AI systems, paving the way for fairer and more equitable technology deployment.
    \end{block}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Conclusion - Part 1}
  \begin{block}{Summary of Key Points}
    In this week's exploration of \textbf{Probabilistic Reasoning}, we have covered essential concepts that underline decision-making in uncertain environments, particularly in AI. The primary takeaways include:
  \end{block}

  \begin{enumerate}
    \item \textbf{Fundamentals of Probability}
      \begin{itemize}
        \item Key Terms: Random Variables, Independence, Conditional Probability.
      \end{itemize}
    \item \textbf{Bayesian Inference}
      \begin{itemize}
        \item Allows updating beliefs with new evidence.
        \item Example: Updating the probability of disease presence as new test results are obtained.
      \end{itemize}
    \item \textbf{Probabilistic Models}
      \begin{itemize}
        \item We explored models such as Bayesian networks and Markov models.
        \item Example: A Bayesian network predicting illness likelihood based on symptoms.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Conclusion - Part 2}
  \begin{enumerate}
    \setcounter{enumii}{3}
    \item \textbf{Applications in AI}
      \begin{itemize}
        \item Critical in natural language processing, robotics, and recommendation systems.
      \end{itemize}
    \item \textbf{Ethical Considerations}
      \begin{itemize}
        \item The ethical implications guide the transparency and fairness of AI decision-making.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Future Directions}
  Looking ahead, several developments in the field of probabilistic reasoning and AI hold promise for enhancing model robustness and applicability:

  \begin{enumerate}
    \item \textbf{Advancements in Algorithm Efficiency}
    \item \textbf{Integration with Machine Learning}
      \begin{itemize}
        \item Integration of probabilistic reasoning with deep learning, e.g., CNNs for image classification.
      \end{itemize}
    \item \textbf{Explainable AI}
      \begin{itemize}
        \item Enhancing interpretability of probabilistic models.
      \end{itemize}
    \item \textbf{Real-World Applications}
      \begin{itemize}
        \item New applications in healthcare, finance, and climate modeling.
      \end{itemize}
    \item \textbf{Ethical Frameworks}
      \begin{itemize}
        \item Building frameworks to ensure accountability and fairness.
      \end{itemize}
  \end{enumerate}
  
  By synthesizing these concepts and exploring future avenues, we can enhance our understanding of probabilistic reasoning in AI.
\end{frame}

\begin{frame}[fragile]
  \frametitle{Key Formulas}
  \begin{block}{Bayes' Theorem}
    \[
    P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
    \]
    This formula illustrates how to update the probability of a hypothesis (A) given new data (B).
  \end{block}
\end{frame}


\end{document}